import asyncio
from typing import Any, Optional

from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from pocketflow import AsyncFlow
from pydantic import BaseModel

from nodes import AsyncDesignOptimizationNode, AsyncRequirementsAnalysisNode
from short_planner_flow import (
    GenerateStepsNode,
    OptimizeNode,
    create_short_planner_flow,
)

planning_router = APIRouter(prefix="/planning", tags=["planning"])


async def encode_stream_generator(generator):
    """ç¡®ä¿æµå¼è¾“å‡ºæ­£ç¡®ç¼–ç ä¸ºUTF-8"""
    async for chunk in generator:
        if isinstance(chunk, str):
            yield chunk.encode('utf-8')
        else:
            yield chunk


class ShortPlanningRequest(BaseModel):
    requirement: str
    previous_flow: Optional[Any] = None
    language: Optional[str] = None  # User's preferred language (e.g., 'en', 'zh', 'es')
    user_id: Optional[str] = None  # Optional user identifier for language preferences


class LongPlanningRequest(BaseModel):
    requirement: str
    previous_flow: Optional[Any] = None
    design_doc: Optional[Any] = None
    language: Optional[str] = None  # User's preferred language
    user_id: Optional[str] = None  # Optional user identifier for language preferences


@planning_router.post("/short")
async def short_planning(body: ShortPlanningRequest):
    requirement = body.requirement
    previous_flow = body.previous_flow
    language = body.language
    user_id = body.user_id

    if not requirement:
        return {"error": "Missing 'requirement' in request body."}

    # Prepare shared context with multilingual support
    shared_base = {
        "requirement": requirement,
        "request_language": language,
        "user_id": user_id,
        "history": [],
        "version": 1,
    }

    # Add user language preference if available
    if user_id:
        from utils.config_manager import get_language_preference

        user_preference = get_language_preference(user_id)
        if user_preference:
            shared_base["user_language_preference"] = user_preference

    if previous_flow and previous_flow != "":
        # User provided previous flow, go directly to optimization node
        shared = shared_base.copy()
        shared["steps"] = previous_flow
        shared["feedback"] = requirement  # Use new requirement as optimization feedback

        optimize = OptimizeNode()
        await AsyncFlow(start=optimize).run_async(shared)

        # Determine the language used for response
        response_language = shared.get("language", language or "en")

        return {
            "flow": shared.get("steps", "No flow generated."),
            "language": response_language,
            "user_id": user_id,
        }
    else:
        # Generate new flow
        shared = shared_base.copy()

        generateStepsNode = GenerateStepsNode()
        await AsyncFlow(start=generateStepsNode).run_async(shared)

        # Determine the language used for response
        # Use detected language from shared context, fallback to request language only if not empty, otherwise default to "en"
        response_language = shared.get("language", language if language else "en")

        return {
            "flow": shared.get("steps", "No flow generated."),
            "language": response_language,
            "user_id": user_id,
        }


@planning_router.post("/long")
async def long_planning(body: LongPlanningRequest):
    requirement = body.requirement
    previous_flow = body.previous_flow
    design_doc = body.design_doc
    language = body.language
    user_id = body.user_id

    if not requirement:
        return {"error": "Missing 'requirement' in request body."}

    # Prepare shared context with multilingual support
    shared = {
        "user_input": {
            "processed_natural_language": requirement,
            "processed_documents": design_doc,
        },
        "short_flow_steps": previous_flow,
        "conversation_history": [],
        "request_language": language,
        "user_id": user_id,
    }

    # Add user language preference if available
    if user_id:
        from utils.config_manager import get_language_preference

        user_preference = get_language_preference(user_id)
        if user_preference:
            shared["user_language_preference"] = user_preference

    requirement_node = AsyncRequirementsAnalysisNode()
    design_doc_node = AsyncDesignOptimizationNode()
    requirement_node >> design_doc_node
    await AsyncFlow(start=requirement_node).run_async(shared)

    # Determine the language used for response
    # Use detected language from shared context, fallback to request language only if not empty, otherwise default to "en"
    response_language = shared.get("language", language if language else "en")

    print(shared.get("user_input", {}).get("processed_documents", "No flow generated."))
    return {
        "flow": shared.get("user_input", {}).get(
            "processed_documents", "No flow generated."
        ),
        "language": response_language,
        "user_id": user_id,
    }


async def short_planning_stream(body: ShortPlanningRequest):
    """æµå¼çŸ­è§„åˆ’ç”Ÿæˆ - åŒ…å«å’Œéæµå¼ç‰ˆæœ¬ç›¸åŒçš„æ‰€æœ‰åŠŸèƒ½"""
    requirement = body.requirement
    previous_flow = body.previous_flow
    language = body.language
    user_id = body.user_id

    if not requirement:
        yield "data: [ERROR_START]\n"
        yield "data: âŒ Missing 'requirement' in request body.\n"
        yield "data: [ERROR_END]\n\n"
        return

    try:
        # Prepare shared context with multilingual support (å’Œéæµå¼ç‰ˆæœ¬ç›¸åŒ)
        shared_base = {
            "requirement": requirement,
            "request_language": language,
            "user_id": user_id,
            "history": [],
            "version": 1,
        }

        # Add user language preference if available (å’Œéæµå¼ç‰ˆæœ¬ç›¸åŒ)
        if user_id:
            from utils.config_manager import get_language_preference

            user_preference = get_language_preference(user_id)
            if user_preference:
                shared_base["user_language_preference"] = user_preference

        if previous_flow and previous_flow != "":
            # User provided previous flow, go directly to optimization node (æµå¼ç‰ˆæœ¬)
            shared = shared_base.copy()
            shared["steps"] = previous_flow
            shared["feedback"] = requirement  # Use new requirement as optimization feedback

            from short_planner_flow import OptimizeStreamNode
            optimize_node = OptimizeStreamNode()
            prep_result = await optimize_node.prep_async(shared)

            # æµå¼è¾“å‡ºä¼˜åŒ–ç»“æœ
            yield "data: [SHORT_PLAN_START]\n"

            full_response = ""
            async for chunk in optimize_node.exec_async_stream(prep_result):
                full_response += chunk
                # ä½¿ç”¨å ä½ç¬¦ä¿æŠ¤æ¢è¡Œç¬¦ï¼Œé¿å…ä¸SSEåè®®å†²çª
                protected_chunk = chunk.replace('\n', '<|newline|>')
                yield f"data: {protected_chunk}\n"

            # ä¿å­˜ç»“æœåˆ°shared context
            await optimize_node.post_async(shared, prep_result, full_response)

            yield "data: [SHORT_PLAN_END]\n\n"
        else:
            # Generate new flow (æµå¼ç‰ˆæœ¬)
            shared = shared_base.copy()

            from short_planner_flow import GenerateStepsStreamNode
            generate_node = GenerateStepsStreamNode()
            prep_result = await generate_node.prep_async(shared)

            # æµå¼è¾“å‡ºç”Ÿæˆç»“æœ
            yield "data: [SHORT_PLAN_START]\n"

            full_response = ""
            async for chunk in generate_node.exec_async_stream(prep_result):
                full_response += chunk
                # ä½¿ç”¨å ä½ç¬¦ä¿æŠ¤æ¢è¡Œç¬¦ï¼Œé¿å…ä¸SSEåè®®å†²çª
                protected_chunk = chunk.replace('\n', '<|newline|>')
                yield f"data: {protected_chunk}\n"

            # ä¿å­˜ç»“æœåˆ°shared context
            await generate_node.post_async(shared, prep_result, full_response)

            yield "data: [SHORT_PLAN_END]\n\n"

    except Exception as e:
        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
        import logging
        logging.error(f"Error in short_planning_stream: {str(e)}", exc_info=True)

        # å‘ç”¨æˆ·è¿”å›é€šç”¨é”™è¯¯ä¿¡æ¯ï¼Œä¸æš´éœ²å†…éƒ¨ç»†èŠ‚
        yield "data: [ERROR_START]\n"
        yield "data: âŒ An internal error occurred while generating planning. Please try again later.\n"
        yield "data: [ERROR_END]\n\n"


async def long_planning_stream(body: LongPlanningRequest):
    """æµå¼é•¿æ–‡æ¡£ç”Ÿæˆ - åŒ…å«å’Œéæµå¼ç‰ˆæœ¬ç›¸åŒçš„æ‰€æœ‰åŠŸèƒ½"""
    requirement = body.requirement
    previous_flow = body.previous_flow
    design_doc = body.design_doc
    language = body.language
    user_id = body.user_id

    if not requirement:
        yield "data: [ERROR_START]\n"
        yield "data: âŒ Missing 'requirement' in request body.\n"
        yield "data: [ERROR_END]\n\n"
        return

    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å— (AsyncFlowå’Œnodeså·²åœ¨é¡¶éƒ¨å¯¼å…¥)

        # Prepare shared context with multilingual support (å’Œéæµå¼ç‰ˆæœ¬ç›¸åŒ)
        shared = {
            "user_input": {
                "processed_natural_language": requirement,
                "processed_documents": design_doc,
            },
            "short_flow_steps": previous_flow,
            "conversation_history": [],
            "request_language": language,
            "user_id": user_id,
        }

        # Add user language preference if available (å’Œéæµå¼ç‰ˆæœ¬ç›¸åŒ)
        if user_id:
            from utils.config_manager import get_language_preference

            user_preference = get_language_preference(user_id)
            if user_preference:
                shared["user_language_preference"] = user_preference

        # æµå¼éœ€æ±‚åˆ†æé˜¶æ®µ
        yield "data: [STATUS_START]\n"
        if language == "zh":
            yield "data: ğŸ” æ­£åœ¨åˆ†æéœ€æ±‚...\n"
        else:
            yield "data: ğŸ” Analyzing requirements...\n"
        yield "data: [STATUS_END]\n\n"

        # ä½¿ç”¨æµå¼éœ€æ±‚åˆ†æèŠ‚ç‚¹
        from nodes import AsyncRequirementsAnalysisStreamNode
        requirement_node = AsyncRequirementsAnalysisStreamNode()
        prep_result = await requirement_node.prep_async(shared)

        # æµå¼è¾“å‡ºéœ€æ±‚åˆ†æè¿‡ç¨‹
        yield "data: [ANALYSIS_START]\n"

        full_analysis = ""
        async for chunk in requirement_node.exec_async_stream(prep_result):
            full_analysis += chunk
            # ä½¿ç”¨å ä½ç¬¦ä¿æŠ¤æ¢è¡Œç¬¦ï¼Œé¿å…ä¸SSEåè®®å†²çª
            protected_chunk = chunk.replace('\n', '<|newline|>')
            yield f"data: {protected_chunk}\n"

        # ä¿å­˜åˆ†æç»“æœ
        await requirement_node.post_async(shared, prep_result, full_analysis)

        yield "data: [ANALYSIS_END]\n\n"

        # å‘é€çŠ¶æ€æ›´æ–°
        yield "data: [STATUS_START]\n"
        if language == "zh":
            yield "data: ğŸ“ å¼€å§‹ç”Ÿæˆè®¾è®¡æ–‡æ¡£...\n"
        else:
            yield "data: ğŸ“ Generating design document...\n"
        yield "data: [STATUS_END]\n\n"

        # ç„¶åæ‰‹åŠ¨è¿è¡Œè®¾è®¡ä¼˜åŒ–èŠ‚ç‚¹çš„æµå¼ç‰ˆæœ¬
        from nodes import AsyncDesignOptimizationStreamNode
        design_doc_node = AsyncDesignOptimizationStreamNode()
        prep_result = await design_doc_node.prep_async(shared)

        # æµå¼è¾“å‡ºç”Ÿæˆçš„æ–‡æ¡£
        yield "data: [LONG_DOC_START]\n"

        # æµå¼ç”Ÿæˆå¹¶è¾“å‡ºæ–‡æ¡£å†…å®¹
        full_response = ""
        async for chunk in design_doc_node.exec_async_stream(prep_result):
            full_response += chunk
            # ä½¿ç”¨å ä½ç¬¦ä¿æŠ¤æ¢è¡Œç¬¦ï¼Œé¿å…ä¸SSEåè®®å†²çª
            protected_chunk = chunk.replace('\n', '<|newline|>')
            yield f"data: {protected_chunk}\n"

        # ä¿å­˜ç»“æœåˆ°shared context
        await design_doc_node.post_async(shared, prep_result, full_response)

        yield "data: [LONG_DOC_END]\n\n"

    except Exception as e:
        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
        import logging
        logging.error(f"Error in long_planning_stream: {str(e)}", exc_info=True)

        # å‘ç”¨æˆ·è¿”å›é€šç”¨é”™è¯¯ä¿¡æ¯ï¼Œä¸æš´éœ²å†…éƒ¨ç»†èŠ‚
        yield "data: [ERROR_START]\n"
        yield "data: âŒ An internal error occurred while generating document. Please try again later.\n"
        yield "data: [ERROR_END]\n\n"


@planning_router.post("/short/stream")
async def short_planning_stream_endpoint(body: ShortPlanningRequest):
    """æµå¼çŸ­è§„åˆ’æ¥å£"""
    return StreamingResponse(
        encode_stream_generator(short_planning_stream(body)),
        media_type="text/plain; charset=utf-8",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/plain; charset=utf-8"
        }
    )


@planning_router.post("/long/stream")
async def long_planning_stream_endpoint(body: LongPlanningRequest):
    """æµå¼é•¿æ–‡æ¡£æ¥å£"""
    return StreamingResponse(
        encode_stream_generator(long_planning_stream(body)),
        media_type="text/plain; charset=utf-8",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/plain; charset=utf-8"
        }
    )


# æµ‹è¯•å‡½æ•°
async def test_short_planning():
    """æµ‹è¯• short_planning å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯• short_planning å‡½æ•°...")

    # æµ‹è¯•ç”¨ä¾‹1: åŸºæœ¬éœ€æ±‚æµ‹è¯•
    print("\næµ‹è¯•ç”¨ä¾‹1: åŸºæœ¬éœ€æ±‚")
    test_request1 = ShortPlanningRequest(requirement="åˆ›å»ºä¸€ä¸ªç®€å•çš„å¾…åŠäº‹é¡¹åº”ç”¨")
    try:
        result1 = await short_planning(test_request1)
        print(f"ç»“æœ1: {result1}")
    except Exception as e:
        print(f"æµ‹è¯•1å‡ºé”™: {e}")

    # æµ‹è¯•ç”¨ä¾‹2: ç©ºéœ€æ±‚æµ‹è¯•
    print("\næµ‹è¯•ç”¨ä¾‹2: ç©ºéœ€æ±‚")
    test_request2 = ShortPlanningRequest(requirement="")
    try:
        result2 = await short_planning(test_request2)
        print(f"ç»“æœ2: {result2}")
    except Exception as e:
        print(f"æµ‹è¯•2å‡ºé”™: {e}")

    # æµ‹è¯•ç”¨ä¾‹3: å¸¦æœ‰ä¹‹å‰æµç¨‹çš„ä¼˜åŒ–æµ‹è¯•
    print("\næµ‹è¯•ç”¨ä¾‹3: ä¼˜åŒ–ç°æœ‰æµç¨‹")
    previous_flow = ["æ­¥éª¤1: è®¾è®¡ç•Œé¢", "æ­¥éª¤2: å®ç°åŠŸèƒ½", "æ­¥éª¤3: æµ‹è¯•"]
    test_request3 = ShortPlanningRequest(
        requirement="å¢åŠ ç”¨æˆ·ç™»å½•åŠŸèƒ½", previous_flow=previous_flow
    )
    try:
        result3 = await short_planning(test_request3)
        print(f"ç»“æœ3: {result3}")
    except Exception as e:
        print(f"æµ‹è¯•3å‡ºé”™: {e}")

    print("\næµ‹è¯•å®Œæˆ!")


# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œæµ‹è¯•
if __name__ == "__main__":
    asyncio.run(test_short_planning())
