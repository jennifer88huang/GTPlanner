"""
OpenAIæµå¼è¾“å‡ºé€‚é…å™¨

æä¾›OpenAI SDKæµå¼è¾“å‡ºä¸ç°æœ‰JSONStreamParserçš„å…¼å®¹æ€§å±‚ï¼Œ
æ”¯æŒFunction Callingçš„æµå¼å¤„ç†å’Œå®æ—¶æ˜¾ç¤ºã€‚
"""

import json
import asyncio
from typing import AsyncIterator, Dict, List, Any, Optional, Callable, Union
from openai.types.chat import ChatCompletionChunk
from openai.types.chat.chat_completion_chunk import ChoiceDelta

from utils.openai_client import get_openai_client
from utils.json_stream_parser import JSONStreamParser


class OpenAIStreamAdapter:
    """OpenAIæµå¼è¾“å‡ºé€‚é…å™¨"""
    
    def __init__(self):
        self.client = get_openai_client()
        self.current_content = ""
        self.current_tool_calls = {}
        self.message_complete = False
    
    async def stream_chat_completion(
        self,
        messages: List[Dict[str, str]],
        tools: Optional[List[Dict]] = None,
        json_mode: bool = False,
        field_callback: Optional[Callable] = None,
        tool_call_callback: Optional[Callable] = None,
        **kwargs
    ) -> AsyncIterator[str]:
        """
        æµå¼èŠå¤©å®Œæˆï¼Œæ”¯æŒJSONè§£æå’ŒFunction Calling
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            tools: Function Callingå·¥å…·åˆ—è¡¨
            json_mode: æ˜¯å¦å¯ç”¨JSONæ¨¡å¼
            field_callback: JSONå­—æ®µæ›´æ–°å›è°ƒ
            tool_call_callback: å·¥å…·è°ƒç”¨å›è°ƒ
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            æµå¼å†…å®¹å—
        """
        # é‡ç½®çŠ¶æ€
        self.current_content = ""
        self.current_tool_calls = {}
        self.message_complete = False
        
        # è®¾ç½®JSONæ¨¡å¼
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}
        
        # åˆ›å»ºJSONè§£æå™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        json_parser = None
        if json_mode and field_callback:
            json_parser = JSONStreamParser()
            json_parser.subscribe_field("user_message", field_callback)
        
        try:
            # æ‰§è¡Œæµå¼è°ƒç”¨
            async for chunk in self.client.chat_completion_stream_async(
                messages, tools=tools, **kwargs
            ):
                # å¤„ç†å†…å®¹æµ
                content_chunk = await self._process_content_chunk(
                    chunk, json_parser, tool_call_callback
                )
                
                if content_chunk:
                    yield content_chunk
            
            # å¤„ç†å®Œæˆåçš„å·¥å…·è°ƒç”¨
            if self.current_tool_calls and tool_call_callback:
                await self._finalize_tool_calls(tool_call_callback)
                
        except Exception as e:
            print(f"âš ï¸ æµå¼å¤„ç†é”™è¯¯: {e}")
            raise
    
    async def _process_content_chunk(
        self,
        chunk: ChatCompletionChunk,
        json_parser: Optional[JSONStreamParser] = None,
        tool_call_callback: Optional[Callable] = None
    ) -> Optional[str]:
        """
        å¤„ç†å•ä¸ªå†…å®¹å—
        
        Args:
            chunk: OpenAIå“åº”å—
            json_parser: JSONè§£æå™¨
            tool_call_callback: å·¥å…·è°ƒç”¨å›è°ƒ
            
        Returns:
            å¤„ç†åçš„å†…å®¹å—
        """
        if not chunk.choices:
            return None
        
        choice = chunk.choices[0]
        delta = choice.delta
        
        # å¤„ç†å†…å®¹
        if delta.content:
            self.current_content += delta.content
            
            # JSONè§£æ
            if json_parser:
                json_parser.add_chunk(delta.content)
            
            return delta.content
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if delta.tool_calls:
            await self._process_tool_calls(delta.tool_calls, tool_call_callback)
        
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if choice.finish_reason:
            self.message_complete = True
            
            # æœ€ç»ˆJSONè§£æ
            if json_parser:
                json_parser.finalize()
        
        return None
    
    async def _process_tool_calls(
        self,
        tool_calls: List[Any],
        tool_call_callback: Optional[Callable] = None
    ) -> None:
        """
        å¤„ç†å·¥å…·è°ƒç”¨æµ
        
        Args:
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            tool_call_callback: å·¥å…·è°ƒç”¨å›è°ƒ
        """
        for tool_call in tool_calls:
            call_id = tool_call.id
            
            # åˆå§‹åŒ–å·¥å…·è°ƒç”¨è®°å½•
            if call_id not in self.current_tool_calls:
                self.current_tool_calls[call_id] = {
                    "id": call_id,
                    "type": tool_call.type,
                    "function": {
                        "name": "",
                        "arguments": ""
                    },
                    "complete": False
                }
            
            # æ›´æ–°å·¥å…·è°ƒç”¨ä¿¡æ¯
            current_call = self.current_tool_calls[call_id]
            
            if tool_call.function:
                if tool_call.function.name:
                    current_call["function"]["name"] = tool_call.function.name
                
                if tool_call.function.arguments:
                    current_call["function"]["arguments"] += tool_call.function.arguments
            
            # å®æ—¶å›è°ƒï¼ˆå¦‚æœæœ‰ï¼‰
            if tool_call_callback:
                await self._call_tool_callback(
                    tool_call_callback,
                    current_call,
                    is_complete=False
                )
    
    async def _finalize_tool_calls(
        self,
        tool_call_callback: Callable
    ) -> None:
        """
        å®Œæˆå·¥å…·è°ƒç”¨å¤„ç†
        
        Args:
            tool_call_callback: å·¥å…·è°ƒç”¨å›è°ƒ
        """
        for call_id, call_data in self.current_tool_calls.items():
            call_data["complete"] = True
            
            await self._call_tool_callback(
                tool_call_callback,
                call_data,
                is_complete=True
            )
    
    async def _call_tool_callback(
        self,
        callback: Callable,
        call_data: Dict[str, Any],
        is_complete: bool
    ) -> None:
        """
        è°ƒç”¨å·¥å…·å›è°ƒå‡½æ•°
        
        Args:
            callback: å›è°ƒå‡½æ•°
            call_data: å·¥å…·è°ƒç”¨æ•°æ®
            is_complete: æ˜¯å¦å®Œæˆ
        """
        try:
            if asyncio.iscoroutinefunction(callback):
                await callback(call_data, is_complete)
            else:
                callback(call_data, is_complete)
        except Exception as e:
            print(f"âš ï¸ å·¥å…·å›è°ƒé”™è¯¯: {e}")


class LegacyStreamAdapter:
    """ä¼ ç»Ÿæµå¼è¾“å‡ºé€‚é…å™¨ï¼ˆå…¼å®¹ç°æœ‰call_llmæ¥å£ï¼‰"""
    
    def __init__(self):
        self.adapter = OpenAIStreamAdapter()
    
    async def call_llm_stream_async_compatible(
        self,
        prompt: str,
        is_json: bool = False,
        **kwargs
    ) -> AsyncIterator[str]:
        """
        å…¼å®¹ç°æœ‰call_llm_stream_asyncæ¥å£
        
        Args:
            prompt: æç¤ºè¯
            is_json: æ˜¯å¦JSONæ¨¡å¼
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            æµå¼å†…å®¹
        """
        messages = [{"role": "user", "content": prompt}]
        
        # JSONæ¨¡å¼å¤„ç†
        if is_json:
            messages[0]["content"] += "\n\nè¯·ä»¥JSONæ ¼å¼å›å¤ï¼Œç¡®ä¿è¾“å‡ºæ˜¯æœ‰æ•ˆçš„JSONã€‚"
        
        async for chunk in self.adapter.stream_chat_completion(
            messages,
            json_mode=is_json,
            **kwargs
        ):
            yield chunk


# ============================================================================
# é«˜çº§æµå¼å¤„ç†åŠŸèƒ½
# ============================================================================

class FunctionCallingStreamProcessor:
    """Function Callingæµå¼å¤„ç†å™¨"""
    
    def __init__(self):
        self.adapter = OpenAIStreamAdapter()
        self.active_tools = {}
        self.conversation_history = []
    
    async def process_with_tools(
        self,
        messages: List[Dict[str, str]],
        tools: List[Dict],
        tool_executor: Callable,
        max_iterations: int = 5,
        stream_callback: Optional[Callable] = None,
        tool_callback: Optional[Callable] = None
    ) -> List[Dict[str, Any]]:
        """
        å¤„ç†å¸¦å·¥å…·è°ƒç”¨çš„æµå¼å¯¹è¯
        
        Args:
            messages: æ¶ˆæ¯å†å²
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            tool_executor: å·¥å…·æ‰§è¡Œå™¨
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            stream_callback: æµå¼å†…å®¹å›è°ƒ
            tool_callback: å·¥å…·è°ƒç”¨å›è°ƒ
            
        Returns:
            å®Œæ•´çš„å¯¹è¯å†å²
        """
        current_messages = messages.copy()
        results = []
        
        for iteration in range(max_iterations):
            print(f"ğŸ”„ å¯¹è¯è¿­ä»£ {iteration + 1}/{max_iterations}")
            
            # æ”¶é›†æµå¼å†…å®¹
            content_buffer = ""
            tool_calls_buffer = []
            
            # å®šä¹‰å†…éƒ¨å›è°ƒ
            async def content_callback(content: str):
                nonlocal content_buffer
                content_buffer += content
                if stream_callback:
                    await self._safe_callback(stream_callback, content)
            
            async def internal_tool_callback(call_data: Dict, is_complete: bool):
                if is_complete:
                    tool_calls_buffer.append(call_data)
                if tool_callback:
                    await self._safe_callback(tool_callback, call_data, is_complete)
            
            # æ‰§è¡Œæµå¼è°ƒç”¨
            async for chunk in self.adapter.stream_chat_completion(
                current_messages,
                tools=tools,
                tool_call_callback=internal_tool_callback
            ):
                await content_callback(chunk)
            
            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
            assistant_message = {
                "role": "assistant",
                "content": content_buffer or None
            }
            
            if tool_calls_buffer:
                assistant_message["tool_calls"] = tool_calls_buffer
            
            current_messages.append(assistant_message)
            
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¯¹è¯
            if not tool_calls_buffer:
                break
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            for tool_call in tool_calls_buffer:
                try:
                    # è§£æå‚æ•°
                    arguments = json.loads(tool_call["function"]["arguments"])
                    
                    # æ‰§è¡Œå·¥å…·
                    print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_call['function']['name']}")
                    result = await tool_executor(
                        tool_call["function"]["name"],
                        arguments
                    )
                    
                    # æ·»åŠ å·¥å…·ç»“æœæ¶ˆæ¯
                    current_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "content": json.dumps(result, ensure_ascii=False)
                    })
                    
                    results.append({
                        "tool_name": tool_call["function"]["name"],
                        "arguments": arguments,
                        "result": result,
                        "success": True
                    })
                    
                except Exception as e:
                    print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                    
                    # æ·»åŠ é”™è¯¯æ¶ˆæ¯
                    current_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "content": f"Error: {str(e)}"
                    })
                    
                    results.append({
                        "tool_name": tool_call["function"]["name"],
                        "arguments": json.loads(tool_call["function"]["arguments"]) if tool_call["function"]["arguments"] else {},
                        "result": None,
                        "success": False,
                        "error": str(e)
                    })
        
        return current_messages
    
    async def _safe_callback(self, callback: Callable, *args, **kwargs):
        """å®‰å…¨è°ƒç”¨å›è°ƒå‡½æ•°"""
        try:
            if asyncio.iscoroutinefunction(callback):
                await callback(*args, **kwargs)
            else:
                callback(*args, **kwargs)
        except Exception as e:
            print(f"âš ï¸ å›è°ƒå‡½æ•°é”™è¯¯: {e}")


# ============================================================================
# å…¨å±€å®ä¾‹å’Œä¾¿æ·å‡½æ•°
# ============================================================================

_stream_adapter: Optional[OpenAIStreamAdapter] = None
_legacy_adapter: Optional[LegacyStreamAdapter] = None
_function_processor: Optional[FunctionCallingStreamProcessor] = None


def get_stream_adapter() -> OpenAIStreamAdapter:
    """è·å–æµå¼é€‚é…å™¨å®ä¾‹"""
    global _stream_adapter
    if _stream_adapter is None:
        _stream_adapter = OpenAIStreamAdapter()
    return _stream_adapter


def get_legacy_adapter() -> LegacyStreamAdapter:
    """è·å–ä¼ ç»Ÿé€‚é…å™¨å®ä¾‹"""
    global _legacy_adapter
    if _legacy_adapter is None:
        _legacy_adapter = LegacyStreamAdapter()
    return _legacy_adapter


def get_function_processor() -> FunctionCallingStreamProcessor:
    """è·å–Function Callingå¤„ç†å™¨å®ä¾‹"""
    global _function_processor
    if _function_processor is None:
        _function_processor = FunctionCallingStreamProcessor()
    return _function_processor
