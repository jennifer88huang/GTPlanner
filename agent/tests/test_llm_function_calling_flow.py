#!/usr/bin/env python3
"""
LLM Function Callingæµç¨‹æµ‹è¯•

æµ‹è¯•LLMä½¿ç”¨Function Callingå®žçŽ°çš„å¤šè½®å·¥å…·è°ƒç”¨å’Œæ–‡æœ¬è¾“å‡ºï¼š
ç”¨æˆ·è¾“å…¥ -> [tool1] -> LLMå¤„ç† -> [tool2] -> LLMå¤„ç† -> æœ€ç»ˆè¾“å‡º

è¿™ä¸ªæµ‹è¯•æ¨¡æ‹ŸçœŸå®žçš„å¯¹è¯åœºæ™¯ï¼Œå…¶ä¸­LLMä¼šï¼š
1. åˆ†æžç”¨æˆ·éœ€æ±‚å¹¶è°ƒç”¨éœ€æ±‚åˆ†æžå·¥å…·
2. åŸºäºŽéœ€æ±‚åˆ†æžç»“æžœè°ƒç”¨çŸ­æœŸè§„åˆ’å·¥å…·
3. å¯èƒ½è°ƒç”¨æŠ€æœ¯è°ƒç ”å·¥å…·
4. æœ€ç»ˆç”Ÿæˆç»¼åˆæ€§çš„å›žå¤
"""

import asyncio
import json
from typing import Dict, Any, List
from utils.openai_client import get_openai_client
from agent.function_calling import get_agent_function_definitions, execute_agent_tool


class LLMFunctionCallingFlowTest:
    """LLM Function Callingæµç¨‹æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.client = get_openai_client()
        self.tools = get_agent_function_definitions()
        self.conversation_history = []
    
    async def test_single_tool_call_flow(self):
        """æµ‹è¯•å•ä¸ªå·¥å…·è°ƒç”¨æµç¨‹"""
        print("ðŸ”„ æµ‹è¯•å•ä¸ªå·¥å…·è°ƒç”¨æµç¨‹...")
        
        # ç”¨æˆ·è¾“å…¥
        user_input = "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªåœ¨çº¿æ•™è‚²å¹³å°ï¼Œæ”¯æŒè§†é¢‘è¯¾ç¨‹å’Œåœ¨çº¿è€ƒè¯•åŠŸèƒ½"
        
        # ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯GTPlanneråŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è¿›è¡Œé¡¹ç›®è§„åˆ’ã€‚
å½“ç”¨æˆ·æå‡ºå¼€å‘éœ€æ±‚æ—¶ï¼Œä½ éœ€è¦ï¼š
1. ä½¿ç”¨requirements_analysiså·¥å…·åˆ†æžç”¨æˆ·éœ€æ±‚
2. åŸºäºŽåˆ†æžç»“æžœï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šçš„é¡¹ç›®å»ºè®®

è¯·å§‹ç»ˆä½¿ç”¨å·¥å…·æ¥å¤„ç†ç”¨æˆ·çš„éœ€æ±‚ï¼Œä¸è¦ç›´æŽ¥å›žç­”ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input}
        ]
        
        # ç¬¬ä¸€è½®ï¼šLLMè°ƒç”¨å·¥å…·
        print(f"ðŸ‘¤ ç”¨æˆ·: {user_input}")
        response = await self.client.chat_completion_async(
            messages=messages,
            tools=self.tools,
            tool_choice="auto"
        )
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if response.choices[0].message.tool_calls:
            tool_call = response.choices[0].message.tool_calls[0]
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)
            
            print(f"ðŸ”§ LLMè°ƒç”¨å·¥å…·: {tool_name}")
            print(f"ðŸ“ å·¥å…·å‚æ•°: {tool_args}")
            
            # æ‰§è¡Œå·¥å…·
            tool_result = await execute_agent_tool(tool_name, tool_args)
            
            # æ·»åŠ å·¥å…·è°ƒç”¨å’Œç»“æžœåˆ°å¯¹è¯åŽ†å²
            messages.append(response.choices[0].message)
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": json.dumps(tool_result, ensure_ascii=False)
            })
            
            # ç¬¬äºŒè½®ï¼šLLMåŸºäºŽå·¥å…·ç»“æžœç”Ÿæˆå›žå¤
            final_response = await self.client.chat_completion_async(
                messages=messages,
                tools=self.tools,
                tool_choice="none"  # ä¸å†è°ƒç”¨å·¥å…·ï¼Œåªç”Ÿæˆæ–‡æœ¬
            )
            
            final_content = final_response.choices[0].message.content
            print(f"ðŸ¤– LLMæœ€ç»ˆå›žå¤: {final_content[:200]}...")
            
            return {
                "success": True,
                "tool_called": tool_name,
                "tool_result": tool_result,
                "final_response": final_content
            }
        else:
            print("âŒ LLMæ²¡æœ‰è°ƒç”¨å·¥å…·")
            return {"success": False, "error": "No tool called"}
    
    async def test_multi_tool_call_flow(self):
        """æµ‹è¯•å¤šå·¥å…·è°ƒç”¨æµç¨‹"""
        print("\nðŸ”„ æµ‹è¯•å¤šå·¥å…·è°ƒç”¨æµç¨‹...")
        
        # ç”¨æˆ·è¾“å…¥
        user_input = "æˆ‘éœ€è¦å¼€å‘ä¸€ä¸ªç”µå•†ç³»ç»Ÿï¼Œè¯·å¸®æˆ‘åˆ†æžéœ€æ±‚å¹¶åˆ¶å®šå¼€å‘è®¡åˆ’"
        
        # ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯GTPlanneråŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è¿›è¡Œé¡¹ç›®è§„åˆ’ã€‚
å½“ç”¨æˆ·æå‡ºå¼€å‘éœ€æ±‚æ—¶ï¼Œä½ éœ€è¦æŒ‰é¡ºåºï¼š
1. é¦–å…ˆä½¿ç”¨requirements_analysiså·¥å…·åˆ†æžç”¨æˆ·éœ€æ±‚
2. ç„¶åŽä½¿ç”¨short_planningå·¥å…·åˆ¶å®šå¼€å‘è®¡åˆ’
3. æœ€åŽä¸ºç”¨æˆ·æä¾›ç»¼åˆæ€§çš„é¡¹ç›®å»ºè®®

è¯·é€æ­¥ä½¿ç”¨å·¥å…·ï¼Œæ¯æ¬¡åªè°ƒç”¨ä¸€ä¸ªå·¥å…·ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input}
        ]
        
        print(f"ðŸ‘¤ ç”¨æˆ·: {user_input}")
        
        tools_called = []
        max_rounds = 5  # æœ€å¤š5è½®å¯¹è¯
        
        for round_num in range(max_rounds):
            print(f"\n--- ç¬¬ {round_num + 1} è½® ---")
            
            # LLMå“åº”
            response = await self.client.chat_completion_async(
                messages=messages,
                tools=self.tools,
                tool_choice="auto"
            )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if response.choices[0].message.tool_calls:
                tool_call = response.choices[0].message.tool_calls[0]
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)
                
                print(f"ðŸ”§ LLMè°ƒç”¨å·¥å…·: {tool_name}")
                print(f"ðŸ“ å·¥å…·å‚æ•°: {tool_args}")
                
                # æ‰§è¡Œå·¥å…·
                tool_result = await execute_agent_tool(tool_name, tool_args)
                tools_called.append({
                    "tool": tool_name,
                    "args": tool_args,
                    "result": tool_result
                })
                
                # æ·»åŠ åˆ°å¯¹è¯åŽ†å²
                messages.append(response.choices[0].message)
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(tool_result, ensure_ascii=False)
                })
                
                print(f"âœ… å·¥å…·æ‰§è¡Œ{'æˆåŠŸ' if tool_result.get('success') else 'å¤±è´¥'}")
                
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼ŒLLMç”Ÿæˆæœ€ç»ˆå›žå¤
                final_content = response.choices[0].message.content
                print(f"ðŸ¤– LLMæœ€ç»ˆå›žå¤: {final_content[:300]}...")
                
                return {
                    "success": True,
                    "tools_called": tools_called,
                    "final_response": final_content,
                    "rounds": round_num + 1
                }
        
        return {
            "success": False,
            "error": "è¾¾åˆ°æœ€å¤§è½®æ•°é™åˆ¶",
            "tools_called": tools_called
        }
    
    async def test_conditional_tool_call_flow(self):
        """æµ‹è¯•æ¡ä»¶æ€§å·¥å…·è°ƒç”¨æµç¨‹"""
        print("\nðŸ”„ æµ‹è¯•æ¡ä»¶æ€§å·¥å…·è°ƒç”¨æµç¨‹...")
        
        # ç”¨æˆ·è¾“å…¥ - ä¸€ä¸ªéœ€è¦æŠ€æœ¯è°ƒç ”çš„å¤æ‚éœ€æ±‚
        user_input = "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªAIé©±åŠ¨çš„æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œéœ€è¦æ”¯æŒå¤šè¯­è¨€å’Œæƒ…æ„Ÿåˆ†æžï¼Œè¯·å¸®æˆ‘åˆ†æžæŠ€æœ¯æ–¹æ¡ˆ"
        
        # ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯GTPlanneråŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è¿›è¡Œé¡¹ç›®è§„åˆ’ã€‚
æ ¹æ®ç”¨æˆ·éœ€æ±‚çš„å¤æ‚ç¨‹åº¦ï¼Œä½ éœ€è¦æ™ºèƒ½é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼š

1. å¯¹äºŽæ‰€æœ‰å¼€å‘éœ€æ±‚ï¼Œéƒ½è¦å…ˆä½¿ç”¨requirements_analysiså·¥å…·
2. å¦‚æžœæ¶‰åŠå¤æ‚æŠ€æœ¯æˆ–æ–°æŠ€æœ¯ï¼Œä½¿ç”¨researchå·¥å…·è¿›è¡ŒæŠ€æœ¯è°ƒç ”
3. å¦‚æžœç”¨æˆ·æ˜Žç¡®è¦æ±‚åˆ¶å®šè®¡åˆ’ï¼Œä½¿ç”¨short_planningå·¥å…·
4. æœ€åŽæä¾›ç»¼åˆå»ºè®®

è¯·æ ¹æ®å®žé™…éœ€è¦é€‰æ‹©å·¥å…·ï¼Œä¸è¦ç›²ç›®è°ƒç”¨æ‰€æœ‰å·¥å…·ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input}
        ]
        
        print(f"ðŸ‘¤ ç”¨æˆ·: {user_input}")
        
        tools_called = []
        conversation_log = []
        max_rounds = 6
        
        for round_num in range(max_rounds):
            print(f"\n--- ç¬¬ {round_num + 1} è½® ---")
            
            response = await self.client.chat_completion_async(
                messages=messages,
                tools=self.tools,
                tool_choice="auto"
            )
            
            if response.choices[0].message.tool_calls:
                tool_call = response.choices[0].message.tool_calls[0]
                tool_name = tool_call.function.name
                tool_args = json.loads(tool_call.function.arguments)
                
                print(f"ðŸ”§ LLMæ™ºèƒ½é€‰æ‹©å·¥å…·: {tool_name}")
                
                # æ‰§è¡Œå·¥å…·
                tool_result = await execute_agent_tool(tool_name, tool_args)
                tools_called.append(tool_name)
                
                # è®°å½•å¯¹è¯
                conversation_log.append({
                    "round": round_num + 1,
                    "action": "tool_call",
                    "tool": tool_name,
                    "success": tool_result.get('success', False)
                })
                
                # æ›´æ–°å¯¹è¯åŽ†å²
                messages.append(response.choices[0].message)
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(tool_result, ensure_ascii=False)
                })
                
            else:
                # æœ€ç»ˆå›žå¤
                final_content = response.choices[0].message.content
                conversation_log.append({
                    "round": round_num + 1,
                    "action": "final_response",
                    "content_length": len(final_content)
                })
                
                print(f"ðŸ¤– LLMæœ€ç»ˆå›žå¤: {final_content[:300]}...")
                
                return {
                    "success": True,
                    "tools_called": tools_called,
                    "conversation_log": conversation_log,
                    "final_response": final_content
                }
        
        return {
            "success": False,
            "error": "è¾¾åˆ°æœ€å¤§è½®æ•°é™åˆ¶",
            "tools_called": tools_called,
            "conversation_log": conversation_log
        }
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ðŸš€ å¼€å§‹LLM Function Callingæµç¨‹æµ‹è¯•\n")
        
        # æµ‹è¯•1ï¼šå•å·¥å…·è°ƒç”¨
        result1 = await self.test_single_tool_call_flow()
        print(f"âœ… å•å·¥å…·è°ƒç”¨æµ‹è¯•: {'æˆåŠŸ' if result1['success'] else 'å¤±è´¥'}")
        
        # æµ‹è¯•2ï¼šå¤šå·¥å…·è°ƒç”¨
        result2 = await self.test_multi_tool_call_flow()
        print(f"âœ… å¤šå·¥å…·è°ƒç”¨æµ‹è¯•: {'æˆåŠŸ' if result2['success'] else 'å¤±è´¥'}")
        if result2['success']:
            print(f"   è°ƒç”¨äº† {len(result2['tools_called'])} ä¸ªå·¥å…·ï¼Œå…± {result2['rounds']} è½®å¯¹è¯")
        
        # æµ‹è¯•3ï¼šæ¡ä»¶æ€§å·¥å…·è°ƒç”¨
        result3 = await self.test_conditional_tool_call_flow()
        print(f"âœ… æ¡ä»¶æ€§å·¥å…·è°ƒç”¨æµ‹è¯•: {'æˆåŠŸ' if result3['success'] else 'å¤±è´¥'}")
        if result3['success']:
            print(f"   æ™ºèƒ½é€‰æ‹©äº†å·¥å…·: {', '.join(result3['tools_called'])}")
        
        print(f"\nðŸŽ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        return {
            "single_tool": result1,
            "multi_tool": result2,
            "conditional_tool": result3
        }


async def main():
    """ä¸»å‡½æ•°"""
    test = LLMFunctionCallingFlowTest()
    results = await test.run_all_tests()
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\nðŸ“Š æµ‹è¯•æ€»ç»“:")
    for test_name, result in results.items():
        status = "âœ… æˆåŠŸ" if result.get('success') else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        test_type = sys.argv[1]
        test = LLMFunctionCallingFlowTest()
        
        if test_type == "single":
            asyncio.run(test.test_single_tool_call_flow())
        elif test_type == "multi":
            asyncio.run(test.test_multi_tool_call_flow())
        elif test_type == "conditional":
            asyncio.run(test.test_conditional_tool_call_flow())
        else:
            print("ç”¨æ³•: python test_llm_function_calling_flow.py [single|multi|conditional]")
    else:
        asyncio.run(main())
