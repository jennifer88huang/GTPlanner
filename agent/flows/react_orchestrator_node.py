"""
ReAct Orchestrator Node

åŸºäºä½ çš„demoä»£ç é‡æ„çš„ReActä¸»æ§åˆ¶å™¨ã€‚
å‚è€ƒMainReActAgentçš„è®¾è®¡ï¼Œä½œä¸ºä¸­å¿ƒè°ƒåº¦å™¨ï¼Œé€šè¿‡åŠ¨æ€è·¯ç”±è¿æ¥åˆ°å„ä¸ªä¸“ä¸šAgentã€‚
"""

import json
import time
from typing import Dict, List, Any
from pocketflow import Node, AsyncNode
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'utils'))
from call_llm import call_llm


class ReActOrchestratorNode(AsyncNode):
    """ReActä¸»æ§åˆ¶å™¨ - å¼‚æ­¥ç‰ˆæœ¬ï¼Œæ”¯æŒæµå¼LLMè°ƒç”¨"""

    def __init__(self):
        super().__init__()
        self.name = "ReActOrchestratorNode"
        self.description = "å¼‚æ­¥ReActä¸»æ§åˆ¶å™¨ï¼Œæ”¯æŒæµå¼è¾“å‡º"
    
    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥å‡†å¤‡ReActæ‰§è¡Œç¯å¢ƒ"""
        try:
            # è·å–å¯¹è¯å†å²
            dialogue_history = shared.get("dialogue_history", {})
            messages = dialogue_history.get("messages", [])
            
            # è·å–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯
            user_message = ""
            if messages:
                for msg in reversed(messages):
                    if msg.get("role") == "user":
                        user_message = msg.get("content", "")
                        break
            
            # è·å–å½“å‰çŠ¶æ€
            current_stage = shared.get("current_stage", "initialization")
            
            # æ„å»ºçŠ¶æ€æè¿°
            state_info = self._build_state_description(shared, user_message)
            
            return {
                "success": True,
                "user_message": user_message,
                "current_stage": current_stage,
                "state_info": state_info,
                "shared_data": shared
            }
            
        except Exception as e:
            return {"error": f"ReAct preparation failed: {str(e)}"}
    
    async def exec_async(self, prep_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥ReActæ¨ç†å’Œå†³ç­–é€»è¾‘"""
        try:
            if "error" in prep_result:
                raise ValueError(prep_result["error"])
            
            user_message = prep_result["user_message"]
            state_info = prep_result["state_info"]
            
            print(f"ğŸ¤– ReAct Agentå¼€å§‹æ¨ç†...")
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt()
            
            # å¼‚æ­¥è®©LLMè¿›è¡Œæ¨ç†å’Œå†³ç­–
            shared_data = prep_result.get("shared_data", {})
            decision = await self._make_decision_async(system_prompt, state_info, shared_data)
            
            print(f"ğŸ¯ ReActå†³ç­–: {decision.get('next_action', 'unknown')}")
            print(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {decision.get('reasoning', '')}")
            
            return {
                "user_message": decision.get("user_message", "æˆ‘æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚..."),
                "next_action": decision.get("next_action", "user_interaction"),
                "reasoning": decision.get("reasoning", "ç»§ç»­å¤„ç†ç”¨æˆ·è¯·æ±‚"),
                "confidence": decision.get("confidence", 0.5),
                "requires_user_input": decision.get("requires_user_input", True),
                "decision_success": True
            }
            
        except Exception as e:
            return {"error": f"ReAct execution failed: {str(e)}"}
    
    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """å¼‚æ­¥æ›´æ–°å…±äº«çŠ¶æ€å¹¶è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹è·¯ç”±"""
        try:
            if "error" in exec_res:
                shared["react_error"] = exec_res["error"]
                return "error"

            # æ›´æ–°ReActå¾ªç¯è®¡æ•°
            react_cycles = shared.get("react_cycle_count", 0) + 1
            shared["react_cycle_count"] = react_cycles

            # æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
            user_message = exec_res.get("user_message", "")
            if user_message:
                shared.setdefault("dialogue_history", {}).setdefault("messages", []).append({
                    "timestamp": time.time(),
                    "role": "assistant",
                    "content": user_message,
                    "metadata": {
                        "agent_source": "react_orchestrator",
                        "reasoning": exec_res.get("reasoning", ""),
                        "confidence": exec_res.get("confidence", 0.5)
                    }
                })

            # æ ¹æ®å†³ç­–è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹è·¯ç”±ï¼ˆå‚è€ƒdemoçš„åŠ¨æ€è·¯ç”±ï¼‰
            next_action = exec_res.get("next_action", "user_interaction")

            # åŠ¨æ€è·¯ç”±åˆ°ç›¸åº”çš„AgentèŠ‚ç‚¹
            if next_action == "requirements_analysis":
                return "requirements_analysis"
            elif next_action == "short_planning":
                return "short_planning"
            elif next_action == "research":
                return "research"
            elif next_action == "architecture_design":
                return "architecture_design"
            elif next_action == "complete":
                return "complete"
            elif next_action == "user_interaction":
                return "wait_for_user"
            else:
                # å…¶ä»–æƒ…å†µï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥
                return "wait_for_user"

        except Exception as e:
            shared["react_post_error"] = str(e)
            return "error"
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºReActç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯GTPlannerçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œä½¿ç”¨ReActï¼ˆæ¨ç†-è¡ŒåŠ¨ï¼‰æ¨¡å¼å·¥ä½œã€‚

ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå½“å‰çŠ¶æ€ï¼Œè¿›è¡Œæ¨ç†ï¼Œå¹¶å†³å®šä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œä»€ä¹ˆè¡ŒåŠ¨ã€‚

å¯ç”¨çš„ä¸“ä¸šAgentï¼š
1. requirements_analysis - éœ€æ±‚åˆ†æAgentï¼ˆä»…å½“ç”¨æˆ·æ˜ç¡®æå‡ºå…·ä½“é¡¹ç›®éœ€æ±‚æ—¶ä½¿ç”¨ï¼‰
2. short_planning - çŸ­è§„åˆ’Agentï¼ˆä»…å½“éœ€æ±‚åˆ†æå®Œæˆä¸”éœ€è¦ç”Ÿæˆè§„åˆ’æ–‡æ¡£æ—¶ä½¿ç”¨ï¼‰
3. research - ç ”ç©¶è°ƒç ”Agentï¼ˆä»…å½“éœ€è¦è°ƒç ”ç‰¹å®šæŠ€æœ¯æˆ–æ–¹æ¡ˆæ—¶ä½¿ç”¨ï¼‰
4. architecture_design - æ¶æ„è®¾è®¡Agentï¼ˆä»…å½“éœ€è¦è®¾è®¡å…·ä½“ç³»ç»Ÿæ¶æ„æ—¶ä½¿ç”¨ï¼‰
5. user_interaction - ç”¨æˆ·äº¤äº’ï¼ˆç”¨äºä¸€èˆ¬å¯¹è¯ã€é—®å€™ã€æ¾„æ¸…é—®é¢˜ï¼‰
6. complete - ä»»åŠ¡å®Œæˆ

é‡è¦å†³ç­–åŸåˆ™ï¼š
1. **ä¿å®ˆåŸåˆ™**ï¼šå¦‚æœä¸ç¡®å®šæ˜¯å¦éœ€è¦è°ƒç”¨ä¸“ä¸šAgentï¼Œä¼˜å…ˆé€‰æ‹©user_interaction
2. **éœ€æ±‚é©±åŠ¨**ï¼šåªæœ‰åœ¨ç”¨æˆ·æ˜ç¡®è¡¨è¾¾é¡¹ç›®éœ€æ±‚æ—¶æ‰è°ƒç”¨requirements_analysis
3. **é¿å…è¿‡åº¦å¤„ç†**ï¼šç®€å•é—®å€™ã€ä»‹ç»ã€æ¾„æ¸…é—®é¢˜éƒ½åº”è¯¥ä½¿ç”¨user_interaction
4. **ç”¨æˆ·ä½“éªŒä¼˜å…ˆ**ï¼šé¿å…ä¸å¿…è¦çš„ç­‰å¾…å’Œå¤æ‚å¤„ç†

è¯·è¿”å›ç®€æ´çš„JSONæ ¼å¼ï¼š
{
    "user_message": "ç”¨è‡ªç„¶ã€å‹å¥½çš„è¯­è¨€ä¸ç”¨æˆ·å¯¹è¯",
    "next_action": "requirements_analysis|short_planning|research|architecture_design|user_interaction|complete",
    "reasoning": "ç®€è¦è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªè¡ŒåŠ¨",
    "confidence": 0.8,
    "requires_user_input": true/false
}"""
    
    def _build_state_description(self, shared: Dict[str, Any], user_message: str) -> str:
        """æ„å»ºå½“å‰çŠ¶æ€æè¿°"""
        # åˆ†æå·²å®Œæˆçš„ä»»åŠ¡
        completed_tasks = []
        if shared.get("structured_requirements"):
            completed_tasks.append("requirements_analysis")
        if shared.get("confirmation_document"):
            completed_tasks.append("short_planning")
        if shared.get("research_findings"):
            completed_tasks.append("research")
        if shared.get("agent_design_document"):
            completed_tasks.append("architecture_design")
        
        # åˆ†ææ•°æ®å®Œæ•´æ€§
        requirements_complete = bool(shared.get("structured_requirements", {}).get("project_overview"))
        research_complete = bool(shared.get("research_findings", {}).get("topics"))
        architecture_complete = bool(shared.get("agent_design_document"))
        
        # è®¡ç®—å¤„ç†è½®æ¬¡
        react_cycles = shared.get("react_cycle_count", 0)
        
        description = f"""
å½“å‰çŠ¶æ€åˆ†æï¼š

ç”¨æˆ·æœ€æ–°æ¶ˆæ¯: {user_message}

å·²å®Œæˆçš„ä»»åŠ¡: {', '.join(completed_tasks) if completed_tasks else 'æ— '}

æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:
- éœ€æ±‚åˆ†æ: {'âœ… å·²å®Œæˆ' if requirements_complete else 'âŒ æœªå®Œæˆ'}
- çŸ­è§„åˆ’æ–‡æ¡£: {'âœ… å·²å®Œæˆ' if shared.get("confirmation_document") else 'âŒ æœªå®Œæˆ'}
- ç ”ç©¶è°ƒç ”: {'âœ… å·²å®Œæˆ' if research_complete else 'âŒ æœªå®Œæˆ'}
- æ¶æ„è®¾è®¡: {'âœ… å·²å®Œæˆ' if architecture_complete else 'âŒ æœªå®Œæˆ'}

å¤„ç†è¿›åº¦:
- ReActå¾ªç¯æ¬¡æ•°: {react_cycles}
- å½“å‰é˜¶æ®µ: {shared.get("current_stage", "initialization")}
- å¯¹è¯æ¶ˆæ¯æ•°: {len(shared.get("dialogue_history", {}).get("messages", []))}

Agentè°ƒç”¨å¯è¡Œæ€§æ£€æŸ¥:
- requirements_analysis: {'âœ… å¯è°ƒç”¨' if user_message else 'âŒ ç¼ºå°‘ç”¨æˆ·è¾“å…¥'}
- short_planning: {'âœ… å¯è°ƒç”¨' if requirements_complete else 'âŒ éœ€è¦å…ˆå®Œæˆéœ€æ±‚åˆ†æ'}
- research: {'âœ… å¯è°ƒç”¨' if requirements_complete else 'âŒ éœ€è¦å…ˆå®Œæˆéœ€æ±‚åˆ†æ'}
- architecture_design: {'âœ… å¯è°ƒç”¨' if (requirements_complete and research_complete) else 'âŒ éœ€è¦å…ˆå®Œæˆéœ€æ±‚åˆ†æå’Œç ”ç©¶'}

è¯·åˆ†æå½“å‰çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œä»€ä¹ˆä»»åŠ¡ã€‚

å†³ç­–ä¼˜å…ˆçº§ï¼š
1. é¦–å…ˆåˆ¤æ–­ç”¨æˆ·æ„å›¾ï¼ˆæ˜¯å¦æœ‰å…·ä½“é¡¹ç›®éœ€æ±‚ï¼‰
2. æ£€æŸ¥Agentè°ƒç”¨å¯è¡Œæ€§
3. æ ¹æ®æ•°æ®å®Œæ•´æ€§é€‰æ‹©æœ€åˆé€‚çš„è¡ŒåŠ¨
4. ä¼˜å…ˆé€‰æ‹©ç”¨æˆ·äº¤äº’ï¼Œé™¤éæ˜ç¡®éœ€è¦ä¸“ä¸šå¤„ç†
"""
        return description
    
    async def _make_decision_async(self, system_prompt: str, state_description: str, shared: Dict[str, Any] = None) -> Dict:
        """å¼‚æ­¥ä½¿ç”¨LLMè¿›è¡Œå†³ç­–ï¼Œæ”¯æŒæµå¼è¾“å‡º"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æµå¼å›è°ƒ
            stream_callback = shared.get("_stream_callback") if shared else None

            if stream_callback:
                # ä½¿ç”¨æµå¼è°ƒç”¨
                return await self._make_decision_with_stream_async(system_prompt, state_description, stream_callback)
            else:
                # ä½¿ç”¨æ™®é€šè°ƒç”¨
                result = call_llm(
                    prompt=f"{system_prompt}\n\n{state_description}",
                    is_json=True
                )

                # ç¡®ä¿è¿”å›çš„æ˜¯å­—å…¸æ ¼å¼
                if isinstance(result, str):
                    result = json.loads(result)

                return result

        except Exception as e:
            print(f"âŒ ReActå†³ç­–å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çš„å®‰å…¨å†³ç­–
            return {
                "user_message": "æˆ‘æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨ç­‰...",
                "next_action": "user_interaction",
                "reasoning": f"LLMå†³ç­–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤äº¤äº’æ¨¡å¼: {str(e)}",
                "confidence": 0.3,
                "requires_user_input": True
            }

    async def _make_decision_with_stream_async(self, system_prompt: str, state_description: str, stream_callback) -> Dict:
        """å¼‚æ­¥æµå¼LLMè°ƒç”¨è¿›è¡Œå†³ç­–"""
        try:
            from utils.json_stream_parser import JSONStreamParser
            from call_llm import call_llm_stream_async

            # åˆ›å»ºJSONæµå¼è§£æå™¨
            parser = JSONStreamParser()
            collected_data = {}
            user_message_buffer = ""

            def on_field_update(field_path: str, new_content: str, is_complete: bool):
                nonlocal user_message_buffer, collected_data

                # å¤„ç†user_messageå­—æ®µçš„æµå¼è¾“å‡º
                if field_path == "user_message":
                    user_message_buffer += new_content

                    # å‘é€æ–°å¢å†…å®¹ç»™CLI
                    if stream_callback and len(new_content) > 0:
                        try:
                            stream_data = {
                                "user_message": new_content,
                                "field_path": field_path,
                                "is_complete": is_complete
                            }
                            stream_callback(stream_data, new_content)
                        except Exception as e:
                            print(f"âš ï¸ æµå¼å›è°ƒå¤±è´¥: {e}")

                # æ”¶é›†å®Œæ•´å­—æ®µæ•°æ®
                if is_complete:
                    collected_data[field_path] = user_message_buffer

            # è®¾ç½®è§£æå™¨å›è°ƒ
            parser.subscribe_field("user_message", on_field_update)

            # å¼‚æ­¥è°ƒç”¨æµå¼LLM
            prompt = f"{system_prompt}\n\n{state_description}"

            async for chunk in call_llm_stream_async(prompt):
                if chunk:
                    parser.add_chunk(chunk)

            # è·å–æœ€ç»ˆç»“æœ
            final_result = parser.get_result()

            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "user_message": collected_data.get("user_message", user_message_buffer),
                "next_action": final_result.get("next_action", "user_interaction"),
                "reasoning": final_result.get("reasoning", "æµå¼å¤„ç†å®Œæˆ"),
                "confidence": float(final_result.get("confidence", 0.5)),
                "requires_user_input": final_result.get("requires_user_input", True)
            }

            return result

        except Exception as e:
            print(f"âŒ å¼‚æ­¥æµå¼å†³ç­–å¤±è´¥: {e}")
            return {
                "user_message": "æˆ‘æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨ç­‰...",
                "next_action": "user_interaction",
                "reasoning": f"å¼‚æ­¥æµå¼å¤„ç†å¤±è´¥: {str(e)}",
                "confidence": 0.3,
                "requires_user_input": True
            }
    

