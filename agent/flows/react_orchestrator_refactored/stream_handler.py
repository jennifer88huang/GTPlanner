"""
æµå¼å¤„ç†å™¨

è´Ÿè´£å¤„ç†æµå¼Function Callingï¼Œæä¾›å®æ—¶åé¦ˆå’Œè¿›åº¦æ˜¾ç¤ºã€‚
"""

import json
import asyncio
from typing import Dict, List, Any, Optional, Callable
from utils.openai_client import get_openai_client
from .constants import LogMessages, MessageRoles
from .tool_executor import ToolExecutor
from .message_builder import MessageBuilder


class StreamHandler:
    """æµå¼å¤„ç†å™¨ç±»"""
    
    def __init__(self, available_tools: List[Dict], tool_executor: ToolExecutor):
        self.available_tools = available_tools
        self.tool_executor = tool_executor
        self.openai_client = get_openai_client()
        self.message_builder = MessageBuilder()
    
    async def execute_with_function_calling_stream(
        self,
        messages: List[Dict[str, str]],
        stream_callback: Callable,
        shared_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨æµå¼Function Callingæ‰§è¡ŒReActé€»è¾‘
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            stream_callback: æµå¼å›è°ƒå‡½æ•°
            shared_data: å…±äº«æ•°æ®
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            print(f"ğŸ” [DEBUG] StreamHandlerå¼€å§‹æ‰§è¡Œ...")
            print(f"ğŸ” [DEBUG] æ¶ˆæ¯æ•°é‡: {len(messages)}, å·¥å…·æ•°é‡: {len(self.available_tools)}")

            # è°ƒè¯•ï¼šæ£€æŸ¥å·¥å…·å®šä¹‰
            for i, tool in enumerate(self.available_tools):
                tool_name = tool.get('function', {}).get('name', 'unknown')
                print(f"ğŸ” [DEBUG] å·¥å…·{i+1}: {tool_name}")

            # ç¬¬ä¸€æ­¥ï¼šæµå¼è·å–LLMçš„åˆå§‹å“åº”å’Œå·¥å…·è°ƒç”¨å†³ç­–
            if stream_callback:
                await stream_callback(LogMessages.STREAM_ANALYZING_REQUEST + "\n")

            # ä½¿ç”¨æµå¼è°ƒç”¨è·å–å“åº”
            print(f"ğŸ” [DEBUG] å¼€å§‹è°ƒç”¨OpenAIæµå¼API...")
            response = await self.openai_client.chat_completion_async(
                messages=messages,
                tools=self.available_tools,
                tool_choice="auto",
                parallel_tool_calls=True,
                stream=True  # å¯ç”¨æµå¼å“åº”
            )
            print(f"ğŸ” [DEBUG] OpenAIæµå¼APIè°ƒç”¨æˆåŠŸ")
            
            # å¤„ç†æµå¼å“åº”
            print(f"ğŸ” [DEBUG] å¼€å§‹å¤„ç†æµå¼å“åº”...")
            collected_content, tool_calls_detected = await self._process_stream_response(
                response, stream_callback
            )
            print(f"ğŸ” [DEBUG] æµå¼å“åº”å¤„ç†å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(collected_content)}, å·¥å…·è°ƒç”¨æ•°: {len(tool_calls_detected)}")
            
            # ç¬¬äºŒæ­¥ï¼šå¦‚æœæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œè¿›è¡Œæµå¼å·¥å…·æ‰§è¡Œ
            tool_results = []
            if tool_calls_detected:
                if stream_callback:
                    await stream_callback(
                        f"\n\n{LogMessages.STREAM_TOOL_EXECUTION_START.format(len(tool_calls_detected))}\n"
                    )
                
                # å¹¶è¡Œæ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œæä¾›å®æ—¶åé¦ˆ
                tool_results = await self._execute_tools_with_stream_feedback(
                    tool_calls_detected, stream_callback
                )
            
            # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœæœ‰å·¥å…·ç»“æœï¼Œè·å–æœ€ç»ˆå“åº”
            final_user_message = await self._get_final_response(
                messages, collected_content, tool_calls_detected, 
                tool_results, stream_callback
            )
            
            # æ„å»ºè¿”å›ç»“æœ
            return {
                "user_message": final_user_message,
                "tool_calls": tool_results,
                "next_action": self._determine_next_action_from_tools(tool_results),
                "decision_success": True,
                "execution_mode": "stream_advanced",
                "collected_content": collected_content
            }
            
        except Exception as e:
            print(f"âŒ æµå¼Function Callingæ‰§è¡Œå¤±è´¥: {e}")
            if stream_callback:
                await stream_callback(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {str(e)}\n")
            
            return {
                "error": f"Stream function calling failed: {str(e)}",
                "user_message": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
                "next_action": "user_interaction",
                "decision_success": False,
                "execution_mode": "stream_error"
            }
    
    async def _process_stream_response(
        self, 
        response, 
        stream_callback: Optional[Callable]
    ) -> tuple[str, List[Any]]:
        """
        å¤„ç†æµå¼å“åº”
        
        Args:
            response: OpenAIæµå¼å“åº”
            stream_callback: æµå¼å›è°ƒå‡½æ•°
            
        Returns:
            (æ”¶é›†çš„å†…å®¹, æ£€æµ‹åˆ°çš„å·¥å…·è°ƒç”¨)
        """
        collected_content = ""
        tool_calls_detected = []
        
        if hasattr(response, '__aiter__'):
            # å¤„ç†æµå¼å“åº”
            # print("ğŸ” [DEBUG] å¼€å§‹å¤„ç†æµå¼å“åº”")
            async for chunk in response:
                if hasattr(chunk, 'choices') and chunk.choices:
                    choice = chunk.choices[0]
                    delta = choice.delta

                    # å¤„ç†å†…å®¹æµ
                    if hasattr(delta, 'content') and delta.content:
                        collected_content += delta.content
                        # print(f"ğŸ” [DEBUG] æµå¼å†…å®¹ç‰‡æ®µ: '{delta.content}'")
                        if stream_callback:
                            await stream_callback(delta.content)

                    # æ£€æµ‹å·¥å…·è°ƒç”¨
                    if hasattr(delta, 'tool_calls') and delta.tool_calls:
                        # print(f"ğŸ” [DEBUG] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ç‰‡æ®µ: {len(delta.tool_calls)}")
                        for tool_call in delta.tool_calls:
                            if hasattr(tool_call, 'function'):
                                # print(f"ğŸ” [DEBUG] å·¥å…·è°ƒç”¨: {tool_call.function.name if tool_call.function.name else 'æœªçŸ¥'}")
                                tool_calls_detected.append(tool_call)
        else:
            # éæµå¼å“åº”çš„å›é€€å¤„ç†
            choice = response.choices[0]
            message = choice.message
            if message.content:
                collected_content = message.content
                if stream_callback:
                    await stream_callback(collected_content)
            if hasattr(message, 'tool_calls') and message.tool_calls:
                tool_calls_detected = message.tool_calls
        
        # print(f"ğŸ” [DEBUG] æµå¼å“åº”å¤„ç†å®Œæˆ:")
        # print(f"ğŸ” [DEBUG] - æ”¶é›†çš„å†…å®¹é•¿åº¦: {len(collected_content)}")
        # print(f"ğŸ” [DEBUG] - æ”¶é›†çš„å†…å®¹: '{collected_content[:100]}{'...' if len(collected_content) > 100 else ''}'")
        # print(f"ğŸ” [DEBUG] - æ£€æµ‹åˆ°çš„å·¥å…·è°ƒç”¨æ•°é‡: {len(tool_calls_detected)}")
        # for i, tool_call in enumerate(tool_calls_detected):
        #     if hasattr(tool_call, 'function') and tool_call.function:
        #         print(f"ğŸ” [DEBUG] - å·¥å…·{i+1}: {tool_call.function.name}")
        # print("ğŸ” [DEBUG] " + "=" * 50)

        return collected_content, tool_calls_detected
    
    async def _execute_tools_with_stream_feedback(
        self,
        tool_calls: List[Any],
        stream_callback: Optional[Callable]
    ) -> List[Dict[str, Any]]:
        """
        å¹¶è¡Œæ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶æä¾›æµå¼åé¦ˆ
        
        Args:
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            stream_callback: æµå¼å›è°ƒå‡½æ•°
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        tool_results = []
        
        # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨åˆ›å»ºæ‰§è¡Œä»»åŠ¡
        tasks = []
        for i, tool_call in enumerate(tool_calls):
            if hasattr(tool_call, 'function'):
                function = tool_call.function
                tool_name = getattr(function, 'name', 'unknown')
                arguments_str = getattr(function, 'arguments', '{}')
                call_id = getattr(tool_call, 'id', f"call_{i}")
                
                try:
                    arguments = json.loads(arguments_str) if arguments_str else {}
                except json.JSONDecodeError:
                    arguments = {}
                
                # åˆ›å»ºå·¥å…·æ‰§è¡Œä»»åŠ¡
                task = self.tool_executor._execute_single_tool_with_stream_feedback(
                    call_id, tool_name, arguments, stream_callback
                )
                tasks.append(task)
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        if tasks:
            tool_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            processed_results = []
            for result in tool_results:
                if isinstance(result, Exception):
                    processed_results.append({
                        "tool_name": "unknown",
                        "arguments": {},
                        "result": {"success": False, "error": str(result)},
                        "call_id": "error",
                        "success": False
                    })
                else:
                    processed_results.append(result)
            
            tool_results = processed_results
        
        return tool_results
    
    async def _get_final_response(
        self,
        messages: List[Dict],
        collected_content: str,
        tool_calls_detected: List[Any],
        tool_results: List[Dict[str, Any]],
        stream_callback: Optional[Callable]
    ) -> str:
        """
        è·å–æœ€ç»ˆå“åº”
        
        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
            collected_content: æ”¶é›†çš„å†…å®¹
            tool_calls_detected: æ£€æµ‹åˆ°çš„å·¥å…·è°ƒç”¨
            tool_results: å·¥å…·æ‰§è¡Œç»“æœ
            stream_callback: æµå¼å›è°ƒå‡½æ•°
            
        Returns:
            æœ€ç»ˆç”¨æˆ·æ¶ˆæ¯
        """
        final_user_message = collected_content
        
        if tool_results:
            # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„æ¶ˆæ¯
            messages_with_results = self.message_builder.build_tool_result_messages(
                messages, collected_content, tool_calls_detected, tool_results
            )
            
            # è·å–æœ€ç»ˆå“åº”
            if stream_callback:
                await stream_callback(f"\n{LogMessages.STREAM_ORGANIZING_RESULTS}\n")
            
            final_response = await self.openai_client.chat_completion_async(
                messages=messages_with_results,
                stream=True
            )
            
            # æµå¼è¾“å‡ºæœ€ç»ˆå“åº”
            if stream_callback:
                await stream_callback(f"\n{LogMessages.STREAM_FINAL_RESPONSE}")
            
            final_content = ""
            if hasattr(final_response, '__aiter__'):
                async for chunk in final_response:
                    if hasattr(chunk, 'choices') and chunk.choices:
                        choice = chunk.choices[0]
                        delta = choice.delta
                        if hasattr(delta, 'content') and delta.content:
                            final_content += delta.content
                            if stream_callback:
                                await stream_callback(delta.content)
            else:
                choice = final_response.choices[0]
                final_content = choice.message.content or ""
                if stream_callback:
                    await stream_callback(final_content)
            
            final_user_message = final_content
        
        return final_user_message
    
    def _determine_next_action_from_tools(self, tool_results: List[Dict[str, Any]]) -> str:
        """
        æ ¹æ®å·¥å…·æ‰§è¡Œç»“æœç¡®å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        
        Args:
            tool_results: å·¥å…·æ‰§è¡Œç»“æœåˆ—è¡¨
            
        Returns:
            ä¸‹ä¸€æ­¥è¡ŒåŠ¨ç±»å‹
        """
        if not tool_results:
            return "user_interaction"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œå¤±è´¥
        failed_tools = [tr for tr in tool_results if not tr.get("success", False)]
        if failed_tools:
            # å¦‚æœæœ‰å·¥å…·å¤±è´¥ï¼Œä½†ä¸æ˜¯å…¨éƒ¨å¤±è´¥ï¼Œç»§ç»­ç”¨æˆ·äº¤äº’
            if len(failed_tools) < len(tool_results):
                return "user_interaction"
            else:
                # å…¨éƒ¨å¤±è´¥ï¼Œå¯èƒ½éœ€è¦é‡è¯•æˆ–ç”¨æˆ·äº¤äº’
                return "user_interaction"
        
        # æ‰€æœ‰å·¥å…·éƒ½æˆåŠŸæ‰§è¡Œï¼Œç»§ç»­ç”¨æˆ·äº¤äº’
        return "user_interaction"
