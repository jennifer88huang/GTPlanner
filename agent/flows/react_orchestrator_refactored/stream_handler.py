"""
æµå¼å¤„ç†å™¨

è´Ÿè´£å¤„ç†æµå¼Function Callingï¼Œæä¾›å®æ—¶åé¦ˆå’Œè¿›åº¦æ˜¾ç¤ºã€‚
"""

import json
import asyncio
from typing import Dict, List, Any, Optional, Callable
from utils.openai_client import get_openai_client
from .constants import MessageRoles
from .tool_executor import ToolExecutor
from .message_builder import MessageBuilder


class StreamHandler:
    """æµå¼å¤„ç†å™¨ç±»"""
    
    def __init__(self, available_tools: List[Dict], tool_executor: ToolExecutor):
        self.available_tools = available_tools
        self.tool_executor = tool_executor
        self.openai_client = get_openai_client()
        self.message_builder = MessageBuilder()
    
    async def execute_with_function_calling_stream(
        self,
        messages: List[Dict[str, str]],
        stream_callback: Callable,
        shared_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨æµå¼Function Callingæ‰§è¡ŒReActé€»è¾‘
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            stream_callback: æµå¼å›è°ƒå‡½æ•°
            shared_data: å…±äº«æ•°æ®
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            # ç¬¬ä¸€æ­¥ï¼šæµå¼è·å–LLMçš„åˆå§‹å“åº”å’Œå·¥å…·è°ƒç”¨å†³ç­–

            # ä½¿ç”¨æµå¼è°ƒç”¨è·å–å“åº”
            response = await self.openai_client.chat_completion_async(
                messages=messages,
                tools=self.available_tools,
                tool_choice="auto",
                parallel_tool_calls=True,
                stream=True  # å¯ç”¨æµå¼å“åº”
            )
            
            # å¤„ç†æµå¼å“åº”
            initial_response, tool_calls_detected, tool_calls_buffer = await self._process_stream_response(
                response, stream_callback
            )

          
            # ğŸ”§ æ–°å¢ï¼šéªŒè¯å·¥å…·è°ƒç”¨æ ¼å¼
            if tool_calls_detected:
                self._validate_tool_calls(tool_calls_detected)
            
            # ç¬¬äºŒæ­¥ï¼šå¦‚æœæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œè¿›è¡Œæµå¼å·¥å…·æ‰§è¡Œ
            tool_results = []
            if tool_calls_detected:
                # å¹¶è¡Œæ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ŒçŠ¶æ€æ ‡è®°åœ¨æ‰§è¡Œå™¨å†…éƒ¨å‘é€
                tool_results = await self._execute_tools_with_stream_feedback(
                    tool_calls_detected, stream_callback
                )
          
            
            # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœæœ‰å·¥å…·ç»“æœï¼Œè·å–æœ€ç»ˆå“åº”
            final_user_message = await self._get_final_response(
                messages, initial_response, tool_calls_detected,
                tool_results, stream_callback
            )
            
            # æ„å»ºè¿”å›ç»“æœ
            return {
                "user_message": final_user_message,  # æœ€ç»ˆçš„AIå›å¤ï¼ˆå¯èƒ½åŸºäºå·¥å…·ç»“æœï¼‰
                "tool_calls": tool_results,
                "decision_success": True,
                "execution_mode": "stream_advanced",
                "initial_response": initial_response  # é‡å‘½åï¼šAIçš„åˆå§‹å“åº”ï¼ˆå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨å†³ç­–ï¼‰
            }
            
        except Exception as e:
            print(f"âŒ æµå¼Function Callingæ‰§è¡Œå¤±è´¥: {e}")
            if stream_callback:
                await stream_callback(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {str(e)}\n")
            
            return {
                "error": f"Stream function calling failed: {str(e)}",
                "user_message": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
                "decision_success": False,
                "execution_mode": "stream_error"
            }
    
    async def _process_stream_response(
        self,
        response,
        stream_callback: Optional[Callable]
    ) -> tuple[str, List[Any], Dict]:
        """
        å¤„ç†æµå¼å“åº”

        Args:
            response: OpenAIæµå¼å“åº”
            stream_callback: æµå¼å›è°ƒå‡½æ•°

        Returns:
            (æ”¶é›†çš„å†…å®¹, æ£€æµ‹åˆ°çš„å·¥å…·è°ƒç”¨, å·¥å…·è°ƒç”¨ç¼“å†²åŒº)
        """
        initial_response = ""
        tool_calls_detected = []
        tool_calls_buffer = {}  # ç”¨äºç´¯ç§¯æµå¼å·¥å…·è°ƒç”¨

      
        if hasattr(response, '__aiter__'):
            # å¤„ç†æµå¼å“åº”
            async for chunk in response:
                if hasattr(chunk, 'choices') and chunk.choices:
                    choice = chunk.choices[0]
                    delta = choice.delta

                    # å¤„ç†å†…å®¹æµ
                    if hasattr(delta, 'content') and delta.content:
                        initial_response += delta.content
                        if stream_callback:
                            await stream_callback(delta.content)

                    # æ£€æµ‹å·¥å…·è°ƒç”¨ï¼ˆæµå¼ç´¯ç§¯ï¼‰
                    if hasattr(delta, 'tool_calls') and delta.tool_calls:
                        for tool_call_delta in delta.tool_calls:
                            if hasattr(tool_call_delta, 'index'):
                                index = tool_call_delta.index

                                # åˆå§‹åŒ–æˆ–æ›´æ–°å·¥å…·è°ƒç”¨ç¼“å†²åŒº
                                if index not in tool_calls_buffer:
                                    tool_calls_buffer[index] = {
                                        'id': getattr(tool_call_delta, 'id', f'call_{index}'),
                                        'function': {
                                            'name': '',
                                            'arguments': ''
                                        }
                                    }

                                # ç´¯ç§¯å·¥å…·è°ƒç”¨ä¿¡æ¯
                                if hasattr(tool_call_delta, 'function') and tool_call_delta.function:
                                    func_delta = tool_call_delta.function
                                    if hasattr(func_delta, 'name') and func_delta.name:
                                        tool_calls_buffer[index]['function']['name'] = func_delta.name
                                    if hasattr(func_delta, 'arguments') and func_delta.arguments:
                                        tool_calls_buffer[index]['function']['arguments'] += func_delta.arguments

            # è½¬æ¢ç¼“å†²åŒºä¸ºæœ€ç»ˆçš„å·¥å…·è°ƒç”¨åˆ—è¡¨
            for index, tool_call_data in tool_calls_buffer.items():
                # åˆ›å»ºæ¨¡æ‹Ÿçš„å·¥å…·è°ƒç”¨å¯¹è±¡
                class MockToolCall:
                    def __init__(self, data):
                        self.id = data['id']
                        self.function = MockFunction(data['function'])

                class MockFunction:
                    def __init__(self, func_data):
                        self.name = func_data['name']
                        self.arguments = func_data['arguments']

                if tool_call_data['function']['name']:  # åªæ·»åŠ æœ‰åç§°çš„å·¥å…·è°ƒç”¨
                    tool_calls_detected.append(MockToolCall(tool_call_data))
        else:
            # éæµå¼å“åº”çš„å›é€€å¤„ç†
            choice = response.choices[0]
            message = choice.message
            if message.content:
                initial_response = message.content
                if stream_callback:
                    await stream_callback(initial_response)
            if hasattr(message, 'tool_calls') and message.tool_calls:
                tool_calls_detected = message.tool_calls

        return initial_response, tool_calls_detected, tool_calls_buffer

    def _validate_tool_calls(self, tool_calls: List[Any]) -> None:
        """
        éªŒè¯å·¥å…·è°ƒç”¨æ ¼å¼çš„æ­£ç¡®æ€§

        Args:
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        for i, tc in enumerate(tool_calls):
            if not hasattr(tc, 'id'):
                print(f"âš ï¸ [StreamHandler] å·¥å…·è°ƒç”¨{i}ç¼ºå°‘idå±æ€§")
            if not hasattr(tc, 'function'):
                print(f"âš ï¸ [StreamHandler] å·¥å…·è°ƒç”¨{i}ç¼ºå°‘functionå±æ€§")
                continue
            if not hasattr(tc.function, 'name'):
                print(f"âš ï¸ [StreamHandler] å·¥å…·è°ƒç”¨{i}çš„functionç¼ºå°‘nameå±æ€§")
            if not hasattr(tc.function, 'arguments'):
                print(f"âš ï¸ [StreamHandler] å·¥å…·è°ƒç”¨{i}çš„functionç¼ºå°‘argumentså±æ€§")
            else:
                # éªŒè¯argumentsæ˜¯å¦ä¸ºæœ‰æ•ˆJSON
                try:
                    import json
                    json.loads(tc.function.arguments)
                except json.JSONDecodeError:
                    print(f"âš ï¸ [StreamHandler] å·¥å…·è°ƒç”¨{i}çš„argumentsä¸æ˜¯æœ‰æ•ˆJSON: {tc.function.arguments}")

    async def _execute_tools_with_stream_feedback(
        self,
        tool_calls: List[Any],
        stream_callback: Optional[Callable]
    ) -> List[Dict[str, Any]]:
        """
        å¹¶è¡Œæ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶æä¾›æµå¼åé¦ˆ
        
        Args:
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            stream_callback: æµå¼å›è°ƒå‡½æ•°
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        tool_results = []
        
        # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨åˆ›å»ºæ‰§è¡Œä»»åŠ¡
        tasks = []
        for i, tool_call in enumerate(tool_calls):
            if hasattr(tool_call, 'function'):
                function = tool_call.function
                tool_name = getattr(function, 'name', 'unknown')
                arguments_str = getattr(function, 'arguments', '{}')
                call_id = getattr(tool_call, 'id', f"call_{i}")

                try:
                    arguments = json.loads(arguments_str) if arguments_str else {}
                except json.JSONDecodeError:
                    arguments = {}

                # å‘é€å·¥å…·å¼€å§‹çŠ¶æ€
                if stream_callback and tool_name != 'unknown':
                    await stream_callback(f"__TOOL_START__{tool_name}")

                # åˆ›å»ºå·¥å…·æ‰§è¡Œä»»åŠ¡
                task = self._execute_single_tool_with_status(
                    call_id, tool_name, arguments, stream_callback
                )
                tasks.append(task)
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        if tasks:
            tool_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            processed_results = []
            for result in tool_results:
                if isinstance(result, Exception):
                    processed_results.append({
                        "tool_name": "unknown",
                        "arguments": {},
                        "result": {"success": False, "error": str(result)},
                        "call_id": "error",
                        "success": False
                    })
                else:
                    processed_results.append(result)
            
            tool_results = processed_results
        
        return tool_results
    
    async def _get_final_response(
        self,
        messages: List[Dict],
        initial_response: str,
        tool_calls_detected: List[Any],
        tool_results: List[Dict[str, Any]],
        stream_callback: Optional[Callable]
    ) -> str:
        """
        è·å–æœ€ç»ˆå“åº”
        
        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
            initial_response: AIçš„åˆå§‹å“åº”å†…å®¹
            tool_calls_detected: æ£€æµ‹åˆ°çš„å·¥å…·è°ƒç”¨
            tool_results: å·¥å…·æ‰§è¡Œç»“æœ
            stream_callback: æµå¼å›è°ƒå‡½æ•°

        Returns:
            æœ€ç»ˆç”¨æˆ·æ¶ˆæ¯
        """
        final_user_message = initial_response
        
        if tool_results:
            # å‘é€æ–°å›å¤æ®µè½å¼€å§‹æ ‡è®°
            if stream_callback:
                await stream_callback("__NEW_AI_REPLY__")

            # ğŸ”§ ä¿®å¤ï¼šç›´æ¥æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„æ¶ˆæ¯
            messages_with_results = messages.copy()

            # æ·»åŠ åŠ©æ‰‹çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
            assistant_message = {
                "role": "assistant",
                "content": initial_response
            }

            if tool_calls_detected:
                assistant_message["tool_calls"] = [
                    {
                        "id": getattr(tc, 'id', f"call_{i}"),
                        "type": "function",
                        "function": {
                            "name": getattr(tc.function, 'name', 'unknown'),
                            "arguments": getattr(tc.function, 'arguments', '{}')
                        }
                    } for i, tc in enumerate(tool_calls_detected)
                ]

            messages_with_results.append(assistant_message)

            # æ·»åŠ å·¥å…·ç»“æœæ¶ˆæ¯
            for tool_result in tool_results:
                import json
                messages_with_results.append({
                    "role": "tool",
                    "tool_call_id": tool_result.get("call_id", "unknown"),
                    "content": json.dumps(tool_result.get("result", {}), ensure_ascii=False)
                })

            # è·å–æœ€ç»ˆå“åº”
            final_response = await self.openai_client.chat_completion_async(
                messages=messages_with_results,
                stream=True
            )

            # æµå¼è¾“å‡ºæœ€ç»ˆå“åº”
            final_content = ""
            if hasattr(final_response, '__aiter__'):
                async for chunk in final_response:
                    if hasattr(chunk, 'choices') and chunk.choices:
                        choice = chunk.choices[0]
                        delta = choice.delta
                        if hasattr(delta, 'content') and delta.content:
                            final_content += delta.content
                            if stream_callback:
                                await stream_callback(delta.content)
            else:
                choice = final_response.choices[0]
                final_content = choice.message.content or ""
                if stream_callback:
                    await stream_callback(final_content)

            final_user_message = final_content
        
        return final_user_message

    async def _execute_single_tool_with_status(
        self,
        call_id: str,
        tool_name: str,
        arguments: Dict[str, Any],
        stream_callback: Optional[Callable]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªå·¥å…·å¹¶å‘é€çŠ¶æ€æ›´æ–°

        Args:
            call_id: è°ƒç”¨ID
            tool_name: å·¥å…·åç§°
            arguments: å·¥å…·å‚æ•°
            stream_callback: æµå¼å›è°ƒå‡½æ•°

        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        # æ‰§è¡Œå·¥å…·
        result = await self.tool_executor._execute_single_tool_with_stream_feedback(
            call_id, tool_name, arguments, stream_callback
        )

        # å‘é€å·¥å…·å®ŒæˆçŠ¶æ€
        if stream_callback:
            success = result.get("success", False)
            execution_time = result.get("execution_time", 0)
            await stream_callback(f"__TOOL_END__{tool_name}__{success}__{execution_time:.1f}")

        return result


