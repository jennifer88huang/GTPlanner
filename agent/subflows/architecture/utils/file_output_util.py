"""
Architecture Agent æ–‡ä»¶è¾“å‡ºå·¥å…·

æä¾›ç»Ÿä¸€çš„æ–‡ä»¶è¾“å‡ºåŠŸèƒ½ï¼Œåœ¨æ¯ä¸ªNodeçš„posté˜¶æ®µè°ƒç”¨ã€‚
æ ¹æ®é˜¶æ®µå’Œæ•°æ®è‡ªåŠ¨ç”Ÿæˆç›¸åº”çš„Markdownæ–‡ä»¶ã€‚
"""

import time
import json
from typing import Dict, Any, Optional


def generate_stage_file(stage: str, data: Any, shared: Dict[str, Any]) -> bool:
    """
    æ ¹æ®é˜¶æ®µç”Ÿæˆç›¸åº”çš„è¾“å‡ºæ–‡ä»¶
    
    Args:
        stage: é˜¶æ®µåç§° (agent_analysis, node_identification, flow_design, data_structure, node_design)
        data: è¯¥é˜¶æ®µçš„æ•°æ®
        shared: å…±äº«å˜é‡å­—å…¸
        
    Returns:
        bool: æ˜¯å¦æˆåŠŸç”Ÿæˆæ–‡ä»¶
    """
    try:
        # å¯¼å…¥NodeOutput
        from agent.nodes.node_output import NodeOutput
        
        # ç”Ÿæˆæ–‡ä»¶å†…å®¹
        filename = _get_filename(stage)
        content = _generate_content(stage, data)
        
        if not content:
            print(f"âš ï¸ {stage}é˜¶æ®µæ— å†…å®¹å¯ç”Ÿæˆ")
            return False
        
        # å‡†å¤‡æ–‡ä»¶æ•°æ®
        files_to_generate = [
            {
                "filename": filename,
                "content": content
            }
        ]
        
        # æ›´æ–°sharedå˜é‡
        shared["files_to_generate"] = files_to_generate
        
        # åˆ›å»ºNodeOutputå¹¶ç”Ÿæˆæ–‡ä»¶
        node_output = NodeOutput(output_dir="output")
        result = node_output.generate_files_directly(files_to_generate)
        
        if result["status"] == "success":
            # æ›´æ–°æˆ–åˆå§‹åŒ–ç”Ÿæˆçš„æ–‡ä»¶ä¿¡æ¯
            if "generated_files" not in shared:
                shared["generated_files"] = []
            shared["generated_files"].extend(result["generated_files"])
            shared["output_directory"] = result["output_directory"]
            
            print(f"ğŸ“„ {stage}é˜¶æ®µæ–‡ä»¶å·²ç”Ÿæˆ: {result['output_directory']}/{filename}")
            return True
        else:
            print(f"âš ï¸ {stage}é˜¶æ®µæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False
            
    except Exception as e:
        print(f"âš ï¸ {stage}é˜¶æ®µæ–‡ä»¶ç”Ÿæˆå‡ºé”™: {str(e)}")
        return False


def _get_filename(stage: str) -> str:
    """è·å–é˜¶æ®µå¯¹åº”çš„æ–‡ä»¶å"""
    filename_mapping = {
        "agent_analysis": "01_agent_analysis.md",
        "node_identification": "02_identified_nodes.md",
        "flow_design": "03_flow_design.md",
        "data_structure": "04_data_structure.md",
        "node_design": "05_node_design.md",
        "document_generation": "06_agent_design_complete.md"
    }
    return filename_mapping.get(stage, f"{stage}.md")


def _generate_content(stage: str, data: Any) -> str:
    """æ ¹æ®é˜¶æ®µå’Œæ•°æ®ç”Ÿæˆæ–‡ä»¶å†…å®¹"""
    if stage == "agent_analysis":
        return _generate_agent_analysis_content(data)
    elif stage == "node_identification":
        return _generate_node_identification_content(data)
    elif stage == "flow_design":
        return _generate_flow_design_content(data)
    elif stage == "data_structure":
        return _generate_data_structure_content(data)
    elif stage == "node_design":
        return _generate_node_design_content(data)
    elif stage == "document_generation":
        return data  # æ–‡æ¡£ç”Ÿæˆé˜¶æ®µç›´æ¥è¿”å›ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹
    else:
        return f"# {stage.title()} ç»“æœ\n\n```json\n{json.dumps(data, indent=2, ensure_ascii=False)}\n```"


def _generate_agent_analysis_content(agent_analysis: Dict[str, Any]) -> str:
    """ç”ŸæˆAgentåˆ†ææ–‡ä»¶å†…å®¹"""
    content = f"""# Agentéœ€æ±‚åˆ†æç»“æœ

## AgentåŸºæœ¬ä¿¡æ¯
- **Agentç±»å‹**: {agent_analysis.get('agent_type', 'Unknown')}
- **Agentç›®çš„**: {agent_analysis.get('agent_purpose', 'Unknown')}
- **å¤„ç†æ¨¡å¼**: {agent_analysis.get('processing_pattern', 'Unknown')}

## æ ¸å¿ƒåŠŸèƒ½
"""
    
    core_functions = agent_analysis.get('core_functions', [])
    for i, func in enumerate(core_functions, 1):
        if isinstance(func, dict):
            content += f"""
### {i}. {func.get('function_name', 'Unknown')}
- **æè¿°**: {func.get('description', '')}
- **å¤æ‚åº¦**: {func.get('complexity', 'Unknown')}
- **ä¼˜å…ˆçº§**: {func.get('priority', 'Unknown')}
"""
    
    content += f"""
## è¾“å…¥è¾“å‡ºç±»å‹
- **è¾“å…¥ç±»å‹**: {', '.join(agent_analysis.get('input_types', []))}
- **è¾“å‡ºç±»å‹**: {', '.join(agent_analysis.get('output_types', []))}

## æŠ€æœ¯æŒ‘æˆ˜
"""
    for challenge in agent_analysis.get('key_challenges', []):
        content += f"- {challenge}\n"
    
    content += f"""
## æˆåŠŸæ ‡å‡†
"""
    for criteria in agent_analysis.get('success_criteria', []):
        content += f"- {criteria}\n"
    
    content += f"""
---
*ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""
    return content


def _generate_node_identification_content(identified_nodes: list) -> str:
    """ç”ŸæˆNodeè¯†åˆ«æ–‡ä»¶å†…å®¹"""
    content = f"""# Nodeè¯†åˆ«ç»“æœ

## æ¦‚è¿°
åŸºäºAgentéœ€æ±‚åˆ†æï¼Œè¯†åˆ«å‡ºä»¥ä¸‹{len(identified_nodes)}ä¸ªNodeï¼š

"""
    
    for i, node in enumerate(identified_nodes, 1):
        if isinstance(node, dict):
            content += f"""## {i}. {node.get('node_name', 'Unknown')}

- **Nodeç±»å‹**: {node.get('node_type', 'Unknown')}
- **ç›®çš„**: {node.get('purpose', '')}
- **èŒè´£**: {node.get('responsibility', '')}
- **è¾“å…¥æœŸæœ›**: {node.get('input_expectations', '')}
- **è¾“å‡ºæœŸæœ›**: {node.get('output_expectations', '')}
- **å¤æ‚åº¦**: {node.get('complexity_level', 'Unknown')}
- **å¤„ç†ç±»å‹**: {node.get('processing_type', 'Unknown')}
- **æ¨èé‡è¯•**: {'æ˜¯' if node.get('retry_recommended', False) else 'å¦'}

"""
    
    # ç»Ÿè®¡Nodeç±»å‹
    node_types = {}
    for node in identified_nodes:
        if isinstance(node, dict):
            node_type = node.get('node_type', 'Unknown')
            node_types[node_type] = node_types.get(node_type, 0) + 1
    
    content += f"""
## Nodeç±»å‹ç»Ÿè®¡
"""
    for node_type, count in node_types.items():
        content += f"- **{node_type}**: {count}ä¸ª\n"
    
    content += f"""
---
*ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""
    return content


def _generate_flow_design_content(flow_design: Dict[str, Any]) -> str:
    """ç”ŸæˆFlowè®¾è®¡æ–‡ä»¶å†…å®¹"""
    content = f"""# Flowè®¾è®¡ç»“æœ

## Flowæ¦‚è¿°
- **Flowåç§°**: {flow_design.get('flow_name', 'Unknown')}
- **Flowæè¿°**: {flow_design.get('flow_description', '')}
- **èµ·å§‹èŠ‚ç‚¹**: {flow_design.get('start_node', 'Unknown')}

## Flowå›¾è¡¨

```mermaid
{flow_design.get('mermaid_diagram', '// Mermaidå›¾è¡¨ç”Ÿæˆå¤±è´¥')}
```

## èŠ‚ç‚¹è¿æ¥å…³ç³»
"""
    
    connections = flow_design.get('connections', [])
    for i, conn in enumerate(connections, 1):
        content += f"""
### è¿æ¥ {i}
- **æºèŠ‚ç‚¹**: {conn.get('from_node', 'Unknown')}
- **ç›®æ ‡èŠ‚ç‚¹**: {conn.get('to_node', 'Unknown')}
- **è§¦å‘Action**: {conn.get('action', 'default')}
- **è½¬æ¢æ¡ä»¶**: {conn.get('condition', '')}
- **ä¼ é€’æ•°æ®**: {conn.get('data_passed', '')}
"""
    
    content += f"""
## æ‰§è¡Œæµç¨‹
"""
    
    execution_flow = flow_design.get('execution_flow', [])
    for step in execution_flow:
        content += f"""
### æ­¥éª¤ {step.get('step', 'Unknown')}
- **èŠ‚ç‚¹**: {step.get('node', 'Unknown')}
- **æè¿°**: {step.get('description', '')}
- **è¾“å…¥æ•°æ®**: {step.get('input_data', '')}
- **è¾“å‡ºæ•°æ®**: {step.get('output_data', '')}
"""
    
    content += f"""
## è®¾è®¡ç†ç”±
{flow_design.get('design_rationale', '')}

---
*ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""
    return content


def _generate_data_structure_content(data_structure: Dict[str, Any]) -> str:
    """ç”Ÿæˆæ•°æ®ç»“æ„æ–‡ä»¶å†…å®¹"""
    content = f"""# æ•°æ®ç»“æ„è®¾è®¡ç»“æœ

## æ•´ä½“æè¿°
{data_structure.get('shared_structure_description', '')}

## Sharedå­—æ®µå®šä¹‰
"""
    
    shared_fields = data_structure.get('shared_fields', [])
    for field in shared_fields:
        content += f"""
### {field.get('field_name', 'Unknown')}
- **æ•°æ®ç±»å‹**: {field.get('data_type', 'Unknown')}
- **æè¿°**: {field.get('description', '')}
- **ç”¨é€”**: {field.get('purpose', '')}
- **è¯»å–èŠ‚ç‚¹**: {', '.join(field.get('read_by_nodes', []))}
- **å†™å…¥èŠ‚ç‚¹**: {', '.join(field.get('written_by_nodes', []))}
- **æ˜¯å¦å¿…éœ€**: {'æ˜¯' if field.get('required', False) else 'å¦'}
- **ç¤ºä¾‹å€¼**: `{field.get('example_value', 'N/A')}`
"""
    
    content += f"""
## æ•°æ®æµæ¨¡å¼
"""
    
    data_flow_patterns = data_structure.get('data_flow_patterns', [])
    for pattern in data_flow_patterns:
        content += f"""
### {pattern.get('pattern_name', 'Unknown')}
- **æè¿°**: {pattern.get('description', '')}
- **æ¶‰åŠå­—æ®µ**: {', '.join(pattern.get('involved_fields', []))}
- **æµè½¬é¡ºåº**: {' â†’ '.join(pattern.get('flow_sequence', []))}
"""
    
    content += f"""
## Sharedå­˜å‚¨ç¤ºä¾‹ç»“æ„

```json
{json.dumps(data_structure.get('shared_example', {}), indent=2, ensure_ascii=False)}
```

---
*ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""
    return content


def _generate_node_design_content(detailed_nodes: list) -> str:
    """ç”ŸæˆNodeè®¾è®¡æ–‡ä»¶å†…å®¹"""
    content = f"""# Nodeè¯¦ç»†è®¾è®¡ç»“æœ

## æ¦‚è¿°
å…±è®¾è®¡äº†{len(detailed_nodes)}ä¸ªNodeçš„è¯¦ç»†å®ç°ï¼š

"""
    
    for i, node in enumerate(detailed_nodes, 1):
        if isinstance(node, dict):
            design_details = node.get('design_details', {})
            prep_stage = design_details.get('prep_stage', {})
            exec_stage = design_details.get('exec_stage', {})
            post_stage = design_details.get('post_stage', {})
            
            content += f"""## {i}. {node.get('node_name', 'Unknown')}

### åŸºæœ¬ä¿¡æ¯
- **Nodeç±»å‹**: {node.get('node_type', 'Unknown')}
- **ç›®çš„**: {node.get('purpose', '')}

### Prepé˜¶æ®µè®¾è®¡
- **æè¿°**: {prep_stage.get('description', '')}
- **ä»sharedè¯»å–**: {', '.join(prep_stage.get('input_from_shared', []))}
- **éªŒè¯é€»è¾‘**: {prep_stage.get('validation_logic', '')}
- **å‡†å¤‡æ­¥éª¤**: {'; '.join(prep_stage.get('preparation_steps', []))}

### Execé˜¶æ®µè®¾è®¡
- **æè¿°**: {exec_stage.get('description', '')}
- **æ ¸å¿ƒé€»è¾‘**: {exec_stage.get('core_logic', '')}
- **å¤„ç†æ­¥éª¤**: {'; '.join(exec_stage.get('processing_steps', []))}
- **é”™è¯¯å¤„ç†**: {exec_stage.get('error_handling', '')}

### Posté˜¶æ®µè®¾è®¡
- **æè¿°**: {post_stage.get('description', '')}
- **ç»“æœå¤„ç†**: {post_stage.get('result_processing', '')}
- **æ›´æ–°shared**: {', '.join(post_stage.get('shared_updates', []))}
- **Actioné€»è¾‘**: {post_stage.get('action_logic', '')}
- **å¯èƒ½Actions**: {', '.join(post_stage.get('possible_actions', []))}

### æ•°æ®è®¿é—®
- **è¯»å–å­—æ®µ**: {', '.join(node.get('data_access', {}).get('reads_from_shared', []))}
- **å†™å…¥å­—æ®µ**: {', '.join(node.get('data_access', {}).get('writes_to_shared', []))}

### é‡è¯•é…ç½®
- **æœ€å¤§é‡è¯•**: {node.get('retry_config', {}).get('max_retries', 0)}æ¬¡
- **ç­‰å¾…æ—¶é—´**: {node.get('retry_config', {}).get('wait', 0)}ç§’

"""
    
    content += f"""
---
*ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""
    return content
