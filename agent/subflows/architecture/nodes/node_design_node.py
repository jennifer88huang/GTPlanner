"""
Node Design Node

ç¬¬äº”æ­¥ï¼šåŸºäºæ•°æ®ç»“æ„è®¾è®¡ï¼Œè¯¦ç»†è®¾è®¡æ¯ä¸ªNodeçš„prep/exec/postä¸‰é˜¶æ®µé€»è¾‘ã€‚
ä¸“æ³¨äºæ¯ä¸ªNodeçš„å…·ä½“å®ç°ç»†èŠ‚å’ŒèŒè´£åˆ†ç¦»ã€‚
"""

import time
import json
import asyncio
from typing import Dict, Any
from pocketflow import Node

# å¯¼å…¥LLMè°ƒç”¨å·¥å…·
from agent.common import call_llm_async
import asyncio


class NodeDesignNode(Node):
    """Nodeè®¾è®¡èŠ‚ç‚¹ - è¯¦ç»†è®¾è®¡æ¯ä¸ªNodeçš„å®ç°"""
    
    def __init__(self):
        super().__init__()
        self.name = "NodeDesignNode"
        self.description = "è¯¦ç»†è®¾è®¡æ¯ä¸ªNodeçš„prep/exec/postä¸‰é˜¶æ®µå®ç°"
    
    def prep(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡é˜¶æ®µï¼šè·å–Flowè®¾è®¡ç»“æœ"""
        try:
            # è·å–Flowè®¾è®¡ç»“æœ
            flow_design = shared.get("flow_design", {})

            # è·å–å·²è¯†åˆ«çš„Nodeåˆ—è¡¨
            identified_nodes = shared.get("identified_nodes", [])

            # è·å–æ•°æ®ç»“æ„è®¾è®¡
            data_structure = shared.get("data_structure", {})

            # è·å–Agentåˆ†æç»“æœ
            agent_analysis = shared.get("agent_analysis", {})

            # æ£€æŸ¥å¿…éœ€çš„è¾“å…¥
            if not flow_design:
                return {"error": "ç¼ºå°‘Flowè®¾è®¡ç»“æœ"}

            if not identified_nodes:
                return {"error": "ç¼ºå°‘å·²è¯†åˆ«çš„Nodeåˆ—è¡¨"}

            if not data_structure:
                return {"error": "ç¼ºå°‘æ•°æ®ç»“æ„è®¾è®¡"}

            return {
                "flow_design": flow_design,
                "identified_nodes": identified_nodes,
                "data_structure": data_structure,
                "agent_analysis": agent_analysis,
                "timestamp": time.time()
            }
            
        except Exception as e:
            return {"error": f"Node design preparation failed: {str(e)}"}
    
    def exec(self, prep_result: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé˜¶æ®µï¼šè®¾è®¡æ¯ä¸ªNodeçš„è¯¦ç»†å®ç°"""
        try:
            if "error" in prep_result:
                raise ValueError(prep_result["error"])
            
            identified_nodes = prep_result["identified_nodes"]

            # ä¸ºæ¯ä¸ªNodeè®¾è®¡è¯¦ç»†å®ç°
            detailed_nodes = []

            for node_info in identified_nodes:
                node_name = node_info.get("node_name", "UnknownNode")
                print(f"ğŸ”§ è®¾è®¡Node: {node_name}")
                
                # æ„å»ºNodeè®¾è®¡æç¤ºè¯
                prompt = self._build_node_design_prompt(prep_result, node_info)
                
                # è°ƒç”¨LLMè®¾è®¡Node
                node_design = asyncio.run(self._design_single_node(prompt))
                
                # è§£æNodeè®¾è®¡ç»“æœ
                parsed_node = self._parse_node_design(node_design, node_info)
                detailed_nodes.append(parsed_node)
            
            return {
                "detailed_nodes": detailed_nodes,
                "design_success": True
            }
            
        except Exception as e:
            return {"error": f"Node design failed: {str(e)}"}
    
    def post(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """åå¤„ç†é˜¶æ®µï¼šä¿å­˜Nodeè®¾è®¡"""
        try:
            if "error" in exec_res:
                shared["node_design_error"] = exec_res["error"]
                print(f"âŒ Nodeè®¾è®¡å¤±è´¥: {exec_res['error']}")
                return "error"
            
            # ä¿å­˜Nodeè®¾è®¡
            detailed_nodes = exec_res["detailed_nodes"]
            shared["detailed_nodes"] = detailed_nodes
            
            # æ›´æ–°ç³»ç»Ÿæ¶ˆæ¯
            if "system_messages" not in shared:
                shared["system_messages"] = []
            
            shared["system_messages"].append({
                "timestamp": time.time(),
                "stage": "node_design",
                "status": "completed",
                "message": f"Nodeè®¾è®¡å®Œæˆï¼š{len(detailed_nodes)}ä¸ªèŠ‚ç‚¹"
            })

            # ç”Ÿæˆæ–‡ä»¶è¾“å‡º
            from ..utils.file_output_util import generate_stage_file
            generate_stage_file("node_design", detailed_nodes, shared)

            print(f"âœ… Nodeè®¾è®¡å®Œæˆ")
            print(f"   è®¾è®¡èŠ‚ç‚¹æ•°: {len(detailed_nodes)}")

            return "nodes_designed"
            
        except Exception as e:
            shared["node_design_post_error"] = str(e)
            print(f"âŒ Nodeè®¾è®¡åå¤„ç†å¤±è´¥: {str(e)}")
            return "error"
    
    def _build_node_design_prompt(self, prep_result: Dict[str, Any], node_info: Dict[str, Any]) -> str:
        """æ„å»ºNodeè®¾è®¡æç¤ºè¯"""
        flow_design = prep_result["flow_design"]
        agent_analysis = prep_result.get("agent_analysis", {})

        node_name = node_info.get("node_name", "UnknownNode")
        node_type = node_info.get("node_type", "Node")
        node_purpose = node_info.get("purpose", "")

        # åˆ†ææ­¤Nodeåœ¨Flowä¸­çš„ä½ç½®å’Œè¿æ¥å…³ç³»
        connections = flow_design.get("connections", [])
        incoming_nodes = [conn for conn in connections if conn.get("to_node") == node_name]
        outgoing_nodes = [conn for conn in connections if conn.get("from_node") == node_name]

        # åˆ†æå‰ç½®å’Œåç½®Nodeçš„ä¿¡æ¯
        context_info = {
            "incoming_connections": incoming_nodes,
            "outgoing_connections": outgoing_nodes,
            "position_in_flow": self._analyze_node_position(node_name, flow_design)
        }

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„pocketflow Nodeè®¾è®¡å¸ˆã€‚è¯·ä¸ºä»¥ä¸‹Nodeè®¾è®¡è¯¦ç»†çš„å®ç°æ–¹æ¡ˆã€‚

**NodeåŸºæœ¬ä¿¡æ¯ï¼š**
- åç§°: {node_name}
- ç±»å‹: {node_type}
- ç›®çš„: {node_purpose}

**Nodeåœ¨Flowä¸­çš„ä½ç½®å’Œè¿æ¥å…³ç³»ï¼š**
{json.dumps(context_info, indent=2, ensure_ascii=False)}

**å®Œæ•´Flowè®¾è®¡ï¼š**
{json.dumps(flow_design, indent=2, ensure_ascii=False)}

**Agentåˆ†æç»“æœï¼š**
{json.dumps(agent_analysis, indent=2, ensure_ascii=False)}

è¯·è®¾è®¡è¿™ä¸ªNodeçš„è¯¦ç»†å®ç°ï¼Œè¾“å‡ºJSONæ ¼å¼ç»“æœï¼š

{{
    "node_name": "{node_name}",
    "node_type": "{node_type}",
    "purpose": "èŠ‚ç‚¹ç›®çš„",
    "design_details": {{
        "prep_stage": {{
            "description": "prepé˜¶æ®µçš„è¯¦ç»†æè¿°",
            "input_from_shared": ["ä»sharedè¯»å–çš„æ•°æ®å­—æ®µ"],
            "validation_logic": "æ•°æ®éªŒè¯é€»è¾‘",
            "preparation_steps": ["å‡†å¤‡æ­¥éª¤1", "å‡†å¤‡æ­¥éª¤2"],
            "output_prep_res": "prep_resçš„ç»“æ„æè¿°"
        }},
        "exec_stage": {{
            "description": "execé˜¶æ®µçš„è¯¦ç»†æè¿°",
            "core_logic": "æ ¸å¿ƒå¤„ç†é€»è¾‘æè¿°",
            "processing_steps": ["å¤„ç†æ­¥éª¤1", "å¤„ç†æ­¥éª¤2"],
            "error_handling": "é”™è¯¯å¤„ç†ç­–ç•¥",
            "output_exec_res": "exec_resçš„ç»“æ„æè¿°"
        }},
        "post_stage": {{
            "description": "posté˜¶æ®µçš„è¯¦ç»†æè¿°",
            "result_processing": "ç»“æœå¤„ç†é€»è¾‘",
            "shared_updates": ["æ›´æ–°åˆ°sharedçš„æ•°æ®"],
            "action_logic": "Actionå†³ç­–é€»è¾‘",
            "possible_actions": ["å¯èƒ½è¿”å›çš„Actionåˆ—è¡¨"]
        }}
    }},
    "data_access": {{
        "reads_from_shared": ["è¯»å–çš„sharedå­—æ®µ"],
        "writes_to_shared": ["å†™å…¥çš„sharedå­—æ®µ"],
        "temp_variables": ["ä¸´æ—¶å˜é‡"]
    }},
    "retry_config": {{
        "max_retries": 3,
        "wait": 1.0,
        "retry_conditions": ["é‡è¯•æ¡ä»¶"]
    }}
}}

**è®¾è®¡è¦æ±‚ï¼š**
1. ä¸¥æ ¼éµå¾ªprep/exec/postä¸‰é˜¶æ®µåˆ†ç¦»
2. execé˜¶æ®µä¸èƒ½ç›´æ¥è®¿é—®shared
3. æ˜ç¡®çš„Actioné©±åŠ¨é€»è¾‘
4. è€ƒè™‘é”™è¯¯å¤„ç†å’Œé‡è¯•
5. ç¡®ä¿ä¸Flowä¸­å…¶ä»–Nodeçš„åè°ƒ

è¯·ç¡®ä¿è®¾è®¡ç¬¦åˆpocketflowçš„æœ€ä½³å®è·µã€‚

**é‡è¦ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡å­—è¯´æ˜ã€ä»£ç å—æ ‡è®°æˆ–å…¶ä»–å†…å®¹ã€‚ç›´æ¥è¾“å‡ºçº¯JSONæ•°æ®ã€‚**"""
        
        return prompt
    
    async def _design_single_node(self, prompt: str) -> str:
        """è°ƒç”¨LLMè®¾è®¡å•ä¸ªNode"""
        try:
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è°ƒç”¨LLM
            result = await call_llm_async(prompt, is_json=True, max_retries=3, retry_delay=2)
            return result
        except Exception as e:
            raise Exception(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")

    def _design_single_node_detailed(self, prep_result: Dict[str, Any], node_info: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸ºå•ä¸ªNodeæ‰§è¡Œè¯¦ç»†è®¾è®¡ï¼ˆä¾›æ‰¹å¤„ç†èšåˆå™¨è°ƒç”¨ï¼‰"""
        try:
            node_name = node_info.get('node_name', 'Unknown')
            print(f"         ğŸ”§ å¼€å§‹è¯¦ç»†è®¾è®¡Node: {node_name}")

            # æ„å»ºè®¾è®¡æç¤ºè¯
            print(f"         ğŸ“ æ„å»ºè®¾è®¡æç¤ºè¯...")
            prompt = self._build_node_design_prompt(prep_result, node_info)
            prompt_length = len(prompt)
            print(f"         ğŸ“ æç¤ºè¯é•¿åº¦: {prompt_length} å­—ç¬¦")

            # è°ƒç”¨LLMè®¾è®¡
            print(f"         ğŸ¤– è°ƒç”¨LLM API...")
            import asyncio
            import time

            llm_start = time.time()
            design_result = asyncio.run(self._design_single_node(prompt))
            llm_duration = time.time() - llm_start

            print(f"         âœ… LLM APIè°ƒç”¨æˆåŠŸ (è€—æ—¶: {llm_duration:.2f}ç§’)")
            print(f"         ğŸ“Š LLMè¿”å›ç»“æœé•¿åº¦: {len(str(design_result))} å­—ç¬¦")

            # è§£æè®¾è®¡ç»“æœ
            print(f"         ğŸ” è§£æè®¾è®¡ç»“æœ...")
            parsed_result = self._parse_node_design(design_result, node_info)

            if parsed_result:
                print(f"         âœ… è®¾è®¡ç»“æœè§£ææˆåŠŸ")
                print(f"            Nodeåç§°: {parsed_result.get('node_name', 'Unknown')}")
                print(f"            è®¾è®¡é˜¶æ®µ: {len(parsed_result.get('design_details', {}))} ä¸ª")
            else:
                print(f"         âŒ è®¾è®¡ç»“æœè§£æå¤±è´¥")

            return parsed_result

        except Exception as e:
            print(f"         âŒ Nodeè¯¦ç»†è®¾è®¡å¼‚å¸¸: {e}")
            import traceback
            print(f"         ğŸ“‹ å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise Exception(f"å•ä¸ªNodeè®¾è®¡å¤±è´¥: {str(e)}")

    def _parse_node_design(self, node_design: str, original_node_info: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æNodeè®¾è®¡ç»“æœ"""
        try:
            # å°è¯•è§£æJSON
            if isinstance(node_design, str):
                parsed_data = json.loads(node_design)
            else:
                parsed_data = node_design

            # å¤„ç†LLMå¯èƒ½è¿”å›åˆ—è¡¨çš„æƒ…å†µ
            if isinstance(parsed_data, list):
                if len(parsed_data) == 0:
                    raise Exception("LLMè¿”å›ç©ºåˆ—è¡¨")
                # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
                parsed_node = parsed_data[0]
                print(f"         âš ï¸ LLMè¿”å›åˆ—è¡¨æ ¼å¼ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ ")
            elif isinstance(parsed_data, dict):
                parsed_node = parsed_data
            else:
                raise Exception(f"LLMè¿”å›äº†ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {type(parsed_data)}")

            print(f"         ğŸ” è§£æåçš„æ•°æ®ç±»å‹: {type(parsed_node)}")
            print(f"         ğŸ“‹ åŒ…å«å­—æ®µ: {list(parsed_node.keys()) if isinstance(parsed_node, dict) else 'Not a dict'}")

            # éªŒè¯å¿…éœ€å­—æ®µ
            if not isinstance(parsed_node, dict):
                raise Exception(f"è§£æåçš„Nodeæ•°æ®ä¸æ˜¯å­—å…¸ç±»å‹: {type(parsed_node)}")

            if "node_name" not in parsed_node:
                parsed_node["node_name"] = original_node_info.get("node_name", "UnknownNode")
            
            if "node_type" not in parsed_node:
                parsed_node["node_type"] = original_node_info.get("node_type", "Node")
            
            if "design_details" not in parsed_node:
                raise Exception("ç¼ºå°‘design_detailså­—æ®µ")
            
            # éªŒè¯design_detailsç»“æ„
            design_details = parsed_node["design_details"]
            if not isinstance(design_details, dict):
                raise Exception(f"design_detailsä¸æ˜¯å­—å…¸ç±»å‹: {type(design_details)}")

            required_stages = ["prep_stage", "exec_stage", "post_stage"]

            for stage in required_stages:
                if stage not in design_details:
                    print(f"         âš ï¸ ç¼ºå°‘{stage}è®¾è®¡ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
                    design_details[stage] = {
                        "description": f"é»˜è®¤{stage}æè¿°",
                        "steps": []
                    }
            
            return parsed_node
            
        except json.JSONDecodeError as e:
            raise Exception(f"Nodeè®¾è®¡JSONè§£æå¤±è´¥: {e}")
        except Exception as e:
            raise Exception(f"Nodeè®¾è®¡è§£æå¤±è´¥: {e}")

    def _analyze_node_position(self, node_name: str, flow_design: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æNodeåœ¨Flowä¸­çš„ä½ç½®å’Œè§’è‰²"""
        try:
            connections = flow_design.get("connections", [])
            start_node = flow_design.get("start_node", "")

            # æ‰¾åˆ°æ‰€æœ‰ç›¸å…³è¿æ¥
            incoming_connections = [conn for conn in connections if conn.get("to_node") == node_name]
            outgoing_connections = [conn for conn in connections if conn.get("from_node") == node_name]

            # åˆ†æèŠ‚ç‚¹ç±»å‹
            node_type = "unknown"
            if node_name == start_node or not incoming_connections:
                node_type = "entry_point"  # å…¥å£èŠ‚ç‚¹
            elif not outgoing_connections:
                node_type = "exit_point"   # å‡ºå£èŠ‚ç‚¹
            elif len(incoming_connections) > 1:
                node_type = "convergence"  # æ±‡èšèŠ‚ç‚¹
            elif len(outgoing_connections) > 1:
                node_type = "divergence"   # åˆ†å‰èŠ‚ç‚¹
            else:
                node_type = "processing"   # å¤„ç†èŠ‚ç‚¹

            # è®¡ç®—èŠ‚ç‚¹æ·±åº¦ï¼ˆä»èµ·å§‹èŠ‚ç‚¹çš„è·ç¦»ï¼‰
            depth = self._calculate_node_depth(node_name, connections, start_node)

            # åˆ†æå‰ç½®èŠ‚ç‚¹
            predecessor_nodes = [conn.get("from_node") for conn in incoming_connections]
            predecessor_actions = [conn.get("action", "default") for conn in incoming_connections]

            # åˆ†æåç»­èŠ‚ç‚¹
            successor_nodes = [conn.get("to_node") for conn in outgoing_connections]
            successor_actions = [conn.get("action", "default") for conn in outgoing_connections]

            # åˆ†ææ•°æ®æµç‰¹å¾
            data_flow_pattern = self._analyze_data_flow_pattern(
                node_name, incoming_connections, outgoing_connections
            )

            return {
                "node_type": node_type,
                "depth_from_start": depth,
                "is_start_node": node_name == start_node,
                "is_end_node": len(outgoing_connections) == 0,
                "predecessor_count": len(predecessor_nodes),
                "successor_count": len(successor_nodes),
                "predecessor_nodes": predecessor_nodes,
                "successor_nodes": successor_nodes,
                "incoming_actions": predecessor_actions,
                "outgoing_actions": successor_actions,
                "data_flow_pattern": data_flow_pattern,
                "complexity_level": self._assess_node_complexity(
                    len(incoming_connections), len(outgoing_connections)
                )
            }

        except Exception as e:
            # å¦‚æœåˆ†æå¤±è´¥ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
            return {
                "node_type": "unknown",
                "depth_from_start": 0,
                "is_start_node": False,
                "is_end_node": False,
                "error": str(e)
            }

    def _calculate_node_depth(self, target_node: str, connections: list, start_node: str) -> int:
        """è®¡ç®—èŠ‚ç‚¹ä»èµ·å§‹èŠ‚ç‚¹çš„æ·±åº¦"""
        if target_node == start_node:
            return 0

        # ä½¿ç”¨BFSè®¡ç®—æœ€çŸ­è·¯å¾„
        from collections import deque

        queue = deque([(start_node, 0)])
        visited = {start_node}

        while queue:
            current_node, depth = queue.popleft()

            # æ‰¾åˆ°å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰åç»­èŠ‚ç‚¹
            for conn in connections:
                if conn.get("from_node") == current_node:
                    next_node = conn.get("to_node")
                    if next_node == target_node:
                        return depth + 1
                    if next_node not in visited:
                        visited.add(next_node)
                        queue.append((next_node, depth + 1))

        return -1  # æ— æ³•åˆ°è¾¾

    def _analyze_data_flow_pattern(self, node_name: str, incoming: list, outgoing: list) -> str:
        """åˆ†æèŠ‚ç‚¹çš„æ•°æ®æµæ¨¡å¼"""
        incoming_count = len(incoming)
        outgoing_count = len(outgoing)

        if incoming_count == 0 and outgoing_count == 1:
            return "source"      # æ•°æ®æº
        elif incoming_count == 1 and outgoing_count == 0:
            return "sink"        # æ•°æ®æ±‡
        elif incoming_count == 1 and outgoing_count == 1:
            return "transform"   # æ•°æ®è½¬æ¢
        elif incoming_count > 1 and outgoing_count == 1:
            return "merge"       # æ•°æ®åˆå¹¶
        elif incoming_count == 1 and outgoing_count > 1:
            return "split"       # æ•°æ®åˆ†å‘
        elif incoming_count > 1 and outgoing_count > 1:
            return "hub"         # æ•°æ®æ¢çº½
        else:
            return "isolated"    # å­¤ç«‹èŠ‚ç‚¹

    def _assess_node_complexity(self, incoming_count: int, outgoing_count: int) -> str:
        """è¯„ä¼°èŠ‚ç‚¹å¤æ‚åº¦"""
        total_connections = incoming_count + outgoing_count

        if total_connections <= 2:
            return "simple"
        elif total_connections <= 4:
            return "moderate"
        else:
            return "complex"
