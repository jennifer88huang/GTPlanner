"""
Document Generation Node

ç¬¬å…­æ­¥ï¼šæ•´åˆæ‰€æœ‰è®¾è®¡ç»“æœï¼Œç”Ÿæˆå®Œæ•´çš„Agentè®¾è®¡æ–‡æ¡£ã€‚
åŸºäºä¹‹å‰æç¤ºè¯çš„å®Œæ•´æ ¼å¼ï¼Œç”Ÿæˆé«˜è´¨é‡çš„pocketflow Agentè®¾è®¡æ–‡æ¡£ã€‚
"""

import time
import json
from typing import Dict, Any
from pocketflow import AsyncNode

# å¯¼å…¥OpenAIå®¢æˆ·ç«¯
from utils.openai_client import get_openai_client
from agent.streaming import (
    emit_processing_status,
    emit_error
)


class DocumentGenerationNode(AsyncNode):
    """æ–‡æ¡£ç”ŸæˆèŠ‚ç‚¹ - ç”Ÿæˆå®Œæ•´çš„Agentè®¾è®¡æ–‡æ¡£"""
    
    def __init__(self):
        super().__init__()
        self.name = "DocumentGenerationNode"
        self.description = "æ•´åˆæ‰€æœ‰è®¾è®¡ç»“æœç”Ÿæˆå®Œæ•´çš„Agentè®¾è®¡æ–‡æ¡£"
    
    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡é˜¶æ®µï¼šæ”¶é›†æ‰€æœ‰è®¾è®¡ç»“æœ"""
        try:
            # è·å–æ‰€æœ‰å‰é¢æ­¥éª¤çš„markdownç»“æœ
            analysis_markdown = shared.get("analysis_markdown", "")
            nodes_markdown = shared.get("nodes_markdown", "")
            flow_markdown = shared.get("flow_markdown", "")
            data_structure_markdown = shared.get("data_structure_markdown", "")
            node_design_markdown = shared.get("node_design_markdown", "")

            # è·å–é¡¹ç›®çŠ¶æ€ä¿¡æ¯
            short_planning = shared.get("short_planning", "")
            user_requirements = shared.get("user_requirements", "")
            research_findings = shared.get("research_findings", {})
            recommended_tools = shared.get("recommended_tools", [])

            # æ£€æŸ¥å¿…éœ€çš„è¾“å…¥
            required_data = {
                "analysis_markdown": analysis_markdown,
                "nodes_markdown": nodes_markdown
            }

            missing_data = [key for key, value in required_data.items() if not value]
            if missing_data:
                return {"error": f"ç¼ºå°‘å¿…éœ€çš„è®¾è®¡æ•°æ®: {missing_data}"}

            return {
                "analysis_markdown": analysis_markdown,
                "nodes_markdown": nodes_markdown,
                "flow_markdown": flow_markdown,
                "data_structure_markdown": data_structure_markdown,
                "node_design_markdown": node_design_markdown,
                "short_planning": short_planning,
                "user_requirements": user_requirements,
                "research_findings": research_findings,
                "recommended_tools": recommended_tools,
                "timestamp": time.time()
            }
            
        except Exception as e:
            return {"error": f"Document generation preparation failed: {str(e)}"}
    
    async def exec_async(self, prep_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œé˜¶æ®µï¼šç”Ÿæˆå®Œæ•´çš„Agentè®¾è®¡æ–‡æ¡£"""
        try:
            if "error" in prep_result:
                raise ValueError(prep_result["error"])
            
            # æ„å»ºæ–‡æ¡£ç”Ÿæˆæç¤ºè¯
            prompt = self._build_document_generation_prompt(prep_result)
            
            # å¼‚æ­¥è°ƒç”¨LLMç”Ÿæˆæ–‡æ¡£
            agent_design_document = await self._generate_complete_document(prompt)
            
            return {
                "agent_design_document": agent_design_document,
                "generation_success": True,
                "generation_time": time.time()
            }
            
        except Exception as e:
            return {"error": f"Document generation failed: {str(e)}"}
    
    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """åå¤„ç†é˜¶æ®µï¼šä¿å­˜æ–‡æ¡£å¹¶ç”Ÿæˆæ–‡ä»¶"""
        try:
            if "error" in exec_res:
                shared["document_generation_error"] = exec_res["error"]
                await emit_error(shared, f"âŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {exec_res['error']}")
                return "error"
            
            # ä¿å­˜ç”Ÿæˆçš„æ–‡æ¡£
            agent_design_document = exec_res["agent_design_document"]
            shared["agent_design_document"] = agent_design_document

            # ä½¿ç”¨æµå¼äº‹ä»¶å‘é€è®¾è®¡æ–‡æ¡£
            from agent.streaming import emit_design_document
            await emit_design_document(shared, "06_agent_design_complete.md", agent_design_document)
            
            # æ›´æ–°ç³»ç»Ÿæ¶ˆæ¯
            if "system_messages" not in shared:
                shared["system_messages"] = []
            
            shared["system_messages"].append({
                "timestamp": time.time(),
                "stage": "document_generation",
                "status": "completed",
                "message": "å®Œæ•´Agentè®¾è®¡æ–‡æ¡£ç”Ÿæˆå®Œæˆ"
            })
            
            await emit_processing_status(shared, "âœ… å®Œæ•´Agentè®¾è®¡æ–‡æ¡£ç”Ÿæˆå®Œæˆ")
            return "documentation_complete"

        except Exception as e:
            shared["document_generation_post_error"] = str(e)
            await emit_error(shared, f"âŒ æ–‡æ¡£ç”Ÿæˆåå¤„ç†å¤±è´¥: {str(e)}")
            return "error"
    
    def _build_document_generation_prompt(self, prep_result: Dict[str, Any]) -> str:
        """æ„å»ºæ–‡æ¡£ç”Ÿæˆæç¤ºè¯"""
        analysis_markdown = prep_result.get("analysis_markdown", "")
        nodes_markdown = prep_result.get("nodes_markdown", "")
        flow_markdown = prep_result.get("flow_markdown", "")
        data_structure_markdown = prep_result.get("data_structure_markdown", "")
        node_design_markdown = prep_result.get("node_design_markdown", "")
        user_requirements = prep_result.get("user_requirements", "")

        # ä»ç”¨æˆ·éœ€æ±‚ä¸­æå–é¡¹ç›®æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        project_title = "AI Agenté¡¹ç›®"
        if user_requirements and isinstance(user_requirements, str):
            # ç®€å•æå–ï¼šå–ç¬¬ä¸€è¡Œæˆ–å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
            first_line = user_requirements.split('\n')[0].strip()
            if first_line:
                project_title = first_line[:50] + ("..." if len(first_line) > 50 else "")

        # è·å–å…¶ä»–ä¸Šä¸‹æ–‡ä¿¡æ¯
        short_planning = prep_result.get("short_planning", "")
        research_findings = prep_result.get("research_findings", {})
        recommended_tools = prep_result.get("recommended_tools", [])

        # æ„å»ºæ¨èå·¥å…·ä¿¡æ¯
        tools_info = ""
        if recommended_tools:
            tools_list = []
            for i, tool in enumerate(recommended_tools):
                # æ·»åŠ  None æ£€æŸ¥ï¼Œé˜²æ­¢ tool ä¸º None
                if tool and isinstance(tool, dict):
                    tool_name = tool.get("name", tool.get("id", "æœªçŸ¥å·¥å…·"))
                    tool_type = tool.get("type", "")
                    tool_summary = tool.get("summary", tool.get("description", ""))
                    tools_list.append(f"- {tool_name} ({tool_type}): {tool_summary}")
                else:
                    print(f"ğŸ” DEBUG - DocumentGenerationNode - è·³è¿‡æ— æ•ˆå·¥å…·: {tool}")
            tools_info = "\n".join(tools_list)

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿ç¼–å†™åŸºäºpocketflowçš„Agentè®¾è®¡æ–‡æ¡£ã€‚è¯·æ ¹æ®ä»¥ä¸‹å®Œæ•´çš„è®¾è®¡ç»“æœï¼Œç”Ÿæˆä¸€ä»½é«˜è´¨é‡çš„Agentè®¾è®¡æ–‡æ¡£ã€‚

**é¡¹ç›®æ ‡é¢˜ï¼š** {project_title}

**ç”¨æˆ·éœ€æ±‚ï¼š**
{user_requirements if user_requirements else "æœªæä¾›ç”¨æˆ·éœ€æ±‚"}

**é¡¹ç›®è§„åˆ’ï¼š**
{short_planning if short_planning else "æœªæä¾›é¡¹ç›®è§„åˆ’"}

**æ¨èå·¥å…·ï¼š**
{tools_info if tools_info else "æ— æ¨èå·¥å…·"}

**æŠ€æœ¯è°ƒç ”ç»“æœï¼š**
{research_findings.get('summary', 'æ— æŠ€æœ¯è°ƒç ”ç»“æœ') if research_findings else 'æ— æŠ€æœ¯è°ƒç ”ç»“æœ'}

**Agentåˆ†æç»“æœï¼š**
{analysis_markdown}

**è¯†åˆ«çš„Nodeåˆ—è¡¨ï¼š**
{nodes_markdown}

**Flowè®¾è®¡ï¼š**
{flow_markdown}

**æ•°æ®ç»“æ„è®¾è®¡ï¼š**
{data_structure_markdown}

**è¯¦ç»†Nodeè®¾è®¡ï¼š**
{node_design_markdown}

è¯·ç”Ÿæˆä¸€ä»½å®Œæ•´çš„Markdownæ ¼å¼çš„Agentè®¾è®¡æ–‡æ¡£ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

# {project_title}

## é¡¹ç›®éœ€æ±‚
åŸºäºAgentåˆ†æç»“æœï¼Œæ¸…æ™°æè¿°é¡¹ç›®ç›®æ ‡å’ŒåŠŸèƒ½éœ€æ±‚ã€‚

## å·¥å…·å‡½æ•°
å¦‚æœéœ€è¦çš„è¯ï¼Œåˆ—å‡ºæ‰€éœ€çš„å·¥å…·å‡½æ•°ï¼ˆå¦‚LLMè°ƒç”¨ã€æ•°æ®å¤„ç†ç­‰ï¼‰ã€‚

## Flowè®¾è®¡
è¯¦ç»†æè¿°pocketflowçš„Flowç¼–æ’ï¼ŒåŒ…å«ï¼š
- Flowçš„æ•´ä½“è®¾è®¡æ€è·¯
- èŠ‚ç‚¹è¿æ¥å’ŒActioné©±åŠ¨çš„è½¬æ¢é€»è¾‘
- å®Œæ•´çš„æ‰§è¡Œæµç¨‹æè¿°

### Flowå›¾è¡¨
ä½¿ç”¨Mermaid flowchart TDè¯­æ³•ï¼Œç”Ÿæˆå®Œæ•´çš„Flowå›¾è¡¨ã€‚

## æ•°æ®ç»“æ„
è¯¦ç»†æè¿°sharedå­˜å‚¨çš„æ•°æ®ç»“æ„ï¼ŒåŒ…å«ï¼š
- sharedå­˜å‚¨çš„æ•´ä½“è®¾è®¡
- å„ä¸ªå­—æ®µçš„å®šä¹‰å’Œç”¨é€”
- æ•°æ®æµè½¬æ¨¡å¼

## Nodeè®¾è®¡
ä¸ºæ¯ä¸ªNodeæä¾›è¯¦ç»†è®¾è®¡ï¼ŒåŒ…å«ï¼š
- Purposeï¼ˆç›®çš„ï¼‰
- Designï¼ˆè®¾è®¡ç±»å‹ï¼Œå¦‚Nodeã€AsyncNodeç­‰ï¼‰
- Data Accessï¼ˆæ•°æ®è®¿é—®æ¨¡å¼ï¼‰
- è¯¦ç»†çš„prep/exec/postä¸‰é˜¶æ®µè®¾è®¡

è¯·ç¡®ä¿æ–‡æ¡£ï¼š
1. éµå¾ªpocketflowçš„æœ€ä½³å®è·µ
2. ä½“ç°å…³æ³¨ç‚¹åˆ†ç¦»åŸåˆ™
3. åŒ…å«å®Œæ•´çš„Actioné©±åŠ¨é€»è¾‘
4. æä¾›æ¸…æ™°çš„æ•°æ®æµè®¾è®¡
5. ä½¿ç”¨ä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£æ ¼å¼

è¾“å‡ºå®Œæ•´çš„Markdownæ ¼å¼æ–‡æ¡£ï¼š"""
        
        return prompt
    
    async def _generate_complete_document(self, prompt: str) -> str:
        """è°ƒç”¨LLMç”Ÿæˆå®Œæ•´æ–‡æ¡£"""
        try:
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è°ƒç”¨LLM
            client = get_openai_client()
            response = await client.chat_completion(
                messages=[{"role": "user", "content": prompt}]
            )
            result = response.choices[0].message.content if response.choices else ""
            return result
        except Exception as e:
            raise Exception(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
    

