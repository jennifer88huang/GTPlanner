"""
å¹¶å‘ç ”ç©¶èŠ‚ç‚¹ - å‚è€ƒå®˜æ–¹ç¤ºä¾‹å®ç°çœŸæ­£çš„å¹¶å‘å¤„ç†

åœ¨å•ä¸ªèŠ‚ç‚¹å†…éƒ¨å¤„ç†å¤šä¸ªå…³é”®è¯çš„å¹¶å‘ç ”ç©¶ï¼Œè€Œä¸æ˜¯å¹¶å‘å¤šä¸ªFlow
"""

import asyncio
from typing import Dict, List, Any
from pocketflow import AsyncNode
from ..flows.keyword_research_flow import create_keyword_research_subflow
from agent.streaming import (
    emit_processing_status_from_prep,
    emit_error_from_prep,
    emit_processing_status,
    emit_error
)


class ConcurrentResearchNode(AsyncNode):
    """
    å¹¶å‘ç ”ç©¶èŠ‚ç‚¹ - å‚è€ƒå®˜æ–¹ç¤ºä¾‹çš„å®ç°æ–¹å¼
    
    åœ¨å•ä¸ªèŠ‚ç‚¹å†…éƒ¨å¹¶å‘å¤„ç†å¤šä¸ªå…³é”®è¯ï¼Œä¿æŒtraceçš„æ­£ç¡®æ—¶é—´çº¿
    """

    def __init__(self):
        super().__init__()
        self.name = "concurrent_research"
        self._subflows_and_data = []
        self._execution_results = []

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡å¹¶å‘ç ”ç©¶å‚æ•°"""
        
        # è·å–ç ”ç©¶å‚æ•°
        research_keywords = shared.get("research_keywords", [])
        focus_areas = shared.get("focus_areas", [])
        project_context = shared.get("project_context", "")
        
        # éªŒè¯å‚æ•°
        if not research_keywords:
            return {"error": "ç¼ºå°‘ç ”ç©¶å…³é”®è¯"}
        
        if not focus_areas:
            return {"error": "ç¼ºå°‘å…³æ³¨ç‚¹"}
        
        
        # åˆ›å»ºå­æµç¨‹å’Œæ•°æ®å¯¹
        subflows_and_data = []
        for keyword in research_keywords:
            # åˆ›å»ºå…³é”®è¯ç ”ç©¶å­æµç¨‹
            keyword_subflow = create_keyword_research_subflow()
            
            # å‡†å¤‡å…³é”®è¯æ•°æ®
            keyword_data = {
                "current_keyword": keyword,
                "focus_areas": focus_areas,
                "project_context": project_context
            }
            
            subflows_and_data.append((keyword_subflow, keyword_data))
        
        # å­˜å‚¨åˆ°å®ä¾‹å˜é‡ï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜
        self._subflows_and_data = subflows_and_data
        
        # è¿”å›å¯åºåˆ—åŒ–çš„æ•°æ®ç”¨äºtracing
        return {
            "keywords": research_keywords,
            "focus_areas": focus_areas,
            "project_context": project_context,
            "total_keywords": len(research_keywords),
            "execution_start_time": asyncio.get_event_loop().time(),
            "streaming_session": shared.get("streaming_session")
        }

    async def exec_async(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """å¹¶å‘æ‰§è¡Œå…³é”®è¯ç ”ç©¶"""
        
        if "error" in prep_res:
            raise ValueError(prep_res["error"])
        
        subflows_and_data = self._subflows_and_data
        keywords = prep_res["keywords"]

        # å‘é€å¤„ç†çŠ¶æ€äº‹ä»¶
        await emit_processing_status_from_prep(
            prep_res,
            f"ğŸš€ å¼€å§‹å¹¶å‘æ‰§è¡Œ {len(subflows_and_data)} ä¸ªå…³é”®è¯ç ”ç©¶..."
        )

        start_time = asyncio.get_event_loop().time()
        
        # ğŸ”§ å…³é”®ï¼šåœ¨å•ä¸ªèŠ‚ç‚¹å†…éƒ¨å¹¶å‘æ‰§è¡Œæ‰€æœ‰å­æµç¨‹
        results = await asyncio.gather(*[
            subflow.run_async(data)
            for subflow, data in subflows_and_data
        ], return_exceptions=True)
        
        execution_time = asyncio.get_event_loop().time() - start_time
        
        # åˆ†æç»“æœ
        successful_results = []
        failed_results = []
        
        for i, (result, (subflow, data)) in enumerate(zip(results, subflows_and_data)):
            keyword = data["current_keyword"]
            
            if isinstance(result, Exception):
                # å‘é€é”™è¯¯äº‹ä»¶
                await emit_error_from_prep(
                    prep_res,
                    f"âš ï¸ å…³é”®è¯ '{keyword}' å¤„ç†å¤±è´¥: {result}"
                )

                failed_results.append({
                    "keyword": keyword,
                    "error": str(result)
                })
            else:
                # ä»å­æµç¨‹çš„sharedå­—å…¸ä¸­è·å–ç»“æœ
                keyword_result = data.get("keyword_report", {})
                successful_results.append({
                    "keyword": keyword,
                    "result": keyword_result
                })
        
        successful_count = len(successful_results)
        failed_count = len(failed_results)
        
        
        # å­˜å‚¨ç»“æœåˆ°å®ä¾‹å˜é‡
        self._execution_results = {
            "successful_results": successful_results,
            "failed_results": failed_results
        }
        
        # è¿”å›å¯åºåˆ—åŒ–çš„æ‰§è¡Œç»“æœ
        return {
            "execution_time": execution_time,
            "statistics": {
                "total": len(keywords),
                "successful": successful_count,
                "failed": failed_count
            },
            "keywords_processed": keywords,
            "success_rate": successful_count / len(keywords) if keywords else 0
        }

    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """å¤„ç†å¹¶å‘ç ”ç©¶ç»“æœ"""
        
        statistics = exec_res["statistics"]
        execution_time = exec_res["execution_time"]
        success_rate = exec_res["success_rate"]
        
        # ä»å®ä¾‹å˜é‡è·å–è¯¦ç»†ç»“æœ
        execution_results = self._execution_results
        successful_results = execution_results["successful_results"]
        failed_results = execution_results["failed_results"]
        
        # æ„å»ºæœ€ç»ˆçš„ç ”ç©¶ç»“æœ
        keyword_results = []
        
        # æ·»åŠ æˆåŠŸçš„ç»“æœ
        for item in successful_results:
            keyword_results.append({
                "keyword": item["keyword"],
                "success": True,
                "result": item["result"]
            })
        
        # æ·»åŠ å¤±è´¥çš„ç»“æœ
        for item in failed_results:
            keyword_results.append({
                "keyword": item["keyword"],
                "success": False,
                "error": item["error"]
            })
        
        # ç”Ÿæˆç ”ç©¶æ‘˜è¦
        summary = self._generate_summary(
            prep_res["keywords"], 
            prep_res["focus_areas"], 
            statistics["successful"], 
            statistics["total"]
        )
        
        # æ„å»ºæœ€ç»ˆçš„research_findings
        research_findings = {
            "project_context": prep_res["project_context"],
            "research_keywords": prep_res["keywords"],
            "focus_areas": prep_res["focus_areas"],
            "total_keywords": statistics["total"],
            "successful_keywords": statistics["successful"],
            "failed_keywords": statistics["failed"],
            "keyword_results": keyword_results,
            "summary": summary,
            "execution_time": execution_time,
            "success_rate": success_rate
        }
        
        # ä¿å­˜åˆ°sharedçŠ¶æ€
        shared["research_findings"] = research_findings
        shared["concurrent_statistics"] = statistics
        shared["concurrent_execution_time"] = execution_time
        
        # ç¡®å®šæˆåŠŸçŠ¶æ€
        if success_rate >= 0.8:  # 80%æˆåŠŸç‡
            shared["research_status"] = "success"
            # å‘é€æˆåŠŸäº‹ä»¶
            await emit_processing_status(
                shared,
                f"ğŸ‰ å¹¶å‘ç ”ç©¶æˆåŠŸ: {success_rate:.1%} æˆåŠŸç‡"
            )
            return "research_complete"
        elif success_rate >= 0.5:  # 50%æˆåŠŸç‡
            shared["research_status"] = "partial_success"
            # å‘é€éƒ¨åˆ†æˆåŠŸäº‹ä»¶
            await emit_processing_status(
                shared,
                f"âš ï¸ å¹¶å‘ç ”ç©¶éƒ¨åˆ†æˆåŠŸ: {success_rate:.1%} æˆåŠŸç‡"
            )
            return "research_partial"
        else:
            shared["research_status"] = "failed"
            # å‘é€å¤±è´¥äº‹ä»¶
            await emit_error(
                shared,
                f"âŒ å¹¶å‘ç ”ç©¶å¤±è´¥: {success_rate:.1%} æˆåŠŸç‡"
            )
            return "research_failed"

    def _generate_summary(self, keywords: List[str], focus_areas: List[str], successful: int, total: int) -> str:
        """ç”Ÿæˆç ”ç©¶æ‘˜è¦"""
        
        if successful == 0:
            return "ç ”ç©¶è¿‡ç¨‹ä¸­æœªèƒ½è·å¾—æœ‰æ•ˆç»“æœã€‚"
        
        summary_parts = [
            f"é’ˆå¯¹ {total} ä¸ªå…³é”®è¯è¿›è¡Œäº†æŠ€æœ¯è°ƒç ”",
            f"æˆåŠŸå¤„ç†äº† {successful} ä¸ªå…³é”®è¯",
            f"ä¸»è¦å…³æ³¨ç‚¹åŒ…æ‹¬: {', '.join(focus_areas)}"
        ]
        
        return "ã€‚".join(summary_parts) + "ã€‚"
