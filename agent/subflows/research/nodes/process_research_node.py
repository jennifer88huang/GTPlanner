"""
ç ”ç©¶å¤„ç†èŠ‚ç‚¹
è´Ÿè´£ç®¡ç†ç ”ç©¶å¤„ç†çŠ¶æ€ï¼Œåè°ƒResearch Agentçš„æ‰§è¡Œ
"""

import json
import time
from pocketflow import AsyncNode
from ..flows.research_flow import ResearchFlow
from agent.shared_migration import field_validation_decorator


class ProcessResearch(AsyncNode):
    """ç ”ç©¶å¤„ç†èŠ‚ç‚¹ - ç®¡ç†ç ”ç©¶å¤„ç†çŠ¶æ€"""

    def __init__(self):
        super().__init__()
        self.subflow = ResearchFlow()


    
    @field_validation_decorator(validation_enabled=True, strict_mode=False)



    
    async def prep_async(self, shared):
        """å‡†å¤‡ç ”ç©¶å¤„ç† - ä½¿ç”¨pocketflowå­—å…¸å…±äº«å˜é‡"""
        # ä»å…±äº«å˜é‡ä¸­æå–ç ”ç©¶å…³é”®è¯
        research_keywords = []

        # ä»ç”¨æˆ·æ„å›¾ä¸­è·å–å…³é”®è¯
        user_intent = shared.get("user_intent", {})
        extracted_keywords = user_intent.get("extracted_keywords", [])
        if extracted_keywords:
            research_keywords.extend(extracted_keywords[:3])

        # ä»ç»“æ„åŒ–éœ€æ±‚ä¸­è·å–å…³é”®è¯
        structured_requirements = shared.get("structured_requirements", {})
        if structured_requirements:
            # ä»é¡¹ç›®æ¦‚è§ˆè·å–æ ‡é¢˜
            project_overview = structured_requirements.get("project_overview", {})
            project_title = project_overview.get("title", "")
            if project_title and project_title not in research_keywords:
                research_keywords.append(project_title)

            # ä»æ ¸å¿ƒåŠŸèƒ½è·å–å…³é”®è¯
            functional_requirements = structured_requirements.get("functional_requirements", {})
            core_features = functional_requirements.get("core_features", [])
            for feature in core_features[:2]:  # é™åˆ¶æ•°é‡
                if isinstance(feature, dict):
                    feature_name = feature.get("name", "")
                elif isinstance(feature, str):
                    feature_name = feature
                else:
                    feature_name = str(feature) if feature else ""

                if feature_name and feature_name not in research_keywords:
                    research_keywords.append(feature_name)

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        research_keywords = list(set(research_keywords))[:5]

        if not research_keywords:
            # å¦‚æœæ— æ³•æå–å…³é”®è¯ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯
            research_keywords = ["é¡¹ç›®å¼€å‘", "æŠ€æœ¯é€‰å‹", "æœ€ä½³å®è·µ"]
            print("âš ï¸ æ— æ³•ä»å…±äº«çŠ¶æ€æå–å…³é”®è¯ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯")

        # è·å–ç”¨æˆ·éœ€æ±‚
        requirements = {}
        if structured_requirements:
            project_overview = structured_requirements.get("project_overview", {})
            requirements = {
                "project_title": project_overview.get("title", ""),
                "project_description": project_overview.get("description", ""),
                "objectives": project_overview.get("objectives", [])
            }

        return {
            "research_keywords": research_keywords,
            "requirements": requirements,
            "total_keywords": len(research_keywords)
        }
    
    @field_validation_decorator(validation_enabled=True, strict_mode=False)

    
    async def exec_async(self, data):
        """æ‰§è¡Œç ”ç©¶å¤„ç† - æŒ‰ç…§æ¶æ„æ–‡æ¡£å®ç°"""
        research_keywords = data["research_keywords"]
        requirements = data["requirements"]
        total_keywords = data["total_keywords"]
        
        print(f"ğŸ”„ å¼€å§‹ç ”ç©¶å¤„ç†ï¼Œå…³é”®è¯: {research_keywords}")
        
        try:
            # æ„å»ºåˆ†æéœ€æ±‚æè¿°
            analysis_requirements = self._build_analysis_requirements(requirements)

            # ä½¿ç”¨å­æµç¨‹å¤„ç†ç ”ç©¶å…³é”®è¯ï¼ˆæŒ‰ç…§æ¶æ„æ–‡æ¡£çš„æµç¨‹ï¼‰
            result = self.subflow.process_research_keywords(research_keywords, analysis_requirements)

            if not result.get("success"):
                raise Exception(f"ç ”ç©¶å­æµç¨‹å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # æå–å¤„ç†ç»“æœ
            research_report = result.get("research_report", [])
            aggregated_summary = result.get("aggregated_summary", {})
            successful_keywords = result.get("successful_keywords", 0)

            print(f"âœ… ç ”ç©¶å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {successful_keywords}/{total_keywords} ä¸ªå…³é”®è¯")

            return {
                "keywords": research_keywords,
                "result": result,
                "processing_success": True,
                "research_report": research_report,
                "aggregated_summary": aggregated_summary,
                "successful_keywords": successful_keywords,
                "total_keywords": total_keywords
            }
            
        except Exception as e:
            error_msg = f"ç ”ç©¶å¤„ç†å¤±è´¥: {str(e)}"
            print(f"[ERROR] {error_msg}")
            
            return {
                "keywords": research_keywords,
                "result": None,
                "processing_success": False,
                "error": error_msg,
                "research_report": [],
                "aggregated_summary": {},
                "successful_keywords": 0,
                "total_keywords": total_keywords
            }
    
    @field_validation_decorator(validation_enabled=True, strict_mode=False)

    
    async def post_async(self, shared, prep_res, exec_res):
        """ä¿å­˜ç ”ç©¶ç»“æœå¹¶æ›´æ–°çŠ¶æ€ - ä½¿ç”¨pocketflowå­—å…¸å…±äº«å˜é‡"""
        # æ£€æŸ¥æ‰§è¡Œç»“æœ
        if "error" in exec_res:
            shared["research_error"] = exec_res["error"]
            shared["current_stage"] = "research_failed"
            return "error"

        keywords = exec_res.get("keywords", [])
        result = exec_res.get("result")
        success = exec_res.get("processing_success", False)

        # ä»å­æµç¨‹ç»“æœä¸­æå–æ•°æ®
        research_report = exec_res.get("research_report", [])
        aggregated_summary = exec_res.get("aggregated_summary", {})
        successful_keywords = exec_res.get("successful_keywords", 0)
        total_keywords = exec_res.get("total_keywords", 0)

        # ä¿å­˜ç ”ç©¶ç»“æœåˆ°å…±äº«å˜é‡
        if success and result:
            # åˆ›å»ºç ”ç©¶å‘ç°æ•°æ®ç»“æ„
            research_findings = {
                "research_report": research_report,
                "aggregated_summary": aggregated_summary,
                "research_metadata": {
                    "research_keywords": keywords,
                    "total_keywords": total_keywords,
                    "successful_keywords": successful_keywords,
                    "success_rate": successful_keywords / total_keywords if total_keywords > 0 else 0,
                    "research_completed_at": time.time(),
                    "research_success": True
                }
            }

            # ä¿å­˜åˆ°å…±äº«å˜é‡
            shared["research_findings"] = research_findings

        # æ›´æ–°å¤„ç†é˜¶æ®µ
        shared["current_stage"] = "research_completed"

        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        system_messages = shared.get("system_messages", [])
        system_messages.append({
            "message": f"ç ”ç©¶è°ƒç ”å®Œæˆï¼ŒæˆåŠŸå¤„ç† {successful_keywords}/{total_keywords} ä¸ªå…³é”®è¯",
            "agent_source": "ProcessResearch",
            "timestamp": time.time(),
            "keywords": keywords,
            "successful_keywords": successful_keywords,
            "total_keywords": total_keywords,
            "success": success
        })
        shared["system_messages"] = system_messages

        # æ›´æ–°å…ƒæ•°æ®
        metadata = shared.get("metadata", {})
        processing_stages = metadata.get("processing_stages", [])
        if "research" not in processing_stages:
            processing_stages.append("research")
        metadata.update({
            "processing_stages": processing_stages,
            "last_updated": time.time(),
            "total_processing_time": metadata.get("total_processing_time", 0) + 50.0  # ä¼°ç®—å¤„ç†æ—¶é—´
        })
        shared["metadata"] = metadata

        print(f"âœ… ç ”ç©¶å¤„ç†å®Œæˆï¼Œç”Ÿæˆäº† {len(research_report)} ä¸ªå…³é”®è¯æŠ¥å‘Š")

        # è¿”å›ä¸‹ä¸€æ­¥åŠ¨ä½œ - åŸºäºpocketflowæœ€ä½³å®è·µ
        if success and successful_keywords > 0:
            return "success"  # æˆåŠŸå®Œæˆï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        else:
            return "failed"   # å¤„ç†å¤±è´¥ï¼Œéœ€è¦é”™è¯¯å¤„ç†
    
    def _build_analysis_requirements(self, requirements):
        """æ„å»ºåˆ†æéœ€æ±‚æè¿°"""
        analysis_parts = []
        
        if requirements.get("project_title"):
            analysis_parts.append(f"é¡¹ç›®èƒŒæ™¯ï¼š{requirements['project_title']}")
        
        if requirements.get("project_description"):
            analysis_parts.append(f"é¡¹ç›®æè¿°ï¼š{requirements['project_description']}")
        
        if requirements.get("objectives"):
            objectives_text = "ã€".join(requirements["objectives"])
            analysis_parts.append(f"é¡¹ç›®ç›®æ ‡ï¼š{objectives_text}")
        
        # é»˜è®¤åˆ†æéœ€æ±‚
        analysis_parts.append("è¯·é‡ç‚¹å…³æ³¨ï¼šæŠ€æœ¯å®ç°æ–¹æ¡ˆã€æœ€ä½³å®è·µã€ç›¸å…³å·¥å…·å’Œæ¡†æ¶ã€æ½œåœ¨é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ")
        
        return "\n".join(analysis_parts)
