"""
Research Agent å®Œæ•´æµ‹è¯•

åŸºäºpocketflowæœ€ä½³å®è·µçš„å®Œæ•´æµ‹è¯•ï¼ŒéªŒè¯Research Agentçš„æ‰€æœ‰åŠŸèƒ½
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))

from agent.subflows.research import (
    ProcessResearch,
    ResearchFlow,
    create_keyword_research_subflow,
    LLMAnalysisNode,
    ResultAssemblyNode,
    ResearchAggregator
)
from utils.config_manager import get_jina_api_key, get_all_config


def test_config_and_imports():
    """æµ‹è¯•é…ç½®å’Œå¯¼å…¥"""
    print("ğŸ” æµ‹è¯•é…ç½®å’Œå¯¼å…¥...")
    
    # æµ‹è¯•JINA APIå¯†é’¥
    jina_key = get_jina_api_key()
    if jina_key:
        print(f"âœ… JINA APIå¯†é’¥å·²é…ç½®: {jina_key[:10]}...")
    else:
        print("âŒ JINA APIå¯†é’¥æœªé…ç½®")
        return False
    
    # æµ‹è¯•ç»„ä»¶å¯¼å…¥
    try:
        process_node = ProcessResearch()
        research_flow = ResearchFlow()
        subflow = create_keyword_research_subflow()
        aggregator = ResearchAggregator()
        llm_node = LLMAnalysisNode()
        assembly_node = ResultAssemblyNode()
        
        print("âœ… æ‰€æœ‰Research Agentç»„ä»¶å¯¼å…¥å’Œå®ä¾‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_process_research_prep():
    """æµ‹è¯•ProcessResearchçš„prepæ–¹æ³•"""
    print("\nğŸ” æµ‹è¯•ProcessResearchçš„prepæ–¹æ³•...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„pocketflowå­—å…¸å…±äº«å˜é‡
    mock_shared = {
        "user_intent": {
            "extracted_keywords": ["Python", "æœºå™¨å­¦ä¹ ", "API"]
        },
        "structured_requirements": {
            "project_overview": {
                "title": "æ™ºèƒ½æ•°æ®åˆ†æå¹³å°",
                "description": "åŸºäºæœºå™¨å­¦ä¹ çš„æ•°æ®åˆ†æå¹³å°",
                "objectives": ["æé«˜æ•°æ®å¤„ç†æ•ˆç‡", "å®ç°æ™ºèƒ½åˆ†æ"]
            },
            "functional_requirements": {
                "core_features": [
                    {"name": "æ•°æ®å¯¼å…¥"},
                    {"name": "æ¨¡å‹è®­ç»ƒ"}
                ]
            }
        }
    }
    
    try:
        process_node = ProcessResearch()
        prep_result = process_node.prep(mock_shared)
        
        print(f"âœ… prepæ–¹æ³•æ‰§è¡ŒæˆåŠŸ")
        print(f"   æå–çš„å…³é”®è¯: {prep_result['research_keywords']}")
        print(f"   å…³é”®è¯æ•°é‡: {prep_result['total_keywords']}")
        
        # éªŒè¯ç»“æœ
        assert "research_keywords" in prep_result
        assert "requirements" in prep_result
        assert "total_keywords" in prep_result
        assert len(prep_result["research_keywords"]) > 0
        
        return prep_result
        
    except Exception as e:
        print(f"âŒ ProcessResearch prepæ–¹æ³•æµ‹è¯•å¤±è´¥: {e}")
        return None


def test_keyword_subflow():
    """æµ‹è¯•å•ä¸ªå…³é”®è¯çš„å­æµç¨‹"""
    print("\nğŸ” æµ‹è¯•å•ä¸ªå…³é”®è¯çš„å­æµç¨‹...")
    
    try:
        # åˆ›å»ºå­æµç¨‹
        subflow = create_keyword_research_subflow()
        
        # å‡†å¤‡å­æµç¨‹çš„å…±äº«å˜é‡ï¼ˆpocketflowå­—å…¸æ ¼å¼ï¼‰
        subflow_shared = {
            "current_keyword": "Pythonç¼–ç¨‹",
            "analysis_requirements": "é‡ç‚¹å…³æ³¨Pythonç¼–ç¨‹çš„åŸºç¡€æ¦‚å¿µå’Œåº”ç”¨åœºæ™¯",
            "search_keywords": ["Pythonç¼–ç¨‹"],
            "max_search_results": 3,
            
            # ç”¨äºå­˜å‚¨æµç¨‹ä¸­çš„æ•°æ®
            "first_search_result": {},
            "all_search_results": [],
            "url_content": "",
            "url_title": "",
            "url_metadata": {},
            "llm_analysis": {},
            "analyzed_keyword": "",
            "keyword_report": {}
        }
        
        print("   æ‰§è¡Œå­æµç¨‹...")
        flow_result = subflow.run(subflow_shared)
        
        # æ£€æŸ¥ç»“æœ
        keyword_report = subflow_shared.get("keyword_report", {})
        
        if flow_result and keyword_report:
            print("âœ… å­æµç¨‹æ‰§è¡ŒæˆåŠŸ")
            print(f"   å…³é”®è¯: {keyword_report.get('keyword')}")
            print(f"   URL: {keyword_report.get('url', '')[:50]}...")
            print(f"   å†…å®¹é•¿åº¦: {len(keyword_report.get('content', ''))}")
            
            analysis = keyword_report.get('analysis', {})
            if analysis:
                print(f"   ç›¸å…³æ€§åˆ†æ•°: {analysis.get('relevance_score', 0)}")
                insights = analysis.get('key_insights', [])
                print(f"   æ´å¯Ÿæ•°é‡: {len(insights)}")
                if insights:
                    print(f"   ç¬¬ä¸€ä¸ªæ´å¯Ÿ: {insights[0][:50]}...")
            
            return keyword_report
        else:
            print("âŒ å­æµç¨‹æ‰§è¡Œå¤±è´¥æˆ–æ— ç»“æœ")
            print(f"   flow_result: {flow_result}")
            print(f"   keyword_report keys: {list(keyword_report.keys()) if keyword_report else 'None'}")
            return None
            
    except Exception as e:
        print(f"âŒ å­æµç¨‹æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_research_flow_concurrent():
    """æµ‹è¯•å¹¶å‘ç ”ç©¶æµç¨‹"""
    print("\nğŸ” æµ‹è¯•å¹¶å‘ç ”ç©¶æµç¨‹...")
    
    try:
        research_flow = ResearchFlow()
        
        # æµ‹è¯•å¤šä¸ªå…³é”®è¯çš„å¹¶å‘å¤„ç†
        test_keywords = ["Pythonç¼–ç¨‹", "æœºå™¨å­¦ä¹ "]
        analysis_requirements = "é‡ç‚¹å…³æ³¨æŠ€æœ¯å®ç°æ–¹æ¡ˆã€æœ€ä½³å®è·µã€ç›¸å…³å·¥å…·å’Œæ¡†æ¶"
        
        print(f"   å¹¶å‘å¤„ç†å…³é”®è¯: {test_keywords}")
        
        result = research_flow.process_research_keywords(test_keywords, analysis_requirements)
        
        if result.get("success"):
            research_report = result.get("research_report", [])
            aggregated_summary = result.get("aggregated_summary", {})
            
            print(f"âœ… å¹¶å‘å¤„ç†æˆåŠŸï¼Œè·å¾— {len(research_report)} ä¸ªç»“æœ")
            print(f"   æˆåŠŸå…³é”®è¯: {result.get('successful_keywords')}/{result.get('total_keywords')}")
            
            if research_report:
                print(f"   ç¬¬ä¸€ä¸ªç»“æœå…³é”®è¯: {research_report[0].get('keyword')}")
                print(f"   ç¬¬ä¸€ä¸ªç»“æœURL: {research_report[0].get('url', '')[:50]}...")
            
            if aggregated_summary:
                coverage = aggregated_summary.get('coverage_analysis', {})
                print(f"   å¹³å‡ç›¸å…³æ€§: {coverage.get('average_relevance', 0)}")
                print(f"   é«˜è´¨é‡ç»“æœ: {coverage.get('high_quality_results', 0)}")
            
            return result
        else:
            print(f"âŒ å¹¶å‘å¤„ç†å¤±è´¥: {result.get('error')}")
            return None
            
    except Exception as e:
        print(f"âŒ å¹¶å‘ç ”ç©¶æµç¨‹æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_process_research_complete():
    """æµ‹è¯•ProcessResearchçš„å®Œæ•´æµç¨‹"""
    print("\nğŸ” æµ‹è¯•ProcessResearchçš„å®Œæ•´æµç¨‹...")
    
    # åˆ›å»ºå®Œæ•´çš„æ¨¡æ‹Ÿå…±äº«çŠ¶æ€
    mock_shared = {
        "user_intent": {
            "extracted_keywords": ["Python", "æœºå™¨å­¦ä¹ ", "API"]
        },
        "structured_requirements": {
            "project_overview": {
                "title": "æ™ºèƒ½æ•°æ®åˆ†æå¹³å°",
                "description": "åŸºäºæœºå™¨å­¦ä¹ çš„æ•°æ®åˆ†æå¹³å°",
                "objectives": ["æé«˜æ•°æ®å¤„ç†æ•ˆç‡", "å®ç°æ™ºèƒ½åˆ†æ"]
            },
            "functional_requirements": {
                "core_features": [
                    {"name": "æ•°æ®å¯¼å…¥"},
                    {"name": "æ¨¡å‹è®­ç»ƒ"}
                ]
            }
        },
        "current_stage": "requirements_completed",
        "system_messages": [],
        "metadata": {
            "processing_stages": ["requirements_analysis"],
            "total_processing_time": 100.0
        }
    }
    
    try:
        process_node = ProcessResearch()
        
        # æ‰§è¡Œprep
        prep_result = process_node.prep(mock_shared)
        print(f"   prepå®Œæˆï¼Œå…³é”®è¯: {prep_result['research_keywords']}")
        
        # æ‰§è¡Œexec
        exec_result = process_node.exec(prep_result)
        print(f"   execå®Œæˆï¼ŒæˆåŠŸ: {exec_result.get('processing_success')}")
        
        # æ‰§è¡Œpost
        post_result = process_node.post(mock_shared, prep_result, exec_result)
        print(f"   postå®Œæˆï¼Œè¿”å›: {post_result}")
        
        # æ£€æŸ¥å…±äº«çŠ¶æ€çš„å˜åŒ–
        print(f"   å½“å‰é˜¶æ®µ: {mock_shared.get('current_stage')}")
        print(f"   ç ”ç©¶å‘ç°: {'å·²åˆ›å»º' if mock_shared.get('research_findings') else 'æœªåˆ›å»º'}")
        print(f"   ç³»ç»Ÿæ¶ˆæ¯æ•°é‡: {len(mock_shared.get('system_messages', []))}")
        
        research_findings = mock_shared.get('research_findings', {})
        if research_findings:
            research_report = research_findings.get('research_report', [])
            print(f"   ç ”ç©¶æŠ¥å‘Šæ•°é‡: {len(research_report)}")
            
            metadata = research_findings.get('research_metadata', {})
            print(f"   æˆåŠŸç‡: {metadata.get('success_rate', 0):.2f}")
        
        return post_result == "success"
        
    except Exception as e:
        print(f"âŒ ProcessResearchå®Œæ•´æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è¿è¡ŒResearch Agentå®Œæ•´æµ‹è¯•...")
    print("=" * 60)
    
    test_results = []
    
    # 1. é…ç½®å’Œå¯¼å…¥æµ‹è¯•
    test_results.append(test_config_and_imports())
    
    # 2. ProcessResearch prepæµ‹è¯•
    prep_result = test_process_research_prep()
    test_results.append(prep_result is not None)
    
    # 3. å•ä¸ªå…³é”®è¯å­æµç¨‹æµ‹è¯•
    subflow_result = test_keyword_subflow()
    test_results.append(subflow_result is not None)
    
    # 4. å¹¶å‘ç ”ç©¶æµç¨‹æµ‹è¯•
    concurrent_result = test_research_flow_concurrent()
    test_results.append(concurrent_result is not None)
    
    # 5. ProcessResearchå®Œæ•´æµç¨‹æµ‹è¯•
    complete_result = test_process_research_complete()
    test_results.append(complete_result)
    
    # ç»Ÿè®¡ç»“æœ
    passed = sum(test_results)
    total = len(test_results)
    
    print("\n" + "=" * 60)
    print(f"ğŸ¯ æµ‹è¯•å®Œæˆ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Research Agentå·¥ä½œæ­£å¸¸ã€‚")
        print("\nâœ… éªŒè¯çš„åŠŸèƒ½:")
        print("   - é…ç½®ç®¡ç†å’Œç»„ä»¶å¯¼å…¥")
        print("   - ProcessResearchèŠ‚ç‚¹çš„prep/exec/postæ–¹æ³•")
        print("   - å•ä¸ªå…³é”®è¯çš„å®Œæ•´å­æµç¨‹")
        print("   - å¤šå…³é”®è¯çš„å¹¶å‘å¤„ç†")
        print("   - pocketflowå­—å…¸å…±äº«å˜é‡çš„æ­£ç¡®ä½¿ç”¨")
        print("   - çœŸå®APIè°ƒç”¨å’Œæ•°æ®æµ")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
    
    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1)
