"""
Research Agentä¸»æµç¨‹

æŒ‰ç…§æ¶æ„æ–‡æ¡£å®ç°ï¼šå¹¶è¡Œæ‰¹å¤„ç†ç‰ˆæœ¬
å¯¹æ¯ä¸ªå…³é”®è¯æ‰§è¡Œå®Œæ•´çš„å­æµç¨‹ï¼Œæœ€åèšåˆç»“æœ
"""

import concurrent.futures
from .keyword_research_flow import create_keyword_research_subflow
from ..utils.research_aggregator import ResearchAggregator


class ResearchFlow:
    """ç ”ç©¶è°ƒç ”å­æµç¨‹åŒ…è£…å™¨"""
    
    def __init__(self):
        self.subflow = create_keyword_research_subflow()
        self.aggregator = ResearchAggregator()
    
    def process_research_keywords(self, search_keywords, analysis_requirements):
        """
        ä½¿ç”¨å¹¶å‘æ‰¹å¤„ç†å¤„ç†ç ”ç©¶å…³é”®è¯

        å¯¹æ¯ä¸ªå…³é”®è¯å¹¶å‘æ‰§è¡Œå®Œæ•´çš„å­æµç¨‹ï¼šæœç´¢ â†’ URLè§£æ â†’ LLMåˆ†æ â†’ ç»“æœç»„è£…

        Args:
            search_keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            analysis_requirements: åˆ†æéœ€æ±‚æè¿°

        Returns:
            research_report: èšåˆåçš„ç ”ç©¶æŠ¥å‘Šåˆ—è¡¨
        """
        print(f"ğŸ”„ å¼€å§‹å¹¶å‘ç ”ç©¶å¤„ç†ï¼Œå…³é”®è¯: {search_keywords}")

        research_report = []

        try:
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†å…³é”®è¯
            with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(search_keywords), 3)) as executor:
                # æäº¤æ‰€æœ‰å…³é”®è¯å¤„ç†ä»»åŠ¡
                future_to_keyword = {
                    executor.submit(self._process_single_keyword, keyword, analysis_requirements): keyword
                    for keyword in search_keywords
                }

                # æ”¶é›†ç»“æœ
                for future in concurrent.futures.as_completed(future_to_keyword):
                    keyword = future_to_keyword[future]
                    try:
                        keyword_result = future.result()
                        if keyword_result and keyword_result.get("success"):
                            research_report.append(keyword_result["keyword_report"])
                            print(f"âœ… å®Œæˆå…³é”®è¯: {keyword}")
                        else:
                            print(f"âŒ å…³é”®è¯å¤„ç†å¤±è´¥: {keyword}")
                    except Exception as e:
                        print(f"âŒ å…³é”®è¯ {keyword} å¤„ç†å‡ºé”™: {e}")

            # 3. ç»“æœèšåˆ
            aggregated_report = self.aggregator.aggregate_research_results(research_report)

            print(f"âœ… å¹¶å‘ç ”ç©¶å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(research_report)} ä¸ªå…³é”®è¯æŠ¥å‘Š")

            return {
                "success": True,
                "research_report": research_report,
                "aggregated_summary": aggregated_report,
                "total_keywords": len(search_keywords),
                "successful_keywords": len(research_report)
            }

        except Exception as e:
            print(f"âŒ å¹¶å‘ç ”ç©¶å¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "research_report": research_report,
                "total_keywords": len(search_keywords),
                "successful_keywords": len(research_report)
            }

    def _process_single_keyword(self, keyword, analysis_requirements):
        """å¤„ç†å•ä¸ªå…³é”®è¯"""
        print(f"ğŸ” å¤„ç†å…³é”®è¯: {keyword}")

        # ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºç‹¬ç«‹çš„å­æµç¨‹å®ä¾‹
        subflow = create_keyword_research_subflow()

        # å‡†å¤‡å­æµç¨‹çš„å…±äº«å˜é‡
        subflow_shared = {
            "current_keyword": keyword,
            "analysis_requirements": analysis_requirements,
            "search_keywords": [keyword],  # ä¼ é€’ç»™æœç´¢èŠ‚ç‚¹
            "max_search_results": 5,

            # ç”¨äºå­˜å‚¨æµç¨‹ä¸­çš„æ•°æ®
            "first_search_result": {},
            "url_content": "",
            "llm_analysis": {},
            "keyword_report": {}
        }

        try:
            # æ‰§è¡Œå­æµç¨‹
            flow_result = subflow.run(subflow_shared)

            # æ£€æŸ¥flow_resultå’Œå…±äº«å˜é‡ä¸­çš„ç»“æœ
            keyword_report = subflow_shared.get("keyword_report", {})

            # éªŒè¯æµç¨‹æ˜¯å¦æˆåŠŸæ‰§è¡Œ
            if flow_result and keyword_report:
                return {
                    "success": True,
                    "keyword_report": keyword_report,
                    "flow_result": flow_result
                }
            else:
                return {
                    "success": False,
                    "error": f"Flow execution failed or no report generated",
                    "flow_result": flow_result
                }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "flow_result": None
            }
