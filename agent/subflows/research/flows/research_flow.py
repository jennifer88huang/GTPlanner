"""
ç ”ç©¶è°ƒç ”æµç¨‹ - å®Œå…¨é‡æ„ç‰ˆæœ¬
å®Œå…¨æ¨¡ä»¿å®˜æ–¹ç¤ºä¾‹çš„å¹¶å‘å®ç°æ–¹å¼
"""

import asyncio
import os
from typing import Dict, List, Any
from pocketflow_tracing import trace_flow
from pocketflow import AsyncFlow, AsyncNode
from .keyword_research_flow import create_keyword_research_subflow
from agent.streaming import (
    emit_processing_status_from_prep,
    emit_error_from_prep,
    emit_processing_status,
    emit_error
)


class ConcurrentResearchNode(AsyncNode):
    """å¹¶å‘ç ”ç©¶èŠ‚ç‚¹ - åœ¨ResearchFlowå†…éƒ¨å¤„ç†å¹¶å‘"""

    def __init__(self):
        super().__init__()
        self.name = "concurrent_research"
        self._subflows_and_data = []
        self._execution_results = []

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡å¹¶å‘ç ”ç©¶å‚æ•°"""

        # è·å–ç ”ç©¶å‚æ•°
        research_keywords = shared.get("research_keywords", [])
        focus_areas = shared.get("focus_areas", [])
        project_context = shared.get("project_context", "")

        # åˆ›å»ºå­æµç¨‹åˆ—è¡¨ï¼Œä½†ä¸åˆ›å»ºå•ç‹¬çš„æ•°æ®å­—å…¸
        # è€Œæ˜¯ç›´æ¥ä½¿ç”¨ä¸»sharedå­—å…¸ï¼Œåªæ˜¯ä¸ºæ¯ä¸ªå…³é”®è¯è®¾ç½®å½“å‰å…³é”®è¯
        subflows_and_keywords = []
        for keyword in research_keywords:
            keyword_subflow = create_keyword_research_subflow()
            subflows_and_keywords.append((keyword_subflow, keyword))

        # å­˜å‚¨åˆ°å®ä¾‹å˜é‡
        self._subflows_and_keywords = subflows_and_keywords

        return {
            "keywords": research_keywords,
            "focus_areas": focus_areas,
            "project_context": project_context,
            "total_keywords": len(research_keywords),
            "execution_start_time": asyncio.get_event_loop().time(),
            "streaming_session": shared.get("streaming_session")
        }

    async def exec_async(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """å¹¶å‘æ‰§è¡Œå…³é”®è¯ç ”ç©¶"""

        subflows_and_keywords = self._subflows_and_keywords
        keywords = prep_res["keywords"]

        # å‘é€å¤„ç†çŠ¶æ€äº‹ä»¶
        await emit_processing_status_from_prep(
            prep_res,
            f"ğŸš€ å¼€å§‹å¹¶å‘æ‰§è¡Œ {len(subflows_and_keywords)} ä¸ªå…³é”®è¯ç ”ç©¶..."
        )

        start_time = asyncio.get_event_loop().time()

        # ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºç‹¬ç«‹çš„sharedå­—å…¸å‰¯æœ¬ï¼Œä½†åŒ…å«å½“å‰å…³é”®è¯ä¿¡æ¯
        async def run_keyword_research(subflow, keyword, shared_template):
            # åˆ›å»ºè¯¥å…³é”®è¯çš„sharedå­—å…¸å‰¯æœ¬
            keyword_shared = shared_template.copy()
            keyword_shared["current_keyword"] = keyword

            # è¿è¡Œå­æµç¨‹
            result = await subflow.run_async(keyword_shared)

            # è¿”å›å…³é”®è¯å’Œç»“æœ
            return keyword, keyword_shared.get("research_findings", {}), result

        # åˆ›å»ºsharedæ¨¡æ¿ï¼ˆåŒ…å«æ‰€æœ‰å…¬å…±æ•°æ®ï¼‰
        shared_template = {
            "focus_areas": prep_res["focus_areas"],
            "project_context": prep_res["project_context"],
            "streaming_session": prep_res.get("streaming_session")
        }

        # ğŸ”§ å…³é”®ï¼šåœ¨èŠ‚ç‚¹å†…éƒ¨å¹¶å‘æ‰§è¡Œæ‰€æœ‰å­æµç¨‹
        results = await asyncio.gather(*[
            run_keyword_research(subflow, keyword, shared_template)
            for subflow, keyword in subflows_and_keywords
        ], return_exceptions=True)

        execution_time = asyncio.get_event_loop().time() - start_time

        # åˆ†æç»“æœ
        successful_results = []
        failed_results = []

        for result in results:
            if isinstance(result, Exception):
                # å‘é€é”™è¯¯äº‹ä»¶
                await emit_error_from_prep(
                    prep_res,
                    f"âš ï¸ å…³é”®è¯ç ”ç©¶å¤„ç†å¤±è´¥: {result}"
                )

                failed_results.append({
                    "keyword": "unknown",
                    "error": str(result)
                })
            else:
                keyword, keyword_result, _ = result  # å¿½ç•¥ subflow_result

                if keyword_result:  # å¦‚æœæœ‰ç ”ç©¶ç»“æœ
                    successful_results.append({
                        "keyword": keyword,
                        "result": keyword_result
                    })
                else:
                    failed_results.append({
                        "keyword": keyword,
                        "error": "No research findings generated"
                    })

        successful_count = len(successful_results)
        failed_count = len(failed_results)

        # å­˜å‚¨ç»“æœåˆ°å®ä¾‹å˜é‡
        self._execution_results = {
            "successful_results": successful_results,
            "failed_results": failed_results
        }

        return {
            "execution_time": execution_time,
            "statistics": {
                "total": len(keywords),
                "successful": successful_count,
                "failed": failed_count
            },
            "success_rate": successful_count / len(keywords) if keywords else 0
        }

    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """å¤„ç†å¹¶å‘ç ”ç©¶ç»“æœ"""

        statistics = exec_res["statistics"]
        success_rate = exec_res["success_rate"]

        # ä»å®ä¾‹å˜é‡è·å–è¯¦ç»†ç»“æœ
        execution_results = self._execution_results
        successful_results = execution_results["successful_results"]
        failed_results = execution_results["failed_results"]

        # æ„å»ºæœ€ç»ˆçš„ç ”ç©¶ç»“æœ
        keyword_results = []

        # æ·»åŠ æˆåŠŸçš„ç»“æœ
        for item in successful_results:
            keyword_results.append({
                "keyword": item["keyword"],
                "success": True,
                "result": item["result"]
            })

        # æ·»åŠ å¤±è´¥çš„ç»“æœ
        for item in failed_results:
            keyword_results.append({
                "keyword": item["keyword"],
                "success": False,
                "error": item["error"]
            })

        # ç”Ÿæˆç ”ç©¶æ‘˜è¦
        summary = self._generate_summary(
            prep_res["keywords"],
            prep_res["focus_areas"],
            statistics["successful"],
            statistics["total"]
        )

        # æ„å»ºæœ€ç»ˆçš„research_findings
        research_findings = {
            "project_context": prep_res["project_context"],
            "research_keywords": prep_res["keywords"],
            "focus_areas": prep_res["focus_areas"],
            "total_keywords": statistics["total"],
            "successful_keywords": statistics["successful"],
            "failed_keywords": statistics["failed"],
            "keyword_results": keyword_results,
            "summary": summary,
            "execution_time": exec_res["execution_time"],
            "success_rate": success_rate
        }

        # ä¿å­˜åˆ°sharedçŠ¶æ€
        shared["research_findings"] = research_findings

        return "research_complete"

    def _generate_summary(self, keywords: List[str], focus_areas: List[str], successful: int, total: int) -> str:
        """ç”Ÿæˆç ”ç©¶æ‘˜è¦"""

        if successful == 0:
            return "ç ”ç©¶è¿‡ç¨‹ä¸­æœªèƒ½è·å¾—æœ‰æ•ˆç»“æœã€‚"

        summary_parts = [
            f"é’ˆå¯¹ {total} ä¸ªå…³é”®è¯è¿›è¡Œäº†æŠ€æœ¯è°ƒç ”",
            f"æˆåŠŸå¤„ç†äº† {successful} ä¸ªå…³é”®è¯",
            f"ä¸»è¦å…³æ³¨ç‚¹åŒ…æ‹¬: {', '.join(focus_areas)}"
        ]

        return "ã€‚".join(summary_parts) + "ã€‚"


@trace_flow(flow_name="ResearchFlow")
class TracedResearchFlow(AsyncFlow):
    """å¸¦tracingçš„ç ”ç©¶è°ƒç ”æµç¨‹"""

    def __init__(self):
        super().__init__()
        # è®¾ç½®å¹¶å‘ç ”ç©¶èŠ‚ç‚¹ä½œä¸ºèµ·å§‹èŠ‚ç‚¹
        self.start_node = ConcurrentResearchNode()

    async def prep_async(self, shared: Dict[str, Any]) -> Dict[str, Any]:
        """æµç¨‹çº§å‡†å¤‡"""
        shared["flow_start_time"] = asyncio.get_event_loop().time()

        return {
            "flow_start_time": shared["flow_start_time"],
            "operation": "research_flow"
        }

    async def post_async(self, shared: Dict[str, Any], prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> Dict[str, Any]:
        """æµç¨‹çº§åå¤„ç†"""
        flow_duration = asyncio.get_event_loop().time() - prep_res["flow_start_time"]

        # å‘é€å®ŒæˆçŠ¶æ€äº‹ä»¶
        await emit_processing_status(
            shared,
            f"âœ… ç ”ç©¶è°ƒç ”æµç¨‹å®Œæˆï¼Œè€—æ—¶: {flow_duration:.2f}ç§’"
        )

        return exec_res


class ResearchFlow:
    """ç ”ç©¶è°ƒç ”æµç¨‹ - ä½¿ç”¨å¸¦tracingçš„æµç¨‹å’Œå¹¶å‘èŠ‚ç‚¹"""

    def __init__(self):
        self.flow = TracedResearchFlow()

    async def run_async(self, shared: Dict[str, Any]) -> bool:
        """
        å¼‚æ­¥è¿è¡Œç ”ç©¶è°ƒç ”æµç¨‹

        Args:
            shared: å…±äº«çŠ¶æ€å­—å…¸ï¼ŒåŒ…å«research_keywords, focus_areas, project_context

        Returns:
            bool: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
        """
        try:
            # éªŒè¯å‚æ•°
            research_keywords = shared.get("research_keywords", [])
            focus_areas = shared.get("focus_areas", [])
            project_context = shared.get("project_context", "")

            if not research_keywords:
                # å‘é€é”™è¯¯äº‹ä»¶
                await emit_error(shared, "âŒ ç¼ºå°‘ç ”ç©¶å…³é”®è¯")
                shared["research_error"] = "ç¼ºå°‘ç ”ç©¶å…³é”®è¯"
                return False

            if not focus_areas:
                # å‘é€é”™è¯¯äº‹ä»¶
                await emit_error(shared, "âŒ ç¼ºå°‘å…³æ³¨ç‚¹")
                shared["research_error"] = "ç¼ºå°‘å…³æ³¨ç‚¹"
                return False


            # ğŸ”§ ä½¿ç”¨å¸¦tracingçš„æµç¨‹æ‰§è¡Œ
            result = await self.flow.run_async(shared)

            if result and shared.get("research_findings"):
                # å‘é€æˆåŠŸå®Œæˆäº‹ä»¶
                await emit_processing_status(
                    shared,
                    f"âœ… ç ”ç©¶è°ƒç ”æµç¨‹å®Œæˆï¼Œå¤„ç†äº† {len(research_keywords)} ä¸ªå…³é”®è¯"
                )
                return True
            else:
                # å‘é€å¤±è´¥äº‹ä»¶
                await emit_error(shared, "âŒ ç ”ç©¶è°ƒç ”æµç¨‹æœªèƒ½äº§ç”Ÿæœ‰æ•ˆç»“æœ")
                return False

        except Exception as e:
            # å‘é€å¼‚å¸¸äº‹ä»¶
            await emit_error(shared, f"âŒ ç ”ç©¶è°ƒç ”æµç¨‹å¤±è´¥: {e}")
            shared["research_error"] = str(e)
            return False


def create_research_flow():
    """åˆ›å»ºç ”ç©¶è°ƒç ”æµç¨‹å®ä¾‹"""
    return ResearchFlow()
