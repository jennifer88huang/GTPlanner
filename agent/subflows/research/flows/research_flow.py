"""
Research Agentä¸»æµç¨‹

æŒ‰ç…§æ¶æ„æ–‡æ¡£å®ç°ï¼šå¹¶è¡Œæ‰¹å¤„ç†ç‰ˆæœ¬
å¯¹æ¯ä¸ªå…³é”®è¯æ‰§è¡Œå®Œæ•´çš„å­æµç¨‹ï¼Œæœ€åèšåˆç»“æœ
"""

import concurrent.futures
from .keyword_research_flow import create_keyword_research_subflow
from ..utils.research_aggregator import ResearchAggregator


class ResearchFlow:
    """ç ”ç©¶è°ƒç ”å­æµç¨‹åŒ…è£…å™¨"""
    
    def __init__(self):
        self.subflow = create_keyword_research_subflow()
        self.aggregator = ResearchAggregator()
    
    def process_research_keywords(self, search_keywords, analysis_requirements):
        """
        ä½¿ç”¨å¹¶å‘æ‰¹å¤„ç†å¤„ç†ç ”ç©¶å…³é”®è¯

        å¯¹æ¯ä¸ªå…³é”®è¯å¹¶å‘æ‰§è¡Œå®Œæ•´çš„å­æµç¨‹ï¼šæœç´¢ â†’ URLè§£æ â†’ LLMåˆ†æ â†’ ç»“æœç»„è£…

        Args:
            search_keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            analysis_requirements: åˆ†æéœ€æ±‚æè¿°

        Returns:
            research_report: èšåˆåçš„ç ”ç©¶æŠ¥å‘Šåˆ—è¡¨
        """
        print(f"ğŸ”„ å¼€å§‹å¹¶å‘ç ”ç©¶å¤„ç†ï¼Œå…³é”®è¯: {search_keywords}")

        research_report = []

        try:
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†å…³é”®è¯
            with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(search_keywords), 3)) as executor:
                # æäº¤æ‰€æœ‰å…³é”®è¯å¤„ç†ä»»åŠ¡
                future_to_keyword = {
                    executor.submit(self._process_single_keyword, keyword, analysis_requirements): keyword
                    for keyword in search_keywords
                }

                # æ”¶é›†ç»“æœ
                for future in concurrent.futures.as_completed(future_to_keyword):
                    keyword = future_to_keyword[future]
                    try:
                        keyword_result = future.result()
                        if keyword_result and keyword_result.get("success"):
                            research_report.append(keyword_result["keyword_report"])
                            print(f"âœ… å®Œæˆå…³é”®è¯: {keyword}")
                        else:
                            print(f"âŒ å…³é”®è¯å¤„ç†å¤±è´¥: {keyword}")
                    except Exception as e:
                        print(f"âŒ å…³é”®è¯ {keyword} å¤„ç†å‡ºé”™: {e}")

            # 3. ç»“æœèšåˆ
            aggregated_report = self.aggregator.aggregate_research_results(research_report)

            print(f"âœ… å¹¶å‘ç ”ç©¶å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(research_report)} ä¸ªå…³é”®è¯æŠ¥å‘Š")

            return {
                "success": True,
                "research_report": research_report,
                "aggregated_summary": aggregated_report,
                "total_keywords": len(search_keywords),
                "successful_keywords": len(research_report)
            }

        except Exception as e:
            print(f"âŒ å¹¶å‘ç ”ç©¶å¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "research_report": research_report,
                "total_keywords": len(search_keywords),
                "successful_keywords": len(research_report)
            }

    def _process_single_keyword(self, keyword, analysis_requirements):
        """å¤„ç†å•ä¸ªå…³é”®è¯"""
        print(f"ğŸ” å¤„ç†å…³é”®è¯: {keyword}")

        # ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºç‹¬ç«‹çš„å­æµç¨‹å®ä¾‹
        subflow = create_keyword_research_subflow()

        # å‡†å¤‡å­æµç¨‹çš„å…±äº«å˜é‡
        subflow_shared = {
            "current_keyword": keyword,
            "analysis_requirements": analysis_requirements,
            "search_keywords": [keyword],  # ä¼ é€’ç»™æœç´¢èŠ‚ç‚¹
            "max_search_results": 5,

            # ç”¨äºå­˜å‚¨æµç¨‹ä¸­çš„æ•°æ®
            "first_search_result": {},
            "url_content": "",
            "llm_analysis": {},
            "keyword_report": {}
        }

        try:
            # æ‰§è¡Œå­æµç¨‹
            flow_result = subflow.run(subflow_shared)

            # æ£€æŸ¥flow_resultå’Œå…±äº«å˜é‡ä¸­çš„ç»“æœ
            keyword_report = subflow_shared.get("keyword_report", {})

            # éªŒè¯æµç¨‹æ˜¯å¦æˆåŠŸæ‰§è¡Œ
            if flow_result and keyword_report:
                return {
                    "success": True,
                    "keyword_report": keyword_report,
                    "flow_result": flow_result
                }
            else:
                return {
                    "success": False,
                    "error": f"Flow execution failed or no report generated",
                    "flow_result": flow_result
                }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "flow_result": None
            }

    def run(self, shared: dict) -> bool:
        """
        è¿è¡Œç ”ç©¶è°ƒç ”æµç¨‹ï¼ˆå…¼å®¹ReActç³»ç»Ÿï¼‰

        Args:
            shared: å…±äº«çŠ¶æ€å­—å…¸

        Returns:
            bool: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
        """
        try:
            print("ğŸ”„ å¯åŠ¨ç ”ç©¶è°ƒç ”æµç¨‹...")

            # ä»å…±äº«çŠ¶æ€è·å–ç»“æ„åŒ–éœ€æ±‚
            structured_requirements = shared.get("structured_requirements", {})
            if not structured_requirements:
                print("âŒ ç¼ºå°‘ç»“æ„åŒ–éœ€æ±‚æ•°æ®")
                return False

            # æå–é¡¹ç›®ä¿¡æ¯ç”Ÿæˆç ”ç©¶å…³é”®è¯
            project_overview = structured_requirements.get("project_overview", {})
            project_title = project_overview.get("title", "é¡¹ç›®")
            project_description = project_overview.get("description", "")

            # ç”Ÿæˆç ”ç©¶å…³é”®è¯
            search_keywords = [
                f"{project_title} æŠ€æœ¯æ–¹æ¡ˆ",
                f"{project_title} æ¶æ„è®¾è®¡",
                "æœ€ä½³å®è·µ",
                "æŠ€æœ¯é€‰å‹"
            ]

            # åˆ†æéœ€æ±‚
            analysis_requirements = f"é’ˆå¯¹{project_title}é¡¹ç›®è¿›è¡ŒæŠ€æœ¯è°ƒç ”ï¼Œé¡¹ç›®æè¿°ï¼š{project_description}"

            # æ‰§è¡Œç ”ç©¶
            research_results = self.process_research_keywords(search_keywords, analysis_requirements)

            # ä¿å­˜ç»“æœåˆ°å…±äº«çŠ¶æ€
            shared["research_findings"] = {
                "topics": search_keywords,
                "results": research_results,
                "summary": f"å®Œæˆäº†{len(search_keywords)}ä¸ªä¸»é¢˜çš„æŠ€æœ¯è°ƒç ”"
            }

            print("âœ… ç ”ç©¶è°ƒç ”æµç¨‹å®Œæˆ")
            return True

        except Exception as e:
            print(f"âŒ ç ”ç©¶è°ƒç ”æµç¨‹å¤±è´¥: {e}")
            shared["research_error"] = str(e)
            return False

    async def run_async(self, shared: dict) -> bool:
        """å¼‚æ­¥è¿è¡Œç ”ç©¶è°ƒç ”æµç¨‹"""
        import asyncio
        import concurrent.futures

        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥æ–¹æ³•
        with concurrent.futures.ThreadPoolExecutor() as executor:
            result = await asyncio.get_event_loop().run_in_executor(
                executor, self.run, shared
            )
        return result
