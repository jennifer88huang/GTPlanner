"""
Requirements Analysis Agent å®Œæ•´æµ‹è¯•

åŸºäºpocketflowæœ€ä½³å®è·µçš„å®Œæ•´æµ‹è¯•ï¼ŒéªŒè¯Requirements Analysis Agentçš„æ‰€æœ‰åŠŸèƒ½
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))

from agent.subflows.requirements_analysis import (
    RequirementsAnalysisFlow,
    ProcessRequirementsNode,
    LLMStructureNode,
    ValidationNode
)
from agent.nodes.node_req import NodeReq


def test_imports_and_initialization():
    """æµ‹è¯•å¯¼å…¥å’Œåˆå§‹åŒ–"""
    print("ğŸ” æµ‹è¯•å¯¼å…¥å’Œåˆå§‹åŒ–...")
    
    try:
        # æµ‹è¯•ç»„ä»¶å¯¼å…¥å’Œå®ä¾‹åŒ–
        requirements_flow = RequirementsAnalysisFlow()
        process_node = ProcessRequirementsNode()
        llm_node = LLMStructureNode()
        validation_node = ValidationNode()
        req_node = NodeReq()
        
        print("âœ… æ‰€æœ‰Requirements Analysis Agentç»„ä»¶å¯¼å…¥å’Œå®ä¾‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_llm_structure_node():
    """æµ‹è¯•LLMç»“æ„åŒ–èŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•LLMç»“æ„åŒ–èŠ‚ç‚¹...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„å…±äº«å˜é‡
    mock_shared = {
        "extracted_requirements": {
            "project_type": "web_application",
            "main_features": ["ç”¨æˆ·ç®¡ç†", "é¡¹ç›®ç®¡ç†", "ä»»åŠ¡è·Ÿè¸ª"],
            "technologies": ["Python", "React"],
            "complexity": "medium"
        },
        "dialogue_history": "ç”¨æˆ·å¸Œæœ›å¼€å‘ä¸€ä¸ªé¡¹ç›®ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒå¤šç”¨æˆ·åä½œï¼ŒåŒ…å«ä»»åŠ¡åˆ†é…å’Œè¿›åº¦è·Ÿè¸ªåŠŸèƒ½ã€‚",
        "user_intent": {
            "original_request": "å¼€å‘é¡¹ç›®ç®¡ç†ç³»ç»Ÿ",
            "extracted_keywords": ["é¡¹ç›®ç®¡ç†", "å¤šç”¨æˆ·", "ä»»åŠ¡åˆ†é…"]
        }
    }
    
    try:
        llm_node = LLMStructureNode()
        
        # æ‰§è¡Œprep
        prep_result = llm_node.prep(mock_shared)
        print(f"   prepå®Œæˆï¼Œæå–çš„ä¿¡æ¯: {len(prep_result['extracted_info'])} ä¸ªå­—æ®µ")
        
        # æ‰§è¡Œexec
        exec_result = llm_node.exec(prep_result)
        print(f"   execå®Œæˆï¼Œå¤„ç†æˆåŠŸ: {exec_result.get('processing_success')}")
        
        # æ‰§è¡Œpost
        post_result = llm_node.post(mock_shared, prep_result, exec_result)
        print(f"   postå®Œæˆï¼Œè¿”å›: {post_result}")
        
        # æ£€æŸ¥ç»“æœ
        structured_requirements = mock_shared.get("structured_requirements", {})
        if structured_requirements:
            project_title = structured_requirements.get("project_overview", {}).get("title", "")
            core_features = structured_requirements.get("functional_requirements", {}).get("core_features", [])
            print(f"   é¡¹ç›®æ ‡é¢˜: {project_title}")
            print(f"   æ ¸å¿ƒåŠŸèƒ½æ•°é‡: {len(core_features)}")
            return True
        else:
            print("âŒ æœªç”Ÿæˆç»“æ„åŒ–éœ€æ±‚")
            return False
            
    except Exception as e:
        print(f"âŒ LLMç»“æ„åŒ–èŠ‚ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_validation_node():
    """æµ‹è¯•éªŒè¯èŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•éªŒè¯èŠ‚ç‚¹...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„ç»“æ„åŒ–éœ€æ±‚
    mock_shared = {
        "structured_requirements": {
            "project_overview": {
                "title": "æ™ºèƒ½é¡¹ç›®ç®¡ç†ç³»ç»Ÿ",
                "description": "åŸºäºAIçš„é¡¹ç›®ç®¡ç†å’Œåä½œå¹³å°",
                "objectives": ["æé«˜é¡¹ç›®ç®¡ç†æ•ˆç‡", "å¢å¼ºå›¢é˜Ÿåä½œ"],
                "target_users": ["é¡¹ç›®ç»ç†", "å›¢é˜Ÿæˆå‘˜"],
                "success_criteria": ["é¡¹ç›®äº¤ä»˜æ•ˆç‡æå‡30%"]
            },
            "functional_requirements": {
                "core_features": [
                    {
                        "name": "é¡¹ç›®åˆ›å»ºä¸ç®¡ç†",
                        "description": "åˆ›å»ºã€ç¼–è¾‘ã€åˆ é™¤é¡¹ç›®",
                        "priority": "high",
                        "acceptance_criteria": ["æ”¯æŒé¡¹ç›®æ¨¡æ¿"]
                    }
                ],
                "user_stories": [
                    {
                        "role": "é¡¹ç›®ç»ç†",
                        "goal": "å¿«é€Ÿåˆ›å»ºé¡¹ç›®",
                        "benefit": "æé«˜æ•ˆç‡"
                    }
                ]
            },
            "non_functional_requirements": {
                "performance": {
                    "response_time": "< 2ç§’",
                    "throughput": "1000å¹¶å‘ç”¨æˆ·"
                },
                "security": {
                    "authentication": "å¤šå› ç´ è®¤è¯",
                    "authorization": "åŸºäºè§’è‰²çš„æƒé™æ§åˆ¶"
                }
            },
            "technical_requirements": {
                "programming_languages": ["Python", "JavaScript"],
                "frameworks": ["Django", "React"],
                "databases": ["PostgreSQL"]
            }
        }
    }
    
    try:
        validation_node = ValidationNode()
        
        # æ‰§è¡Œprep
        prep_result = validation_node.prep(mock_shared)
        print(f"   prepå®Œæˆï¼Œå¾…éªŒè¯éœ€æ±‚å­—æ®µæ•°: {len(prep_result['structured_requirements'])}")
        
        # æ‰§è¡Œexec
        exec_result = validation_node.exec(prep_result)
        print(f"   execå®Œæˆï¼ŒéªŒè¯æˆåŠŸ: {exec_result.get('validation_success')}")
        
        # æ‰§è¡Œpost
        post_result = validation_node.post(mock_shared, prep_result, exec_result)
        print(f"   postå®Œæˆï¼Œè¿”å›: {post_result}")
        
        # æ£€æŸ¥éªŒè¯æŠ¥å‘Š
        validation_report = mock_shared.get("validation_report", {})
        if validation_report:
            overall_score = validation_report.get("overall_score", 0)
            grade = validation_report.get("quality_assessment", {}).get("grade", "")
            print(f"   è´¨é‡è¯„åˆ†: {overall_score}")
            print(f"   è´¨é‡ç­‰çº§: {grade}")
            return True
        else:
            print("âŒ æœªç”ŸæˆéªŒè¯æŠ¥å‘Š")
            return False
            
    except Exception as e:
        print(f"âŒ éªŒè¯èŠ‚ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_node_req_standalone():
    """å•ç‹¬æµ‹è¯•NodeReqèŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•NodeReqèŠ‚ç‚¹...")

    try:
        req_node = NodeReq()

        # å‡†å¤‡æµ‹è¯•æ•°æ® - ä½¿ç”¨æ­£ç¡®çš„å­—å…¸æ ¼å¼
        shared = {
            "dialogue_history": {
                "session_id": "test-session",
                "start_time": "2024-12-01T10:00:00",
                "messages": [
                    {
                        "timestamp": "2024-12-01T10:00:00",
                        "role": "user",
                        "content": "ç”¨æˆ·å¸Œæœ›å¼€å‘ä¸€ä¸ªåœ¨çº¿æ•™è‚²å¹³å°ï¼Œæ”¯æŒè§†é¢‘è¯¾ç¨‹ã€åœ¨çº¿è€ƒè¯•ã€å­¦ä¹ è¿›åº¦è·Ÿè¸ªç­‰åŠŸèƒ½ã€‚",
                        "message_type": "text",
                        "metadata": {}
                    }
                ],
                "total_messages": 1,
                "last_activity": "2024-12-01T10:00:00"
            },
            "user_intent": {
                "original_request": "å¼€å‘åœ¨çº¿æ•™è‚²å¹³å°"
            }
        }

        # æ‰§è¡Œprep
        prep_result = req_node.prep(shared)
        print(f"   prepå®Œæˆ: {prep_result is not None}")

        # æ‰§è¡Œexec
        exec_result = req_node.exec(prep_result)
        print(f"   execå®Œæˆ: {exec_result is not None}")

        # æ‰§è¡Œpost
        post_result = req_node.post(shared, prep_result, exec_result)
        print(f"   postå®Œæˆï¼Œè¿”å›: {post_result}")

        # æ£€æŸ¥ç»“æœ
        extracted_requirements = shared.get("extracted_requirements", {})
        print(f"   æå–çš„éœ€æ±‚: {len(extracted_requirements)} ä¸ªå­—æ®µ")

        return post_result == "success"

    except Exception as e:
        print(f"âŒ NodeReqæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_requirements_analysis_flow():
    """æµ‹è¯•éœ€æ±‚åˆ†ææµç¨‹"""
    print("\nğŸ” æµ‹è¯•éœ€æ±‚åˆ†ææµç¨‹...")

    try:
        requirements_flow = RequirementsAnalysisFlow()

        # å‡†å¤‡æµ‹è¯•æ•°æ® - ä½¿ç”¨æ­£ç¡®çš„å­—å…¸æ ¼å¼
        shared = {
            "dialogue_history": {
                "session_id": "test-session-2",
                "start_time": "2024-12-01T11:00:00",
                "messages": [
                    {
                        "timestamp": "2024-12-01T11:00:00",
                        "role": "user",
                        "content": "ç”¨æˆ·å¸Œæœ›å¼€å‘ä¸€ä¸ªåœ¨çº¿æ•™è‚²å¹³å°ï¼Œæ”¯æŒè§†é¢‘è¯¾ç¨‹ã€åœ¨çº¿è€ƒè¯•ã€å­¦ä¹ è¿›åº¦è·Ÿè¸ªç­‰åŠŸèƒ½ã€‚éœ€è¦æ”¯æŒå¤šç§ç”¨æˆ·è§’è‰²ï¼šå­¦ç”Ÿã€æ•™å¸ˆã€ç®¡ç†å‘˜ã€‚",
                        "message_type": "text",
                        "metadata": {}
                    }
                ],
                "total_messages": 1,
                "last_activity": "2024-12-01T11:00:00"
            },
            "user_intent": {
                "original_request": "å¼€å‘åœ¨çº¿æ•™è‚²å¹³å°",
                "extracted_keywords": ["åœ¨çº¿æ•™è‚²", "è§†é¢‘è¯¾ç¨‹", "åœ¨çº¿è€ƒè¯•", "å­¦ä¹ è¿›åº¦"]
            },

            # ç”¨äºå­˜å‚¨æµç¨‹ä¸­çš„æ•°æ®
            "extracted_requirements": {},
            "structured_requirements": {},
            "validation_report": {}
        }

        print("   æ‰§è¡Œéœ€æ±‚åˆ†ææµç¨‹...")
        try:
            flow_result = requirements_flow.run(shared)
            print(f"   æµç¨‹æ‰§è¡Œç»“æœ: {flow_result}")
        except Exception as e:
            print(f"   æµç¨‹æ‰§è¡Œå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            flow_result = False

        if flow_result:
            print("âœ… éœ€æ±‚åˆ†ææµç¨‹æ‰§è¡ŒæˆåŠŸ")
            
            # æ£€æŸ¥ç»“æœ
            structured_requirements = shared.get("structured_requirements", {})
            validation_report = shared.get("validation_report", {})
            
            if structured_requirements:
                project_title = structured_requirements.get("project_overview", {}).get("title", "")
                core_features = structured_requirements.get("functional_requirements", {}).get("core_features", [])
                print(f"   é¡¹ç›®æ ‡é¢˜: {project_title}")
                print(f"   æ ¸å¿ƒåŠŸèƒ½æ•°é‡: {len(core_features)}")
            
            if validation_report:
                overall_score = validation_report.get("overall_score", 0)
                print(f"   è´¨é‡è¯„åˆ†: {overall_score}")
            
            return True
        else:
            print("âŒ éœ€æ±‚åˆ†ææµç¨‹æ‰§è¡Œå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ éœ€æ±‚åˆ†ææµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_process_requirements_node():
    """æµ‹è¯•ProcessRequirementsä¸»èŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•ProcessRequirementsä¸»èŠ‚ç‚¹...")
    
    # åˆ›å»ºå®Œæ•´çš„æ¨¡æ‹Ÿä¸»Agentå…±äº«çŠ¶æ€
    mock_shared = {
        "dialogue_history": {
            "session_id": "test-session-3",
            "start_time": "2024-12-01T12:00:00",
            "messages": [
                {
                    "timestamp": "2024-12-01T12:00:00",
                    "role": "user",
                    "content": "ç”¨æˆ·å¸Œæœ›å¼€å‘ä¸€ä¸ªç”µå•†å¹³å°ï¼ŒåŒ…å«å•†å“ç®¡ç†ã€è®¢å•å¤„ç†ã€æ”¯ä»˜é›†æˆã€ç”¨æˆ·è¯„ä»·ç­‰åŠŸèƒ½ã€‚éœ€è¦æ”¯æŒç§»åŠ¨ç«¯å’ŒPCç«¯ã€‚",
                    "message_type": "text",
                    "metadata": {}
                }
            ],
            "total_messages": 1,
            "last_activity": "2024-12-01T12:00:00"
        },
        "user_intent": {
            "original_request": "å¼€å‘ç”µå•†å¹³å°",
            "extracted_keywords": ["ç”µå•†", "å•†å“ç®¡ç†", "è®¢å•å¤„ç†", "æ”¯ä»˜"]
        },
        "current_stage": "user_input_completed",
        "system_messages": [],
        "metadata": {
            "processing_stages": [],
            "total_processing_time": 0.0
        }
    }
    
    try:
        process_node = ProcessRequirementsNode()
        
        # æ‰§è¡Œprep
        prep_result = process_node.prep(mock_shared)
        print(f"   prepå®Œæˆï¼Œå¯¹è¯å†å²é•¿åº¦: {len(prep_result['dialogue_history'])}")
        
        # æ‰§è¡Œexec
        exec_result = process_node.exec(prep_result)
        print(f"   execå®Œæˆï¼Œå¤„ç†æˆåŠŸ: {exec_result.get('processing_success')}")
        
        # æ‰§è¡Œpost
        post_result = process_node.post(mock_shared, prep_result, exec_result)
        print(f"   postå®Œæˆï¼Œè¿”å›: {post_result}")
        
        # æ£€æŸ¥ä¸»Agentå…±äº«çŠ¶æ€çš„å˜åŒ–
        print(f"   å½“å‰é˜¶æ®µ: {mock_shared.get('current_stage')}")
        print(f"   ç»“æ„åŒ–éœ€æ±‚: {'å·²åˆ›å»º' if mock_shared.get('structured_requirements') else 'æœªåˆ›å»º'}")
        print(f"   ç³»ç»Ÿæ¶ˆæ¯æ•°é‡: {len(mock_shared.get('system_messages', []))}")
        
        structured_requirements = mock_shared.get('structured_requirements', {})
        if structured_requirements:
            project_title = structured_requirements.get('project_overview', {}).get('title', '')
            core_features = structured_requirements.get('functional_requirements', {}).get('core_features', [])
            print(f"   é¡¹ç›®æ ‡é¢˜: {project_title}")
            print(f"   æ ¸å¿ƒåŠŸèƒ½æ•°é‡: {len(core_features)}")
        
        requirements_metadata = mock_shared.get('requirements_metadata', {})
        if requirements_metadata:
            quality_score = requirements_metadata.get('quality_score', 0)
            print(f"   è´¨é‡è¯„åˆ†: {quality_score}")
        
        return post_result == "success"
        
    except Exception as e:
        print(f"âŒ ProcessRequirementsä¸»èŠ‚ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è¿è¡ŒRequirements Analysis Agentå®Œæ•´æµ‹è¯•...")
    print("=" * 60)
    
    test_results = []
    
    # 1. å¯¼å…¥å’Œåˆå§‹åŒ–æµ‹è¯•
    test_results.append(test_imports_and_initialization())
    
    # 2. NodeReqèŠ‚ç‚¹æµ‹è¯•
    test_results.append(test_node_req_standalone())

    # 3. LLMç»“æ„åŒ–èŠ‚ç‚¹æµ‹è¯•
    test_results.append(test_llm_structure_node())

    # 4. éªŒè¯èŠ‚ç‚¹æµ‹è¯•
    test_results.append(test_validation_node())

    # 5. éœ€æ±‚åˆ†ææµç¨‹æµ‹è¯•
    test_results.append(test_requirements_analysis_flow())

    # 6. ProcessRequirementsä¸»èŠ‚ç‚¹æµ‹è¯•
    test_results.append(test_process_requirements_node())
    
    # ç»Ÿè®¡ç»“æœ
    passed = sum(test_results)
    total = len(test_results)
    
    print("\n" + "=" * 60)
    print(f"ğŸ¯ æµ‹è¯•å®Œæˆ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Requirements Analysis Agentå·¥ä½œæ­£å¸¸ã€‚")
        print("\nâœ… éªŒè¯çš„åŠŸèƒ½:")
        print("   - ç»„ä»¶å¯¼å…¥å’Œåˆå§‹åŒ–")
        print("   - LLMç»“æ„åŒ–å¤„ç†")
        print("   - éœ€æ±‚éªŒè¯å’Œè´¨é‡è¯„ä¼°")
        print("   - å®Œæ•´çš„éœ€æ±‚åˆ†ææµç¨‹")
        print("   - ä¸»Agentå…±äº«çŠ¶æ€æ›´æ–°")
        print("   - pocketflowå­—å…¸å…±äº«å˜é‡çš„æ­£ç¡®ä½¿ç”¨")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
    
    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1)
