"""
å·¥å…·ç´¢å¼•èŠ‚ç‚¹ (Node_Tool_Index)

è´Ÿè´£æ‰«æå·¥å…·æè¿°æ–‡ä»¶å¹¶å»ºç«‹å‘é‡ç´¢å¼•ï¼Œæ”¯æŒä¸åŒç±»å‹çš„å·¥å…·ã€‚
åŸºäºæ¶æ„æ–‡æ¡£ä¸­å®šä¹‰çš„è¾“å…¥è¾“å‡ºè§„æ ¼å®ç°ã€‚

åŠŸèƒ½æè¿°ï¼š
- æ‰«ætoolsç›®å½•ä¸‹çš„æ‰€æœ‰å·¥å…·æè¿°æ–‡ä»¶
- è§£æYAMLæ ¼å¼çš„å·¥å…·æè¿°
- æ„å»ºç»Ÿä¸€çš„æ–‡æ¡£ç»“æ„
- è°ƒç”¨å‘é‡æœåŠ¡è¿›è¡Œæ‰¹é‡ç´¢å¼•
- æ”¯æŒå¤šç§å·¥å…·ç±»å‹çš„æ‰©å±•
"""

import os
import glob
import yaml
import requests
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from pocketflow import AsyncNode
from utils.config_manager import get_vector_service_config
from agent.streaming import (
    emit_processing_status,
    emit_error
)


class NodeToolIndex(AsyncNode):
    """å·¥å…·ç´¢å¼•èŠ‚ç‚¹"""
    
    def __init__(self, max_retries: int = 3, wait: float = 2.0):
        """
        åˆå§‹åŒ–å·¥å…·ç´¢å¼•èŠ‚ç‚¹

        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            wait: é‡è¯•ç­‰å¾…æ—¶é—´
        """
        super().__init__(max_retries=max_retries, wait=wait)

        # ä»é…ç½®æ–‡ä»¶åŠ è½½å‘é‡æœåŠ¡é…ç½®
        vector_config = get_vector_service_config()
        self.vector_service_url = vector_config.get("base_url", "http://nodeport.sensedeal.vip:32421")
        self.timeout = vector_config.get("timeout", 30)

        # è¿™äº›å‚æ•°ä¿æŒç¡¬ç¼–ç ï¼Œä¸ä»é…ç½®æ–‡ä»¶è¯»å–
        self.index_name = "tools_index"
        self.vector_field = "combined_text"
        
        # å·¥å…·ç›®å½•é…ç½®
        self.tools_dir = "tools"
        self.supported_types = ["PYTHON_PACKAGE", "APIS"]
        
        # æ£€æŸ¥å‘é‡æœåŠ¡å¯ç”¨æ€§
        try:
            response = requests.get(f"{self.vector_service_url}/health", timeout=5)
            self.vector_service_available = response.status_code == 200
        except Exception:
            self.vector_service_available = False
            # æ³¨æ„ï¼šåˆå§‹åŒ–é˜¶æ®µæ— æ³•å‘é€æµå¼äº‹ä»¶
    
    async def prep_async(self, shared) -> Dict[str, Any]:
        """
        å‡†å¤‡é˜¶æ®µï¼šæ‰«æå’Œè§£æå·¥å…·æè¿°æ–‡ä»¶

        Args:
            shared: pocketflowå­—å…¸å…±äº«å˜é‡

        Returns:
            å‡†å¤‡ç»“æœå­—å…¸
        """
        try:
            # ä»å…±äº«å˜é‡è·å–é…ç½®
            tools_dir = shared.get("tools_dir", self.tools_dir)
            index_name = shared.get("index_name", self.index_name)
            force_reindex = shared.get("force_reindex", False)
            
            # æ‰«æå·¥å…·æ–‡ä»¶
            tool_files = await self._scan_tool_files(tools_dir, shared)

            if not tool_files:
                return {
                    "error": f"No tool files found in {tools_dir}",
                    "tool_files": [],
                    "tools_count": 0
                }

            # è§£æå·¥å…·æ–‡ä»¶
            parsed_tools = []
            failed_files = []

            for file_path in tool_files:
                try:
                    tool_data = await self._parse_tool_file(file_path, shared)
                    if tool_data:
                        parsed_tools.append(tool_data)
                except Exception as e:
                    failed_files.append({"file": file_path, "error": str(e)})
                    # é”™è¯¯å·²åœ¨ _parse_tool_file ä¸­å‘é€äº‹ä»¶
            
            if not parsed_tools:
                return {
                    "error": "No valid tool files parsed",
                    "tool_files": tool_files,
                    "parsed_tools": [],
                    "failed_files": failed_files,
                    "tools_count": 0
                }
            
            return {
                "tool_files": tool_files,
                "parsed_tools": parsed_tools,
                "failed_files": failed_files,
                "tools_count": len(parsed_tools),
                "index_name": index_name,
                "force_reindex": force_reindex,
                "streaming_session": shared.get("streaming_session")
            }
            
        except Exception as e:
            return {
                "error": f"Tool indexing preparation failed: {str(e)}",
                "tool_files": [],
                "parsed_tools": [],
                "tools_count": 0
            }
    
    async def exec_async(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œé˜¶æ®µï¼šè°ƒç”¨å‘é‡æœåŠ¡è¿›è¡Œå·¥å…·ç´¢å¼•

        Args:
            prep_res: å‡†å¤‡é˜¶æ®µçš„ç»“æœ

        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        if "error" in prep_res:
            raise ValueError(prep_res["error"])
        
        parsed_tools = prep_res["parsed_tools"]
        index_name = prep_res["index_name"]
        
        if not parsed_tools:
            raise ValueError("No tools to index")
        
        if not self.vector_service_available:
            raise RuntimeError("Vector service is not available")
        
        try:
            start_time = time.time()
            
            # æ„å»ºæ–‡æ¡£åˆ—è¡¨
            documents = []
            for tool in parsed_tools:
                doc = self._build_document(tool)
                documents.append(doc)
            
            # è°ƒç”¨å‘é‡æœåŠ¡è¿›è¡Œæ‰¹é‡ç´¢å¼•
            # ä» prep_res ä¸­è·å– streaming_session ç”¨äºäº‹ä»¶å‘é€
            shared_for_events = {"streaming_session": prep_res.get("streaming_session")}
            index_result = await self._index_documents(documents, index_name, shared_for_events)
            
            index_time = time.time() - start_time
            
            return {
                "indexed_count": index_result.get("count", len(documents)),
                "index_name": index_result.get("index", index_name),
                "index_time": round(index_time * 1000),  # è½¬æ¢ä¸ºæ¯«ç§’
                "documents": documents,
                "failed_tools": prep_res.get("failed_files", []),
                "total_processed": prep_res["tools_count"]
            }
            
        except Exception as e:
            raise RuntimeError(f"Tool indexing execution failed: {str(e)}")
    
    async def post_async(self, shared, prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """
        åå¤„ç†é˜¶æ®µï¼šæ›´æ–°å…±äº«çŠ¶æ€

        Args:
            shared: å…±äº«çŠ¶æ€å¯¹è±¡
            prep_res: å‡†å¤‡é˜¶æ®µç»“æœ
            exec_res: æ‰§è¡Œé˜¶æ®µç»“æœ

        Returns:
            ä¸‹ä¸€æ­¥åŠ¨ä½œ
        """
        try:
            if "error" in exec_res:
                if hasattr(shared, 'record_error'):
                    shared.record_error(Exception(exec_res["error"]), "NodeToolIndex.exec")
                return "error"

            indexed_count = exec_res["indexed_count"]
            index_name = exec_res["index_name"]

            # æ£€æŸ¥æ˜¯å¦æ˜¯å­æµç¨‹çš„å…±äº«å˜é‡ï¼ˆå­—å…¸ç±»å‹ï¼‰
            if isinstance(shared, dict):
                # å­æµç¨‹æ¨¡å¼ï¼šä¿å­˜ç´¢å¼•ç»“æœåˆ°å…±äº«å˜é‡
                shared["tool_index_result"] = {
                    "indexed_count": indexed_count,
                    "index_name": index_name,
                    "index_time": exec_res["index_time"],
                    "total_processed": exec_res["total_processed"]
                }
                return "success"

            # ä¸»æµç¨‹æ¨¡å¼ï¼šæ›´æ–°ç³»ç»ŸçŠ¶æ€
            if not hasattr(shared, 'system_status'):
                shared.system_status = {}
            
            shared.system_status.update({
                "tool_index_name": index_name,
                "tool_index_count": indexed_count,
                "last_index_time": datetime.now().isoformat(),
                "index_duration_ms": exec_res["index_time"]
            })

            # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯è®°å½•ç´¢å¼•ç»“æœ
            shared.add_system_message(
                f"å·¥å…·ç´¢å¼•å®Œæˆï¼ŒæˆåŠŸç´¢å¼• {indexed_count} ä¸ªå·¥å…·åˆ° {index_name}",
                agent_source="NodeToolIndex",
                indexed_count=indexed_count,
                total_processed=exec_res["total_processed"],
                index_time_ms=exec_res["index_time"]
            )

            return "success"

        except Exception as e:
            if hasattr(shared, 'record_error'):
                shared.record_error(e, "NodeToolIndex.post")
            return "error"
    
    def exec_fallback(self, prep_res: Dict[str, Any], exc: Exception) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¤±è´¥æ—¶çš„é™çº§å¤„ç†
        
        Args:
            prep_res: å‡†å¤‡é˜¶æ®µç»“æœ
            exc: å¼‚å¸¸å¯¹è±¡
            
        Returns:
            é”™è¯¯ä¿¡æ¯
        """
        return {
            "error": f"Tool indexing execution failed: {str(exc)}",
            "indexed_count": 0,
            "total_processed": prep_res.get("tools_count", 0)
        }
    
    async def _scan_tool_files(self, tools_dir: str, shared: Dict[str, Any]) -> List[str]:
        """æ‰«æå·¥å…·æè¿°æ–‡ä»¶"""
        if not os.path.exists(tools_dir):
            # å‘é€é”™è¯¯äº‹ä»¶
            await emit_error(shared, f"âš ï¸ å·¥å…·ç›®å½•ä¸å­˜åœ¨: {tools_dir}")
            return []

        # æ‰«ææ‰€æœ‰å­ç›®å½•ä¸‹çš„ymlæ–‡ä»¶
        pattern = os.path.join(tools_dir, "**", "*.yml")
        tool_files = glob.glob(pattern, recursive=True)

        # å‘é€å‘ç°æ–‡ä»¶çš„çŠ¶æ€äº‹ä»¶
        await emit_processing_status(shared, f"ğŸ“ å‘ç° {len(tool_files)} ä¸ªå·¥å…·æè¿°æ–‡ä»¶")
        return tool_files
    
    async def _parse_tool_file(self, file_path: str, shared: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è§£æå•ä¸ªå·¥å…·æè¿°æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            
            if not data or not isinstance(data, dict):
                return None
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ['id', 'type', 'summary']
            for field in required_fields:
                if field not in data:
                    # å‘é€è­¦å‘Šäº‹ä»¶
                    await emit_error(shared, f"âš ï¸ å·¥å…·æ–‡ä»¶ç¼ºå°‘å¿…éœ€å­—æ®µ {field}: {file_path}")
                    return None
            
            # æ·»åŠ æ–‡ä»¶è·¯å¾„ä¿¡æ¯
            data['file_path'] = file_path
            data['file_name'] = os.path.basename(file_path)
            
            return data
            
        except Exception as e:
            # å‘é€é”™è¯¯äº‹ä»¶
            await emit_error(shared, f"âŒ è§£æå·¥å…·æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            return None

    def _build_document(self, tool_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºç”¨äºç´¢å¼•çš„æ–‡æ¡£ç»“æ„"""
        # åŸºç¡€å­—æ®µ
        doc = {
            "id": tool_data["id"],
            "type": tool_data["type"],
            "summary": tool_data.get("summary", ""),
            "description": tool_data.get("description", ""),
            "file_path": tool_data.get("file_path", ""),
            "file_name": tool_data.get("file_name", ""),
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }

        # å¤„ç†ç¤ºä¾‹
        examples_text = ""
        if "examples" in tool_data and isinstance(tool_data["examples"], list):
            examples_list = []
            for example in tool_data["examples"]:
                if isinstance(example, dict):
                    title = example.get("title", "")
                    content = example.get("content", "")
                    examples_list.append(f"{title}: {content}")
                else:
                    examples_list.append(str(example))
            examples_text = "\n".join(examples_list)

        doc["examples"] = examples_text

        # å¤„ç†ä¸åŒç±»å‹å·¥å…·çš„ç‰¹æ®Šå­—æ®µ
        if tool_data["type"] == "PYTHON_PACKAGE":
            doc["requirement"] = tool_data.get("requirement", "")
            doc["category"] = "python_package"
        elif tool_data["type"] == "APIS":
            doc["base_url"] = tool_data.get("base_url", "")
            doc["category"] = "api"

            # å¤„ç†endpoints
            endpoints_text = ""
            if "endpoints" in tool_data and isinstance(tool_data["endpoints"], list):
                endpoints_list = []
                for endpoint in tool_data["endpoints"]:
                    if isinstance(endpoint, dict):
                        method = endpoint.get("method", "")
                        path = endpoint.get("path", "")
                        summary = endpoint.get("summary", "")
                        endpoints_list.append(f"{method} {path}: {summary}")
                endpoints_text = "\n".join(endpoints_list)

            doc["endpoints"] = endpoints_text
        else:
            doc["category"] = "other"

        # æ„å»ºç”¨äºå‘é‡æ£€ç´¢çš„ç»„åˆæ–‡æœ¬
        combined_parts = [
            doc["summary"],
            doc["description"],
            examples_text
        ]

        # æ·»åŠ ç±»å‹ç‰¹å®šçš„æ–‡æœ¬
        if tool_data["type"] == "PYTHON_PACKAGE":
            combined_parts.append(doc.get("requirement", ""))
        elif tool_data["type"] == "APIS":
            combined_parts.append(doc.get("endpoints", ""))

        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å¹¶ç»„åˆ
        combined_text = " ".join([part.strip() for part in combined_parts if part.strip()])
        doc[self.vector_field] = combined_text

        return doc

    async def _index_documents(self, documents: List[Dict[str, Any]], index_name: str, shared: Dict[str, Any]) -> Dict[str, Any]:
        """è°ƒç”¨å‘é‡æœåŠ¡è¿›è¡Œæ–‡æ¡£ç´¢å¼•"""
        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "documents": documents,
                "vector_field": self.vector_field
            }

            # å°è¯•ä½¿ç”¨æŒ‡å®šçš„ç´¢å¼•å
            if index_name:
                request_data["index"] = index_name

            # è°ƒç”¨å‘é‡æœåŠ¡
            response = requests.post(
                f"{self.vector_service_url}/documents",
                json=request_data,
                timeout=self.timeout,
                headers={"Content-Type": "application/json"}
            )

            # å¦‚æœæŒ‡å®šç´¢å¼•ä¸å­˜åœ¨ï¼Œå°è¯•ä¸æŒ‡å®šç´¢å¼•åè®©æœåŠ¡è‡ªåŠ¨åˆ›å»º
            if (response.status_code in [400, 404]) and "ä¸å­˜åœ¨" in response.text and index_name:
                await emit_processing_status(shared, f"âš ï¸ ç´¢å¼• {index_name} ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨åˆ›å»ºç´¢å¼•...")
                request_data.pop("index", None)  # ç§»é™¤ç´¢å¼•å
                response = requests.post(
                    f"{self.vector_service_url}/documents",
                    json=request_data,
                    timeout=self.timeout,
                    headers={"Content-Type": "application/json"}
                )

            if response.status_code == 200:
                result = response.json()
                await emit_processing_status(shared, f"âœ… æˆåŠŸç´¢å¼• {result.get('count', 0)} ä¸ªå·¥å…·åˆ° {result.get('index', index_name)}")
                return result
            else:
                error_msg = f"å‘é‡æœåŠ¡è¿”å›é”™è¯¯: {response.status_code}, {response.text}"
                await emit_error(shared, f"âŒ {error_msg}")
                raise RuntimeError(error_msg)

        except requests.exceptions.RequestException as e:
            error_msg = f"è°ƒç”¨å‘é‡æœåŠ¡å¤±è´¥: {str(e)}"
            await emit_error(shared, f"âŒ {error_msg}")
            raise RuntimeError(error_msg)
