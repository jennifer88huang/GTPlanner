"""
æœç´¢å¼•æ“èŠ‚ç‚¹ (Node_Search)

åŸºäºå…³é”®è¯è¿›è¡Œç½‘ç»œæœç´¢ï¼Œè¿”å›ç›¸å…³ç»“æœã€‚
åŸºäºæ¶æ„æ–‡æ¡£ä¸­å®šä¹‰çš„è¾“å…¥è¾“å‡ºè§„æ ¼å®ç°ã€‚

åŠŸèƒ½æè¿°ï¼š
- å…³é”®è¯ä¼˜åŒ–å’Œç»„åˆ
- å¤šæœç´¢å¼•æ“APIè°ƒç”¨
- ç»“æœå»é‡å’Œæ’åº
- ç›¸å…³æ€§è¯„åˆ†è®¡ç®—
- ç»“æœæ ¼å¼æ ‡å‡†åŒ–
"""

import time
from typing import Dict, List, Any, Optional
from pocketflow import AsyncNode
from ..utils.search import JinaSearchClient


class NodeSearch(AsyncNode):
    """æœç´¢å¼•æ“èŠ‚ç‚¹"""
    
    def __init__(self, max_retries: int = 3, wait: float = 2.0):
        """
        åˆå§‹åŒ–æœç´¢å¼•æ“èŠ‚ç‚¹
        
        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            wait: é‡è¯•ç­‰å¾…æ—¶é—´
        """
        super().__init__(max_retries=max_retries, wait=wait)
        self.name = "NodeSearch"
        
        # åˆå§‹åŒ–æœç´¢å®¢æˆ·ç«¯
        try:
            self.search_client = JinaSearchClient()
            self.search_available = True
        except ValueError:
            self.search_client = None
            self.search_available = False
            print("âš ï¸ æœç´¢APIæœªé…ç½®")

        # æœç´¢é…ç½®
        self.default_max_results = 10
        self.default_language = "zh-CN"
        self.timeout = 30

        # ç›¸å…³æ€§è¯„åˆ†æƒé‡
        self.title_weight = 0.4
        self.snippet_weight = 0.3
        self.url_weight = 0.2
        self.source_weight = 0.1
    
    async def prep_async(self, shared) -> Dict[str, Any]:
        """
        å‡†å¤‡é˜¶æ®µï¼šä»pocketflowå­—å…¸å…±äº«å˜é‡è·å–æœç´¢å…³é”®è¯

        Args:
            shared: pocketflowå­—å…¸å…±äº«å˜é‡

        Returns:
            å‡†å¤‡ç»“æœå­—å…¸
        """
        try:
            # ğŸ”§ æ”¯æŒå•ä¸ªå…³é”®è¯è¾“å…¥
            current_keyword = shared.get("current_keyword")
            search_keywords = shared.get("search_keywords", [])
            search_type = shared.get("search_type", "web")
            max_results = shared.get("max_results", self.default_max_results)
            language = shared.get("language", self.default_language)

            # ä¼˜å…ˆä½¿ç”¨å•ä¸ªå…³é”®è¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å…³é”®è¯åˆ—è¡¨
            if current_keyword:
                search_keywords = [current_keyword]
            elif not search_keywords:
                search_keywords = self._extract_keywords_from_shared_state(shared)

            # éªŒè¯è¾“å…¥
            if not search_keywords:
                return self._create_error_result("No search keywords provided", search_type)
            
            # ä¼˜åŒ–å…³é”®è¯
            optimized_keywords = self._optimize_keywords(search_keywords)
            
            return {
                "search_keywords": optimized_keywords,
                "search_type": search_type,
                "max_results": max_results,
                "language": language,
                "original_keywords": search_keywords,
                "keyword_count": len(optimized_keywords)
            }
            
        except Exception as e:
            return self._create_error_result(f"Search preparation failed: {str(e)}")
    
    async def exec_async(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œé˜¶æ®µï¼šæ‰§è¡Œæœç´¢æ“ä½œ
        
        Args:
            prep_res: å‡†å¤‡é˜¶æ®µçš„ç»“æœ
            
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        if "error" in prep_res:
            raise ValueError(prep_res["error"])
        
        search_keywords = prep_res["search_keywords"]
        max_results = prep_res["max_results"]
        
        if not search_keywords:
            raise ValueError("Empty search keywords")
        
        try:
            start_time = time.time()
            
            # æ‰§è¡Œæœç´¢
            all_results = []
            
            for keyword in search_keywords:
                try:
                    if self.search_available and self.search_client:
                        # ä½¿ç”¨çœŸå®æœç´¢API - å¼‚æ­¥è°ƒç”¨
                        results = await self.search_client.search_simple(keyword, count=max_results)

                        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                        formatted_results = []
                        for i, result in enumerate(results):
                            formatted_result = {
                                "title": result.get("title", ""),
                                "url": result.get("url", ""),
                                "snippet": result.get("description", ""),
                                "search_keyword": keyword,
                                "rank": i + 1,
                                "source_type": self._classify_source_type(result.get("url", "")),
                                "content": result.get("content", "")
                            }
                            formatted_result["relevance_score"] = self._calculate_relevance_score(
                                formatted_result, keyword
                            )
                            formatted_results.append(formatted_result)

                        all_results.extend(formatted_results)
                    else:
                        # æœç´¢APIä¸å¯ç”¨ï¼Œè·³è¿‡æ­¤å…³é”®è¯
                        print(f"âš ï¸ æœç´¢APIä¸å¯ç”¨ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                        continue

                    # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    time.sleep(0.5)

                except Exception as e:
                    # å•ä¸ªå…³é”®è¯æœç´¢å¤±è´¥ä¸å½±å“å…¶ä»–å…³é”®è¯
                    print(f"âŒ æœç´¢å¤±è´¥ï¼Œå…³é”®è¯ '{keyword}': {str(e)}")
                    continue
            
            # å»é‡å’Œæ’åº
            deduplicated_results = self._deduplicate_results(all_results)
            sorted_results = self._sort_results(deduplicated_results)
            
            # é™åˆ¶ç»“æœæ•°é‡
            final_results = sorted_results[:max_results]
            
            search_time = time.time() - start_time
            
            return {
                "search_results": final_results,
                "total_found": len(final_results),
                "search_time": round(search_time * 1000),  # è½¬æ¢ä¸ºæ¯«ç§’
                "keywords_processed": len(search_keywords),
                "deduplication_stats": {
                    "original_count": len(all_results),
                    "deduplicated_count": len(deduplicated_results),
                    "final_count": len(final_results)
                }
            }
            
        except Exception as e:
            raise RuntimeError(f"Search execution failed: {str(e)}")
    
    async def post_async(self, shared, prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """
        åå¤„ç†é˜¶æ®µï¼šå°†æœç´¢ç»“æœå­˜å‚¨åˆ°å…±äº«çŠ¶æ€

        Args:
            shared: å…±äº«çŠ¶æ€å­—å…¸
            prep_res: å‡†å¤‡é˜¶æ®µç»“æœ
            exec_res: æ‰§è¡Œé˜¶æ®µç»“æœ

        Returns:
            ä¸‹ä¸€æ­¥åŠ¨ä½œ
        """
        try:
            if "error" in exec_res:
                # è®°å½•é”™è¯¯åˆ°sharedå­—å…¸
                if "errors" not in shared:
                    shared["errors"] = []
                shared["errors"].append({
                    "source": "NodeSearch.exec",
                    "error": exec_res["error"],
                    "timestamp": prep_res.get("timestamp", "")
                })
                return "error"

            search_results = exec_res["search_results"]

            # ç»Ÿä¸€ä½¿ç”¨å­—å…¸æ¨¡å¼å­˜å‚¨æœç´¢ç»“æœ
            if search_results:
                shared["first_search_result"] = search_results[0]
                shared["all_search_results"] = search_results




            print(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
            return "search_complete"

        except Exception as e:
            print(f"âŒ NodeSearch postå¤„ç†å¤±è´¥: {e}")
            # è®°å½•é”™è¯¯åˆ°sharedå­—å…¸
            if "errors" not in shared:
                shared["errors"] = []
            shared["errors"].append({
                "source": "NodeSearch.post",
                "error": str(e),
                "timestamp": prep_res.get("timestamp", "")
            })
            return "error"
    



    
    def _extract_keywords_from_shared_state(self, shared) -> List[str]:
        """ä»å…±äº«çŠ¶æ€ä¸­æå–æœç´¢å…³é”®è¯"""
        # ç›´æ¥ä»sharedå­—å…¸è·å–æœç´¢å…³é”®è¯
        search_keywords = shared.get("search_keywords", [])

        # å»é‡å¹¶è¿”å›
        return list(set(search_keywords))[:5]  # æœ€å¤šè¿”å›5ä¸ªå…³é”®è¯
    

    


    
    def _deduplicate_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é‡æœç´¢ç»“æœ"""
        seen_urls = set()
        deduplicated = []
        
        for result in results:
            url = result.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                deduplicated.append(result)
        
        return deduplicated
    
    def _sort_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºç»“æœ"""
        return sorted(results, key=lambda x: x.get("relevance_score", 0), reverse=True)
    

    

