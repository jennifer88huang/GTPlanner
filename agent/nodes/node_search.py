"""
æœç´¢å¼•æ“èŠ‚ç‚¹ (Node_Search)

åŸºäºå…³é”®è¯è¿›è¡Œç½‘ç»œæœç´¢ï¼Œè¿”å›ç›¸å…³ç»“æœã€‚
åŸºäºæ¶æ„æ–‡æ¡£ä¸­å®šä¹‰çš„è¾“å…¥è¾“å‡ºè§„æ ¼å®ç°ã€‚

åŠŸèƒ½æè¿°ï¼š
- å…³é”®è¯ä¼˜åŒ–å’Œç»„åˆ
- å¤šæœç´¢å¼•æ“APIè°ƒç”¨
- ç»“æœå»é‡å’Œæ’åº
- ç›¸å…³æ€§è¯„åˆ†è®¡ç®—
- ç»“æœæ ¼å¼æ ‡å‡†åŒ–
"""

import time
from typing import Dict, List, Any, Optional
from pocketflow import AsyncNode
from ..utils.search import JinaSearchClient
from agent.streaming import (
    emit_processing_status,
    emit_error
)


class NodeSearch(AsyncNode):
    """æœç´¢å¼•æ“èŠ‚ç‚¹"""
    
    def __init__(self, max_retries: int = 3, wait: float = 2.0):
        """
        åˆå§‹åŒ–æœç´¢å¼•æ“èŠ‚ç‚¹
        
        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            wait: é‡è¯•ç­‰å¾…æ—¶é—´
        """
        super().__init__(max_retries=max_retries, wait=wait)
        self.name = "NodeSearch"
        
        # åˆå§‹åŒ–æœç´¢å®¢æˆ·ç«¯
        try:
            self.search_client = JinaSearchClient()
            self.search_available = True
        except ValueError:
            self.search_client = None
            self.search_available = False
            # æ³¨æ„ï¼šåˆå§‹åŒ–é˜¶æ®µæ— æ³•å‘é€æµå¼äº‹ä»¶ï¼Œè¿™é‡Œä¿ç•™æ—¥å¿—æˆ–ç§»é™¤

        # æœç´¢é…ç½®
        self.default_max_results = 10
        self.default_language = "zh-CN"
        self.timeout = 30

        # ç›¸å…³æ€§è¯„åˆ†æƒé‡
        self.title_weight = 0.4
        self.snippet_weight = 0.3
        self.url_weight = 0.2
        self.source_weight = 0.1
    
    async def prep_async(self, shared) -> Dict[str, Any]:
        """
        å‡†å¤‡é˜¶æ®µï¼šä»pocketflowå­—å…¸å…±äº«å˜é‡è·å–æœç´¢å…³é”®è¯

        Args:
            shared: pocketflowå­—å…¸å…±äº«å˜é‡

        Returns:
            å‡†å¤‡ç»“æœå­—å…¸
        """
        try:
            # ğŸ”§ æ”¯æŒå•ä¸ªå…³é”®è¯è¾“å…¥
            current_keyword = shared.get("current_keyword")
            search_keywords = shared.get("search_keywords", [])
            search_type = shared.get("search_type", "web")
            max_results = shared.get("max_results", self.default_max_results)
            language = shared.get("language", self.default_language)

            # ä¼˜å…ˆä½¿ç”¨å•ä¸ªå…³é”®è¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å…³é”®è¯åˆ—è¡¨
            if current_keyword:
                search_keywords = [current_keyword]
            elif not search_keywords:
                search_keywords = self._extract_keywords_from_shared_state(shared)

            # éªŒè¯è¾“å…¥
            if not search_keywords:
                return {"error": "No search keywords provided"}

            return {
                "search_keywords": search_keywords,
                "search_type": search_type,
                "max_results": max_results,
                "language": language,
                "streaming_session": shared.get("streaming_session")
            }
            
        except Exception as e:
            return {"error": f"Search preparation failed: {str(e)}"}
    
    async def exec_async(self, prep_res: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œé˜¶æ®µï¼šæ‰§è¡Œæœç´¢æ“ä½œ
        
        Args:
            prep_res: å‡†å¤‡é˜¶æ®µçš„ç»“æœ
            
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        if "error" in prep_res:
            raise ValueError(prep_res["error"])
        
        search_keywords = prep_res["search_keywords"]
        max_results = prep_res["max_results"]
        
        if not search_keywords:
            raise ValueError("Empty search keywords")
        
        try:
            start_time = time.time()
            
            # æ‰§è¡Œæœç´¢
            all_results = []
            
            for keyword in search_keywords:
                try:
                    if self.search_available and self.search_client:
                        # ä½¿ç”¨çœŸå®æœç´¢API - å¼‚æ­¥è°ƒç”¨
                        results = await self.search_client.search_simple(keyword, count=max_results)

                        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                        formatted_results = []
                        for result in results:
                            formatted_result = {
                                "title": result.get("title", ""),
                                "url": result.get("url", ""),
                                "snippet": result.get("description", ""),
                                "content": result.get("content", "")
                            }
                            formatted_results.append(formatted_result)

                        all_results.extend(formatted_results)
                    else:
                        # æœç´¢APIä¸å¯ç”¨ï¼Œè·³è¿‡æ­¤å…³é”®è¯
                        streaming_session = prep_res.get("streaming_session")
                        if streaming_session:
                            from agent.streaming import emit_error_from_prep
                            await emit_error_from_prep(prep_res, f"âš ï¸ æœç´¢APIä¸å¯ç”¨ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                        continue

                    # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    time.sleep(0.5)

                except Exception as e:
                    # å•ä¸ªå…³é”®è¯æœç´¢å¤±è´¥ä¸å½±å“å…¶ä»–å…³é”®è¯
                    streaming_session = prep_res.get("streaming_session")
                    if streaming_session:
                        from agent.streaming import emit_error_from_prep
                        await emit_error_from_prep(prep_res, f"âŒ æœç´¢å¤±è´¥ï¼Œå…³é”®è¯ '{keyword}': {str(e)}")
                    continue
            
            # å»é‡
            deduplicated_results = self._deduplicate_results(all_results)

            # é™åˆ¶ç»“æœæ•°é‡
            final_results = deduplicated_results[:max_results]
            
            search_time = time.time() - start_time
            
            return {
                "search_results": final_results,
                "total_found": len(final_results),
                "search_time": round(search_time * 1000),  # è½¬æ¢ä¸ºæ¯«ç§’
                "keywords_processed": len(search_keywords),
                "deduplication_stats": {
                    "original_count": len(all_results),
                    "deduplicated_count": len(deduplicated_results),
                    "final_count": len(final_results)
                }
            }
            
        except Exception as e:
            raise RuntimeError(f"Search execution failed: {str(e)}")
    
    async def post_async(self, shared, prep_res: Dict[str, Any], exec_res: Dict[str, Any]) -> str:
        """
        åå¤„ç†é˜¶æ®µï¼šå°†æœç´¢ç»“æœå­˜å‚¨åˆ°å…±äº«çŠ¶æ€

        Args:
            shared: å…±äº«çŠ¶æ€å­—å…¸
            prep_res: å‡†å¤‡é˜¶æ®µç»“æœ
            exec_res: æ‰§è¡Œé˜¶æ®µç»“æœ

        Returns:
            ä¸‹ä¸€æ­¥åŠ¨ä½œ
        """
        try:
            if "error" in exec_res:
                # è®°å½•é”™è¯¯åˆ°sharedå­—å…¸
                if "errors" not in shared:
                    shared["errors"] = []
                shared["errors"].append({
                    "source": "NodeSearch.exec",
                    "error": exec_res["error"],
                    "timestamp": prep_res.get("timestamp", "")
                })
                return "error"

            search_results = exec_res["search_results"]

            # ç»Ÿä¸€ä½¿ç”¨å­—å…¸æ¨¡å¼å­˜å‚¨æœç´¢ç»“æœ
            if search_results:
                shared["first_search_result"] = search_results[0]
                shared["all_search_results"] = search_results




            return "search_complete"

        except Exception as e:
            # å‘é€é”™è¯¯äº‹ä»¶
            await emit_error(shared, f"âŒ NodeSearch postå¤„ç†å¤±è´¥: {e}")
            # è®°å½•é”™è¯¯åˆ°sharedå­—å…¸
            if "errors" not in shared:
                shared["errors"] = []
            shared["errors"].append({
                "source": "NodeSearch.post",
                "error": str(e),
                "timestamp": prep_res.get("timestamp", "")
            })
            return "error"
    



    
    def _extract_keywords_from_shared_state(self, shared) -> List[str]:
        """ä»å…±äº«çŠ¶æ€ä¸­æå–æœç´¢å…³é”®è¯"""
        # ç›´æ¥ä»sharedå­—å…¸è·å–æœç´¢å…³é”®è¯
        search_keywords = shared.get("search_keywords", [])

        # å»é‡å¹¶è¿”å›
        return list(set(search_keywords))[:5]  # æœ€å¤šè¿”å›5ä¸ªå…³é”®è¯
    

    


    
    def _deduplicate_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é‡æœç´¢ç»“æœ"""
        seen_urls = set()
        deduplicated = []
        
        for result in results:
            url = result.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                deduplicated.append(result)
        
        return deduplicated
    

    

    

