"""
æµ‹è¯•é‡æ„åçš„ReActä¸»æ§åˆ¶å™¨Function CallingåŠŸèƒ½

éªŒè¯æ–°çš„åŸºäºFunction Callingçš„ReActä¸»æ§åˆ¶å™¨æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œã€‚
"""

import pytest
import asyncio
from agent.flows.react_orchestrator_node import ReActOrchestratorNode


class TestReActFunctionCalling:
    """ReAct Function CallingåŠŸèƒ½æµ‹è¯•"""

    @pytest.fixture
    def react_node(self):
        """åˆ›å»ºReActä¸»æ§åˆ¶å™¨èŠ‚ç‚¹ - ä½¿ç”¨çœŸå®ç»„ä»¶"""
        return ReActOrchestratorNode()

    @pytest.fixture
    def mock_shared_data(self):
        """æ¨¡æ‹Ÿå…±äº«æ•°æ®"""
        return {
            "dialogue_history": {
                "messages": [
                    {"role": "user", "content": "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™"}
                ]
            },
            "react_cycle_count": 0
        }

    @pytest.mark.asyncio
    async def test_prep_async(self, react_node, mock_shared_data):
        """æµ‹è¯•å‡†å¤‡é˜¶æ®µ"""
        result = await react_node.prep_async(mock_shared_data)
        
        assert result["success"] is True
        assert "user_message" in result
        assert "state_info" in result
        assert result["user_message"] == "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™"

    @pytest.mark.asyncio
    async def test_build_conversation_messages(self, react_node):
        """æµ‹è¯•å¯¹è¯æ¶ˆæ¯æ„å»º"""
        user_message = "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™"
        state_info = "å½“å‰çŠ¶æ€ï¼šåˆå§‹åŒ–"
        shared_data = {
            "dialogue_history": {
                "messages": [
                    {"role": "user", "content": "ä½ å¥½"},
                    {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯GTPlanneråŠ©æ‰‹"}
                ]
            }
        }
        
        messages = react_node._build_conversation_messages(user_message, state_info, shared_data)
        
        # æ£€æŸ¥æ¶ˆæ¯ç»“æ„
        assert len(messages) >= 3  # ç³»ç»Ÿæ¶ˆæ¯ + å†å²æ¶ˆæ¯ + å½“å‰æ¶ˆæ¯
        assert messages[0]["role"] == "system"
        assert "GTPlanner" in messages[0]["content"]
        assert messages[-1]["role"] == "user"
        assert user_message in messages[-1]["content"]

    @pytest.mark.asyncio
    async def test_function_calling_system_prompt(self, react_node):
        """æµ‹è¯•Function Callingç³»ç»Ÿæç¤ºè¯"""
        prompt = react_node._build_function_calling_system_prompt()
        
        # æ£€æŸ¥å…³é”®å†…å®¹
        assert "GTPlanner" in prompt
        assert "Function Calling" in prompt
        assert "requirements_analysis" in prompt
        assert "short_planning" in prompt
        assert "research" in prompt
        assert "architecture_design" in prompt

    # ç§»é™¤äº†mockæµ‹è¯•ï¼Œä½¿ç”¨çœŸå®LLMæµ‹è¯•æ›¿ä»£

    @pytest.mark.asyncio
    async def test_update_shared_state_with_tool_result(self, react_node):
        """æµ‹è¯•å·¥å…·ç»“æœæ›´æ–°å…±äº«çŠ¶æ€"""
        shared = {}
        
        # æµ‹è¯•éœ€æ±‚åˆ†æç»“æœ
        tool_result = {
            "success": True,
            "result": {"project_overview": {"title": "æµ‹è¯•é¡¹ç›®"}}
        }
        
        react_node._update_shared_state_with_tool_result(shared, "requirements_analysis", tool_result)
        assert "structured_requirements" in shared
        assert shared["structured_requirements"]["project_overview"]["title"] == "æµ‹è¯•é¡¹ç›®"
        
        # æµ‹è¯•çŸ­æœŸè§„åˆ’ç»“æœ
        tool_result = {
            "success": True,
            "result": {"phases": ["é˜¶æ®µ1", "é˜¶æ®µ2"]}
        }
        
        react_node._update_shared_state_with_tool_result(shared, "short_planning", tool_result)
        assert "confirmation_document" in shared
        assert shared["confirmation_document"]["phases"] == ["é˜¶æ®µ1", "é˜¶æ®µ2"]

    @pytest.mark.asyncio
    async def test_post_async_with_tool_calls(self, react_node):
        """æµ‹è¯•å¸¦å·¥å…·è°ƒç”¨çš„postå¤„ç†"""
        shared = {"react_cycle_count": 0}
        prep_res = {}
        exec_res = {
            "user_message": "æˆ‘å·²ç»å®Œæˆäº†éœ€æ±‚åˆ†æã€‚",
            "tool_calls": [
                {
                    "tool_name": "requirements_analysis",
                    "result": {
                        "success": True,
                        "result": {"project_overview": {"title": "ç”µå•†é¡¹ç›®"}}
                    }
                }
            ],
            "next_action": "continue_conversation",
            "decision_success": True
        }

        result = await react_node.post_async(shared, prep_res, exec_res)

        # éªŒè¯ç»“æœ
        assert result == "wait_for_user"
        assert shared["react_cycle_count"] == 1
        assert "dialogue_history" in shared
        assert len(shared["dialogue_history"]["messages"]) == 1
        assert shared["dialogue_history"]["messages"][0]["role"] == "assistant"
        assert "structured_requirements" in shared

    @pytest.mark.asyncio
    async def test_error_handling(self, react_node):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        # æµ‹è¯•prepé˜¶æ®µé”™è¯¯
        shared_with_error = {}  # ç¼ºå°‘å¿…è¦æ•°æ®

        result = await react_node.prep_async(shared_with_error)
        assert result["success"] is True  # prepåº”è¯¥èƒ½å¤„ç†ç©ºæ•°æ®

        # æµ‹è¯•execé˜¶æ®µé”™è¯¯
        prep_result = {"error": "æµ‹è¯•é”™è¯¯"}
        exec_result = await react_node.exec_async(prep_result)
        assert "error" in exec_result
        assert exec_result["decision_success"] is False

    @pytest.mark.asyncio
    async def test_mixed_mode_real_llm_call(self, react_node):
        """æµ‹è¯•æ··åˆæ¨¡å¼ï¼šä½¿ç”¨çœŸå®LLMè°ƒç”¨"""
        # æ„å»ºæµ‹è¯•æ¶ˆæ¯
        messages = [
            {"role": "system", "content": react_node._build_function_calling_system_prompt()},
            {"role": "user", "content": "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªç®€å•çš„å¾…åŠäº‹é¡¹ç®¡ç†åº”ç”¨ï¼Œè¯·å¸®æˆ‘åˆ†æéœ€æ±‚å¹¶è¿›è¡ŒæŠ€æœ¯è°ƒç ”"}
        ]

        print("ğŸš€ å¼€å§‹çœŸå®LLMè°ƒç”¨æµ‹è¯•...")

        # æ‰§è¡ŒçœŸå®çš„Function Calling
        result = await react_node._execute_with_function_calling(messages, {})

        # è¾“å‡ºç»“æœ
        print(f"âœ… LLMè°ƒç”¨å®Œæˆ")
        print(f"ğŸ“ ç”¨æˆ·æ¶ˆæ¯: {result.get('user_message', '')}")
        print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°é‡: {len(result.get('tool_calls', []))}")
        print(f"ğŸ¯ æ‰§è¡Œæ¨¡å¼: {result.get('execution_mode', 'unknown')}")
        print(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {result.get('reasoning', '')}")

        # è¯¦ç»†è¾“å‡ºå·¥å…·è°ƒç”¨ç»“æœ
        for i, tool_call in enumerate(result.get('tool_calls', [])):
            print(f"ğŸ› ï¸ å·¥å…·è°ƒç”¨ {i+1}:")
            print(f"   åç§°: {tool_call.get('tool_name', 'unknown')}")
            print(f"   æˆåŠŸ: {tool_call.get('success', False)}")
            if tool_call.get('result', {}).get('success'):
                print(f"   ç»“æœ: æ‰§è¡ŒæˆåŠŸ")
            else:
                print(f"   é”™è¯¯: {tool_call.get('result', {}).get('error', 'unknown')}")

        # åŸºæœ¬éªŒè¯
        assert result["decision_success"] is True, "LLMè°ƒç”¨åº”è¯¥æˆåŠŸ"
        assert "user_message" in result, "åº”è¯¥æœ‰ç”¨æˆ·æ¶ˆæ¯"

        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼ŒéªŒè¯å…¶ç»“æ„
        if result.get("tool_calls"):
            for tool_call in result["tool_calls"]:
                assert "tool_name" in tool_call, "å·¥å…·è°ƒç”¨åº”è¯¥æœ‰åç§°"
                assert "result" in tool_call, "å·¥å…·è°ƒç”¨åº”è¯¥æœ‰ç»“æœ"
                assert "success" in tool_call, "å·¥å…·è°ƒç”¨åº”è¯¥æœ‰æˆåŠŸæ ‡å¿—"

        print("âœ… çœŸå®LLMè°ƒç”¨æµ‹è¯•é€šè¿‡ï¼")

        return result  # è¿”å›ç»“æœä¾›è¿›ä¸€æ­¥åˆ†æ

    @pytest.mark.asyncio
    async def test_mixed_mode_streaming_real_llm(self, react_node):
        """æµ‹è¯•æ··åˆæ¨¡å¼ï¼šä½¿ç”¨çœŸå®LLMæµå¼è°ƒç”¨"""
        # æ„å»ºæµ‹è¯•æ¶ˆæ¯
        messages = [
            {"role": "system", "content": react_node._build_function_calling_system_prompt()},
            {"role": "user", "content": "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªåœ¨çº¿æ•™è‚²å¹³å°ï¼Œè¯·å¸®æˆ‘åˆ†æéœ€æ±‚"}
        ]

        print("ğŸš€ å¼€å§‹çœŸå®æµå¼LLMè°ƒç”¨æµ‹è¯•...")

        # æ”¶é›†æµå¼å†…å®¹
        streamed_content = []

        async def stream_callback(content: str):
            streamed_content.append(content)
            print(content, end='', flush=True)

        # æ‰§è¡ŒçœŸå®çš„æµå¼Function Calling
        result = await react_node._execute_with_function_calling_stream(
            messages, stream_callback, {}
        )

        print(f"\nâœ… æµå¼LLMè°ƒç”¨å®Œæˆ")
        print(f"ğŸ“ æœ€ç»ˆæ¶ˆæ¯: {result.get('user_message', '')}")
        print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°é‡: {len(result.get('tool_calls', []))}")
        print(f"ğŸ¯ æ‰§è¡Œæ¨¡å¼: {result.get('execution_mode', 'unknown')}")
        print(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {result.get('reasoning', '')}")
        print(f"ğŸ”„ å¯¹è¯è½®æ•°: {result.get('conversation_rounds', 1)}")

        # éªŒè¯æµå¼å†…å®¹
        total_streamed = ''.join(streamed_content)
        print(f"ğŸ“¡ æµå¼å†…å®¹é•¿åº¦: {len(total_streamed)} å­—ç¬¦")

        # åŸºæœ¬éªŒè¯
        assert result["decision_success"] is True, "æµå¼LLMè°ƒç”¨åº”è¯¥æˆåŠŸ"
        assert "user_message" in result, "åº”è¯¥æœ‰ç”¨æˆ·æ¶ˆæ¯"

        # éªŒè¯æµå¼å†…å®¹
        if streamed_content:
            assert len(total_streamed) > 0, "åº”è¯¥æœ‰æµå¼å†…å®¹è¾“å‡º"

        print("âœ… çœŸå®æµå¼LLMè°ƒç”¨æµ‹è¯•é€šè¿‡ï¼")

        return result

    @pytest.mark.asyncio
    async def test_optimized_streaming_with_tools(self, react_node):
        """æµ‹è¯•ä¼˜åŒ–åçš„æµå¼è¾“å‡ºä¸å·¥å…·è°ƒç”¨åè°ƒ"""
        # æ„å»ºæµ‹è¯•æ¶ˆæ¯
        messages = [
            {"role": "system", "content": react_node._build_function_calling_system_prompt()},
            {"role": "user", "content": "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªåšå®¢ç³»ç»Ÿï¼Œè¯·å¸®æˆ‘åˆ†æéœ€æ±‚å¹¶è°ƒç ”æŠ€æœ¯æ–¹æ¡ˆ"}
        ]

        print("ğŸš€ å¼€å§‹ä¼˜åŒ–æµå¼è¾“å‡ºæµ‹è¯•...")

        # æ”¶é›†æ‰€æœ‰æµå¼è¾“å‡º
        stream_log = []

        async def detailed_stream_callback(content: str):
            stream_log.append(content)
            print(f"ğŸ“¡ [{len(stream_log)}] {content}", end='', flush=True)

        # æ‰§è¡Œä¼˜åŒ–åçš„æµå¼Function Calling
        result = await react_node._execute_with_function_calling_stream(
            messages, detailed_stream_callback, {}
        )

        print(f"\nâœ… ä¼˜åŒ–æµå¼è°ƒç”¨å®Œæˆ")
        print(f"ğŸ“ æœ€ç»ˆæ¶ˆæ¯: {result.get('user_message', '')}")
        print(f"ğŸ”§ å·¥å…·è°ƒç”¨æ•°é‡: {len(result.get('tool_calls', []))}")
        print(f"ğŸ¯ æ‰§è¡Œæ¨¡å¼: {result.get('execution_mode', 'unknown')}")
        print(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {result.get('reasoning', '')}")

        # åˆ†ææµå¼è¾“å‡º
        total_stream_content = ''.join(stream_log)
        print(f"ğŸ“¡ æ€»æµå¼å†…å®¹é•¿åº¦: {len(total_stream_content)} å­—ç¬¦")
        print(f"ğŸ“¡ æµå¼å—æ•°é‡: {len(stream_log)}")

        # æ£€æŸ¥æµå¼è¾“å‡ºä¸­çš„å·¥å…·æ‰§è¡Œåé¦ˆ
        tool_feedback_count = sum(1 for item in stream_log if any(
            keyword in item for keyword in ['ğŸ”§', 'âœ…', 'âŒ', 'â³']
        ))
        print(f"ğŸ”§ å·¥å…·æ‰§è¡Œåé¦ˆæ•°é‡: {tool_feedback_count}")

        # åŸºæœ¬éªŒè¯
        assert result["decision_success"] is True, "ä¼˜åŒ–æµå¼è°ƒç”¨åº”è¯¥æˆåŠŸ"
        assert "user_message" in result, "åº”è¯¥æœ‰ç”¨æˆ·æ¶ˆæ¯"

        # å¦‚æœæµå¼è¾“å‡ºä¸ºç©ºï¼Œå¯èƒ½æ˜¯æ¨¡å‹ä¸æ”¯æŒæµå¼æˆ–å›é€€åˆ°äº†æ ‡å‡†è°ƒç”¨
        if len(stream_log) == 0:
            print("âš ï¸ æµå¼è¾“å‡ºä¸ºç©ºï¼Œå¯èƒ½æ¨¡å‹ä¸æ”¯æŒæµå¼æˆ–å›é€€åˆ°æ ‡å‡†è°ƒç”¨")
            # åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒéªŒè¯æ˜¯å¦æœ‰æœ‰æ•ˆçš„å“åº”
            assert len(result.get("user_message", "")) > 0 or len(result.get("tool_calls", [])) > 0, "åº”è¯¥æœ‰æœ‰æ•ˆçš„å“åº”æˆ–å·¥å…·è°ƒç”¨"
        else:
            # å¦‚æœæœ‰æµå¼è¾“å‡ºï¼ŒéªŒè¯å…¶è´¨é‡
            assert result.get("execution_mode") == "stream_mixed", "åº”è¯¥æ˜¯æµå¼æ··åˆæ¨¡å¼"

        print("âœ… ä¼˜åŒ–æµå¼è¾“å‡ºæµ‹è¯•é€šè¿‡ï¼")

        return result

    @pytest.mark.asyncio
    async def test_determine_next_action(self, react_node):
        """æµ‹è¯•ä¸‹ä¸€æ­¥è¡ŒåŠ¨å†³ç­–"""
        # æµ‹è¯•æ— å·¥å…·è°ƒç”¨
        next_action = react_node._determine_next_action([], "Hello")
        assert next_action == "continue_conversation"

        # æµ‹è¯•å•ä¸ªæˆåŠŸçš„éœ€æ±‚åˆ†æ
        tool_calls = [
            {"tool_name": "requirements_analysis", "success": True}
        ]
        next_action = react_node._determine_next_action(tool_calls, "åˆ†æå®Œæˆ")
        assert next_action == "continue_conversation"

        # æµ‹è¯•å¤šä¸ªæˆåŠŸçš„å·¥å…·è°ƒç”¨
        tool_calls = [
            {"tool_name": "requirements_analysis", "success": True},
            {"tool_name": "short_planning", "success": True}
        ]
        next_action = react_node._determine_next_action(tool_calls, "å¤„ç†å®Œæˆ")
        assert next_action == "complete"

        # æµ‹è¯•æœ‰å¤±è´¥çš„å·¥å…·è°ƒç”¨
        tool_calls = [
            {"tool_name": "requirements_analysis", "success": True},
            {"tool_name": "research", "success": False}
        ]
        next_action = react_node._determine_next_action(tool_calls, "éƒ¨åˆ†å¤±è´¥")
        assert next_action == "continue_conversation"

    @pytest.mark.asyncio
    async def test_build_reasoning(self, react_node):
        """æµ‹è¯•æ¨ç†è¯´æ˜æ„å»º"""
        # æµ‹è¯•æ— å·¥å…·è°ƒç”¨
        reasoning = react_node._build_reasoning([], "Hello")
        assert "æœªè°ƒç”¨å·¥å…·" in reasoning

        # æµ‹è¯•å•ä¸ªæˆåŠŸå·¥å…·è°ƒç”¨
        tool_calls = [
            {"tool_name": "requirements_analysis", "success": True}
        ]
        reasoning = react_node._build_reasoning(tool_calls, "åˆ†æå®Œæˆ")
        assert "å•ä¸ªå·¥å…·è°ƒç”¨" in reasoning
        assert "requirements_analysis" in reasoning
        assert "æˆåŠŸ" in reasoning

        # æµ‹è¯•å¤šä¸ªæ··åˆç»“æœçš„å·¥å…·è°ƒç”¨
        tool_calls = [
            {"tool_name": "requirements_analysis", "success": True},
            {"tool_name": "research", "success": False}
        ]
        reasoning = react_node._build_reasoning(tool_calls, "æ··åˆç»“æœ")
        assert "å¹¶è¡Œæ‰§è¡Œäº† 2 ä¸ªå·¥å…·è°ƒç”¨" in reasoning
        assert "æˆåŠŸ: requirements_analysis" in reasoning
        assert "å¤±è´¥: research" in reasoning


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    pytest.main([__file__, "-v"])
